"""
ê³ ê¸‰ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì§ˆë¬¸ ë¶„ë¥˜, ì˜ë£Œ QA, ë³‘ì› ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""
import os
import sys
from pathlib import Path
from dotenv import load_dotenv
import json

load_dotenv()
sys.path.append(str(Path(__file__).parent))

from src.ingestion import ingest_data
from src.chunking import chunk_documents_with_token_range
from src.embeddings import get_embedding_model, create_vectorstore, load_vectorstore
from src.question_classifier import QuestionClassifier
from src.medical_qa_handler import MedicalQAHandler
from src.hospital_handler import HospitalHandler
from src.advanced_rag_pipeline import AdvancedRAGPipeline


def test_question_classifier():
    """
    ì§ˆë¬¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
    """
    print("\n" + "=" * 80)
    print("TEST 1: ì§ˆë¬¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    classifier = QuestionClassifier()
    
    test_questions = [
        # ì˜ë£Œ ì§ˆë¬¸
        "ê°œì˜ ê·€ì—¼ì¦ ì¦ìƒê³¼ ì¹˜ë£Œë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ê³ ì–‘ì´ê°€ ìê¾¸ êµ¬í† í•´ìš”. ë­ê°€ ë¬¸ì œì¸ê°€ìš”?",
        "ë²¼ë£© ì˜ˆë°© ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        
        # ë³‘ì› ì§ˆë¬¸
        "ì„œìš¸ ê°•ë‚¨êµ¬ì˜ ë™ë¬¼ë³‘ì›ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        "24ì‹œê°„ ì‘ê¸‰ì§„ë£Œ ë³‘ì›ì´ ìˆì„ê¹Œìš”?",
        
        # ì¼ë°˜ ì§ˆë¬¸
        "ë°˜ë ¤ë™ë¬¼ êµì‹¤ì„ ì–´ë””ì„œ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”?",
        "ê°œì™€ ê³ ì–‘ì´ëŠ” ì™œ ì‚¬ì´ê°€ ì•ˆ ì¢‹ë‚˜ìš”?",
    ]
    
    for question in test_questions:
        question_type, confidence, reason = classifier.classify(question)
        print(f"\nì§ˆë¬¸: {question}")
        print(f"  ë¶„ë¥˜: {question_type.name} ({question_type.value})")
        print(f"  ì‹ ë¢°ë„: {confidence:.2%}")
        print(f"  ì‚¬ìœ : {reason}")


def test_hospital_handler():
    """
    ë³‘ì› ì •ë³´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    """
    print("\n" + "=" * 80)
    print("TEST 2: ë³‘ì› ì •ë³´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    handler = HospitalHandler()
    
    # í†µê³„ ì¶œë ¥
    print("\nğŸ“Š ë³‘ì› í†µê³„:")
    stats = handler.get_statistics()
    print(f"  ì´ ë³‘ì› ìˆ˜: {stats.get('total_hospitals', 0)}")
    print(f"\n  êµ¬ë³„ ë³‘ì› ìˆ˜ (ìƒìœ„ 10ê°œ):")
    for district, count in stats.get('top_districts', [])[:10]:
        print(f"    â€¢ {district}: {count}ê°œ")
    
    # ì§€ì—­ë³„ ê²€ìƒ‰
    print("\nğŸ” ì§€ì—­ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    hospitals = handler.get_nearby_hospitals("ê°•ë‚¨êµ¬", limit=5)
    print(f"  ê°•ë‚¨êµ¬ì˜ ë³‘ì› ({len(hospitals)}ê°œ):")
    for i, hospital in enumerate(hospitals[:3], 1):
        print(f"    {i}. {hospital['name']}")
        print(f"       ì£¼ì†Œ: {hospital['address']}")
        print(f"       ì „í™”: {hospital['phone']}")


def test_advanced_pipeline():
    """
    ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    """
    print("\n" + "=" * 80)
    print("TEST 3: ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    print("\në²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
    embedding_model = get_embedding_model("openai")
    
    if not os.path.exists("./chroma_db"):
        print("ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘...")
        documents = ingest_data("data/Validation/01.ì›ì²œë°ì´í„°")
        chunked_docs = chunk_documents_with_token_range(
            documents,
            min_tokens=300,
            max_tokens=500,
            overlap_ratio=0.25
        )
        vectorstore = create_vectorstore(
            chunked_docs,
            embedding_model,
            persist_directory="./chroma_db",
            collection_name="rag_collection"
        )
    else:
        vectorstore = load_vectorstore(
            embedding_model,
            persist_directory="./chroma_db",
            collection_name="rag_collection"
        )
    
    print("âœ“ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    print("\níŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
    pipeline = AdvancedRAGPipeline(
        vectorstore=vectorstore,
        hospital_csv_path="data/raw/hospital/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›_ì¸í—ˆê°€_ì •ë³´.csv",
        llm_model="gpt-4o-mini",
        score_threshold=0.6
    )
    print("âœ“ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_queries = [
        # ì˜ë£Œ ì§ˆë¬¸
        "ê°œì˜ í”¼ë¶€ì—¼ ì¦ìƒì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        # ë³‘ì› ì§ˆë¬¸
        "ê°•ë‚¨êµ¬ ë™ë¬¼ë³‘ì›ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        # ì¼ë°˜ ì§ˆë¬¸
        "ë°˜ë ¤ë™ë¬¼ì„ ì²˜ìŒ í‚¤ìš°ëŠ”ë° ì–´ë–¤ ì¤€ë¹„ê°€ í•„ìš”í• ê¹Œìš”?",
    ]
    
    results = []
    for query in test_queries:
        print(f"\n{'â”€' * 80}")
        result = pipeline.process_question(query)
        results.append(result)
        
        print(f"\nğŸ“ ê°„ë‹¨í•œ ë‹µë³€:")
        answer_preview = result['formatted_answer'][:200] + "..." if len(result['formatted_answer']) > 200 else result['formatted_answer']
        print(answer_preview)
    
    # ê²°ê³¼ ì €ì¥
    pipeline.save_results(results, "test_results.json")
    print(f"\nâœ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ test_results.jsonì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


def test_medical_scoring():
    """
    ì˜ë£Œ ì§ˆë¬¸ì˜ ì ìˆ˜ í‰ê°€ í…ŒìŠ¤íŠ¸
    """
    print("\n" + "=" * 80)
    print("TEST 4: ì˜ë£Œ ì§ˆë¬¸ ì ìˆ˜ í‰ê°€ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    print("\në²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
    embedding_model = get_embedding_model("openai")
    
    if not os.path.exists("./chroma_db"):
        print("ë²¡í„°ìŠ¤í† ì–´ í•„ìš” - TEST 3 ì‹¤í–‰ í›„ ì§„í–‰í•˜ì„¸ìš”.")
        return
    
    vectorstore = load_vectorstore(
        embedding_model,
        persist_directory="./chroma_db",
        collection_name="rag_collection"
    )
    
    # ì˜ë£Œ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
    handler = MedicalQAHandler(
        vectorstore=vectorstore,
        score_threshold=0.6,
        top_k=5
    )
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_queries = [
        "ê°œì˜ ë²¼ë£© ì•ŒëŸ¬ì§€ì„± í”¼ë¶€ì—¼ ì¦ìƒì€?",
        "ê³ ì–‘ì´ ì‹ ë¶€ì „ ì¹˜ë£Œë²•",
        "ê°œì˜ ê·€ê°ì—¼ ì›ì¸ê³¼ ì¹˜ë£Œ",
    ]
    
    for query in test_queries:
        print(f"\nì§ˆë¬¸: {query}")
        result = handler.handle_medical_question(query)
        
        print(f"\nê²°ê³¼:")
        print(f"  â€¢ ë‚´ë¶€ ë¬¸ì„œ: {result['internal_search_results']}ê°œ")
        print(f"  â€¢ ì›¹ ê²€ìƒ‰ ì‚¬ìš©: {result['used_web_search']}")
        print(f"  â€¢ ê·¼ê±° ì ìˆ˜: {result['relevance_score']:.2%}")
        print(f"  â€¢ ìƒíƒœ: {'ì¶©ë¶„í•œ ê·¼ê±°' if result['relevance_score'] >= 0.6 else 'ì›¹ ê²€ìƒ‰ ìˆ˜í–‰'}")


def main():
    """
    ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    """
    print("=" * 80)
    print("ğŸ§ª ê³ ê¸‰ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    test_menu = {
        "1": ("ì§ˆë¬¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸", test_question_classifier),
        "2": ("ë³‘ì› ì •ë³´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸", test_hospital_handler),
        "3": ("ì˜ë£Œ ì§ˆë¬¸ ì ìˆ˜ í‰ê°€ í…ŒìŠ¤íŠ¸", test_medical_scoring),
        "4": ("ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸", test_advanced_pipeline),
        "5": ("ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰", None),
    }
    
    print("\ní…ŒìŠ¤íŠ¸ ë©”ë‰´:")
    for key, (name, _) in test_menu.items():
        print(f"  {key}. {name}")
    print("  6. ì¢…ë£Œ")
    
    choice = input("\nì„ íƒ (1-6): ").strip()
    
    if choice == "1":
        test_question_classifier()
    elif choice == "2":
        test_hospital_handler()
    elif choice == "3":
        test_medical_scoring()
    elif choice == "4":
        test_advanced_pipeline()
    elif choice == "5":
        test_question_classifier()
        test_hospital_handler()
        test_medical_scoring()
        test_advanced_pipeline()
    elif choice == "6":
        print("í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        print("ìœ íš¨í•œ ì„ íƒì´ ì•„ë‹™ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

