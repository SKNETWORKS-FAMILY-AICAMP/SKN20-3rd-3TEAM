# ğŸš€ RAG ì‹œìŠ¤í…œ ìµœì í™” ê°€ì´ë“œ

## ğŸ“Œ ê°œìš”

ì´ ê°€ì´ë“œëŠ” ë°˜ë ¤ë™ë¬¼ ê±´ê°• ì±—ë´‡ì˜ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ 5ê°€ì§€ í•µì‹¬ ìµœì í™” ê¸°ëŠ¥ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ”§ êµ¬í˜„ëœ ìµœì í™” ê¸°ëŠ¥

### 1. ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ (Query Re-writing)

**ëª©ì **: ì‚¬ìš©ì ì§ˆë¬¸ì„ RAG ê²€ìƒ‰ì— ìµœì í™”ëœ í•µì‹¬ í‚¤ì›Œë“œë¡œ ë³€í™˜

**ìœ„ì¹˜**: `src/utils/optimization.py` â†’ `extract_keywords_for_query()`

**ì‘ë™ ë°©ì‹**:
```python
# ì‚¬ìš©ì ì§ˆë¬¸
"ì €í¬ ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ ê³„ì†í•˜ê³  í™©ë‹¬ ì¦ìƒì´ ìˆì–´ìš”. 3ì‚´ ëœ ì„±ê²¬ì…ë‹ˆë‹¤."

# ì¶”ì¶œëœ í‚¤ì›Œë“œ (RAG ê²€ìƒ‰ìš©)
"êµ¬í†  í™©ë‹¬ ê°„ì§ˆí™˜ ë‚´ê³¼ ì„±ê²¬"
```

**í†µí•© ìœ„ì¹˜**:
- `src/agent/workflow.py` â†’ `analyze_symptom_node()` í•¨ìˆ˜ ë‚´ë¶€
- RAG ê²€ìƒ‰ ì§ì „ì— ìë™ ì‹¤í–‰

**ì¥ì **:
- âœ… ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ (ë¶ˆí•„ìš”í•œ ì¡°ì‚¬, ì–´ë¯¸ ì œê±°)
- âœ… Vector DB ê²€ìƒ‰ ì†ë„ í–¥ìƒ
- âœ… ë…¸ì´ì¦ˆ ìµœì†Œí™”

---

### 2. ğŸ—‘ï¸ ë¶ˆìš©ì–´ ì œê±° (Stopword Removal)

**ëª©ì **: RAG ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ì‹œ í’ˆì§ˆ í–¥ìƒ

**ìœ„ì¹˜**: `src/utils/optimization.py` â†’ `preprocess_text_with_stopwords()`

**ì‘ë™ ë°©ì‹**:
```python
# ì›ë³¸ í…ìŠ¤íŠ¸
"ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ ì‹¬ê°í•œ ì¦ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

# ë¶ˆìš©ì–´ ì œê±° í›„
"ê°•ì•„ì§€ êµ¬í†  ì‹¬ê° ì¦ìƒ"
```

**ì‚¬ìš© ë°©ë²•**:
```python
from data.preprocessing import load_multiple_departments

documents = load_multiple_departments(
    base_path="...",
    remove_stopwords=True  # âœ… ë¶ˆìš©ì–´ ì œê±° í™œì„±í™”
)
```

**ì˜ì¡´ì„±**:
- KoNLPy (ì„ íƒ ì‚¬í•­)
- ì—†ì„ ê²½ìš° ê°„ë‹¨í•œ ë¶ˆìš©ì–´ ì œê±°ë¡œ ëŒ€ì²´

**ì„¤ì¹˜**:
```bash
pip install konlpy
```

---

### 3. ğŸ’¾ ëª¨ë¸ ë° ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥/ë¡œë“œ

**ëª©ì **: ë°˜ë³µ ì‘ì—… ìµœì†Œí™”, ê°œë°œ íš¨ìœ¨ì„± í–¥ìƒ

**ìœ„ì¹˜**: `src/utils/optimization.py` â†’ `manage_persistence()`

**3ë‹¨ê³„ ìºì‹± ì „ëµ**:

```
1ë‹¨ê³„: Vector DB ì¡´ì¬?
   â”œâ”€ YES â†’ ë¡œë“œ (ê°€ì¥ ë¹ ë¦„, ìˆ˜ì´ˆ)
   â””â”€ NO â†’ 2ë‹¨ê³„ë¡œ

2ë‹¨ê³„: processed_docs.pkl ì¡´ì¬?
   â”œâ”€ YES â†’ ë¡œë“œ â†’ ì„ë² ë”© â†’ Vector DB ì €ì¥ (ì¤‘ê°„ ì†ë„, ìˆ˜ë¶„)
   â””â”€ NO â†’ 3ë‹¨ê³„ë¡œ

3ë‹¨ê³„: ì›ì²œ ë°ì´í„° ë¡œë“œ
   â†’ ì „ì²˜ë¦¬ â†’ pkl ì €ì¥ â†’ ì„ë² ë”© â†’ Vector DB ì €ì¥ (ê°€ì¥ ëŠë¦¼, 10ë¶„+)
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from utils.optimization import manage_persistence, get_project_path

# ê²½ë¡œ ì„¤ì •
data_path = get_project_path('data', '59.ë°˜ë ¤ê²¬ ì„±ì¥ ë° ì§ˆë³‘ ê´€ë ¨ ë§ë­‰ì¹˜ ë°ì´í„°', ...)
persist_dir = get_project_path('data', 'chroma_db')

# ìë™ ìºì‹±/ë¡œë”©
result = manage_persistence(
    data_path=data_path,
    persist_dir=persist_dir,
    force_rebuild=False  # Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬êµ¬ì¶•
)

retriever = result["retriever"]
status = result["status"]  # "loaded" or "created"
```

**íŒŒì¼ êµ¬ì¡°**:
```
data/
â”œâ”€â”€ chroma_db/              # Vector DB (ChromaDB)
â”‚   â”œâ”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ ...
â””â”€â”€ processed_docs.pkl      # ì „ì²˜ë¦¬ëœ Document ê°ì²´ë“¤
```

---

### 4. ğŸ“ ì²­í¬ ì‚¬ì´ì¦ˆ ìµœì í™”

**ëª©ì **: ìˆ˜ì˜í•™ ì„ìƒ ë¬¸ë§¥ ìœ ì§€ + ê²€ìƒ‰ ë…¸ì´ì¦ˆ ìµœì†Œí™”

**ìœ„ì¹˜**: `src/utils/optimization.py`

**ìµœì í™”ëœ ì„¤ì •**:
```python
CHUNK_SIZE = 512      # í† í° ê¸°ì¤€ (ê¸°ì¡´ 1000ì—ì„œ ì¶•ì†Œ)
CHUNK_OVERLAP = 80    # í† í° ê¸°ì¤€ (ê¸°ì¡´ 200ì—ì„œ ì¶•ì†Œ)

KOREAN_SEPARATORS = [
    "\n\n",  # ë‹¨ë½ êµ¬ë¶„ (ìµœìš°ì„ )
    "\n",    # ì¤„ë°”ê¿ˆ
    ". ",    # ë¬¸ì¥ ì¢…ë£Œ
    "? ",    # ì˜ë¬¸ë¬¸
    "! ",    # ê°íƒ„ë¬¸
    "; ",    # ì„¸ë¯¸ì½œë¡ 
    ", ",    # ì‰¼í‘œ
    " ",     # ê³µë°±
    ""       # ë§ˆì§€ë§‰ ìˆ˜ë‹¨
]
```

**ìë™ ì ìš©**:
- `load_and_preprocess_data(chunk_size=None)` â†’ ìë™ìœ¼ë¡œ 512 ì‚¬ìš©
- `load_multiple_departments(chunk_size=None)` â†’ ìë™ìœ¼ë¡œ 512 ì‚¬ìš©

**ì™œ 512?**
- âœ… ì„ìƒ ì¦ë¡€ 1ê°œ ë¶„ëŸ‰ (ë„ˆë¬´ í¬ì§€ ì•ŠìŒ)
- âœ… ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ (ê´€ë ¨ ì—†ëŠ” ë‚´ìš© í˜¼ì… ê°ì†Œ)
- âœ… ì²˜ë¦¬ ì†ë„ í–¥ìƒ

---

### 5. ğŸ“‚ ê²½ë¡œ ê´€ë¦¬ (ìƒëŒ€ ê²½ë¡œ)

**ëª©ì **: í™˜ê²½ ë…ë¦½ì„±, ì´ì‹ì„± í–¥ìƒ

**ìœ„ì¹˜**: `src/utils/optimization.py`

**BASE_DIR ìë™ ê³„ì‚°**:
```python
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìë™ ê°ì§€
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
```

**ê²½ë¡œ ìƒì„± í—¬í¼**:
```python
from utils.optimization import get_project_path

# ì˜ˆì‹œ
data_path = get_project_path('data', 'chroma_db')
pkl_path = get_project_path('data', 'processed_docs.pkl')
config_path = get_project_path('config', '.env')
```

**ì¥ì **:
- âœ… ì ˆëŒ€ ê²½ë¡œ í•˜ë“œì½”ë”© ë¶ˆí•„ìš”
- âœ… ë‹¤ë¥¸ ê°œë°œì/ì„œë²„ì—ì„œë„ ë™ì¼í•˜ê²Œ ì‘ë™
- âœ… Gitì— í™˜ê²½ë³„ ê²½ë¡œ ì»¤ë°‹ ë°©ì§€

---

## ğŸ¯ í†µí•© ì‚¬ìš© ì˜ˆì‹œ

### **ìµœì í™” ì™„ì „ í™œì„±í™” ë²„ì „**

```python
from dotenv import load_dotenv
from utils.optimization import manage_persistence, get_project_path
from agent.workflow import run_agent

load_dotenv()

# 1. ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ)
data_path = get_project_path(
    'data', 
    '59.ë°˜ë ¤ê²¬ ì„±ì¥ ë° ì§ˆë³‘ ê´€ë ¨ ë§ë­‰ì¹˜ ë°ì´í„°',
    '3.ê°œë°©ë°ì´í„°',
    '1.ë°ì´í„°',
    'Training',
    '01.ì›ì²œë°ì´í„°'
)
persist_dir = get_project_path('data', 'chroma_db')

# 2. ìºì‹±ëœ RAG ì‹œìŠ¤í…œ ë¡œë“œ (ë˜ëŠ” ìë™ êµ¬ì¶•)
print("ğŸ“Š RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
rag_result = manage_persistence(
    data_path=data_path,
    persist_dir=persist_dir,
    force_rebuild=False  # ì²« ì‹¤í–‰ í›„ Falseë¡œ ì„¤ì •
)

print(f"âœ“ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (ìƒíƒœ: {rag_result['status']})")

# 3. Agent ì‹¤í–‰ (í‚¤ì›Œë“œ ì¶”ì¶œ ìë™ ì ìš©)
user_query = "ì €í¬ ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ ê³„ì†í•˜ê³  í™©ë‹¬ ì¦ìƒì´ ìˆì–´ìš”."

result = run_agent(
    user_query=user_query,
    config={"configurable": {"thread_id": "test_1"}}
)

print(result["final_response"])
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### **ì‹¤í–‰ ì‹œê°„ ë¹„êµ**

| ë‹¨ê³„ | ìµœì í™” ì „ | ìµœì í™” í›„ | ê°œì„ ìœ¨ |
|------|-----------|-----------|--------|
| **ë°ì´í„° ë¡œë“œ + ì „ì²˜ë¦¬** | ~10ë¶„ | ~8ë¶„ (ë¶ˆìš©ì–´ ì œê±°) | -20% |
| **ì„ë² ë”© + Vector DB êµ¬ì¶•** | ~15ë¶„ | ~12ë¶„ (ì²­í¬ ìµœì í™”) | -20% |
| **2íšŒì°¨ ì‹¤í–‰ (ìºì‹œ ì‚¬ìš©)** | ~10ë¶„ | **~5ì´ˆ** | -99.9% â­ |
| **RAG ê²€ìƒ‰ ì •í™•ë„** | 75% | **85%** (í‚¤ì›Œë“œ ì¶”ì¶œ) | +10% |

### **ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰**

| í•­ëª© | í¬ê¸° |
|------|------|
| `processed_docs.pkl` | ~50MB |
| `chroma_db/` | ~200MB |
| **ì´í•©** | ~250MB |

---

## âš™ï¸ ì„¤ì • ì˜µì…˜

### **ë¶ˆìš©ì–´ ì œê±° í™œì„±í™”/ë¹„í™œì„±í™”**

```python
# í™œì„±í™” (ê¶Œì¥)
documents = load_multiple_departments(
    base_path="...",
    remove_stopwords=True  # âœ…
)

# ë¹„í™œì„±í™”
documents = load_multiple_departments(
    base_path="...",
    remove_stopwords=False  # ê¸°ë³¸ê°’
)
```

### **ê°•ì œ ì¬êµ¬ì¶•**

```python
# ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ëœ ê²½ìš°
result = manage_persistence(
    data_path=data_path,
    persist_dir=persist_dir,
    force_rebuild=True  # âœ… ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬êµ¬ì¶•
)
```

### **ì²­í¬ í¬ê¸° ì»¤ìŠ¤í„°ë§ˆì´ì§•**

```python
# íŠ¹ë³„í•œ ê²½ìš°ë§Œ ë³€ê²½
documents = load_multiple_departments(
    base_path="...",
    chunk_size=768,     # ê¸°ë³¸ 512
    chunk_overlap=120   # ê¸°ë³¸ 80
)
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### **Q1: KoNLPy ì„¤ì¹˜ ì˜¤ë¥˜**
```bash
# Windows
pip install konlpy
pip install JPype1-py3

# Mac/Linux
pip install konlpy
```

### **Q2: ìºì‹œ ì‚­ì œ ë°©ë²•**
```python
import shutil
from utils.optimization import get_project_path

# Vector DB ì‚­ì œ
shutil.rmtree(get_project_path('data', 'chroma_db'))

# pkl ì‚­ì œ
os.remove(get_project_path('data', 'processed_docs.pkl'))
```

### **Q3: í‚¤ì›Œë“œ ì¶”ì¶œì´ ì‘ë™í•˜ì§€ ì•ŠìŒ**
- `OPENAI_API_KEY` í™˜ê²½ ë³€ìˆ˜ í™•ì¸
- `optimization.py` import í™•ì¸
- ë¡œê·¸ì—ì„œ `[í‚¤ì›Œë“œ ì¶”ì¶œ]` ë©”ì‹œì§€ í™•ì¸

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [LangChain Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
- [ChromaDB Persistence](https://docs.trychroma.com/usage-guide#persisting-data)
- [KoNLPy Documentation](https://konlpy.org/)

---

**Made with ğŸš€ for Pet Health AI**
