# ğŸ¾ ë°˜ë ¤ë™ë¬¼ QA ì–´ì‹œìŠ¤í„´íŠ¸ ì‚¬ìš© ê°€ì´ë“œ

## ë¹ ë¥¸ ì‹œì‘ (Quick Start)

### 1. í™˜ê²½ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << EOF
OPENAI_API_KEY=sk-...your-key-here...
TAVILY_API_KEY=tvly-...your-key-here...
EOF
```

### 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 3. ì‹œìŠ¤í…œ ì‹¤í–‰

```bash
python advanced_main.py
```

ë©”ë‰´ì—ì„œ ì„ íƒ:
- `1`: ì˜ˆì‹œ ì§ˆë¬¸ ì‹¤í–‰ (ë°ëª¨)
- `2`: ëŒ€í™”í˜• ëª¨ë“œ (ì¼ë°˜ ì‚¬ìš©)
- `3`: ë°°ì¹˜ ì²˜ë¦¬ (íŒŒì¼ ê¸°ë°˜)
- `4`: ì¢…ë£Œ

---

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°€ì´ë“œ

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë‹¨ìˆœ ì˜ë£Œ ì§ˆë¬¸

**ëª©í‘œ**: ê°œì˜ í”¼ë¶€ì—¼ ì¦ìƒì— ëŒ€í•´ ì•Œì•„ë³´ê¸°

```
ì…ë ¥: "ê°œì˜ í”¼ë¶€ì—¼ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?"

ì‹œìŠ¤í…œ ì²˜ë¦¬:
1. ì§ˆë¬¸ ë¶„ë¥˜ â†’ Type A (ì˜ë£Œ ì§ˆë¬¸)
2. ë‚´ë¶€ Chroma ê²€ìƒ‰ â†’ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰
3. ê·¼ê±° í‰ê°€ â†’ ì ìˆ˜: 0.85 (ì¶©ë¶„í•¨)
4. RAG ë‹µë³€ ìƒì„±

ì¶œë ¥:
- ì¦ìƒ ì •ë³´
- ê·¼ê±° ì ìˆ˜ (85%)
- ì¶œì²˜ ëª…ì‹œ
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë³µí•© ì˜ë£Œ ì§ˆë¬¸

**ëª©í‘œ**: ë‚´ë¶€ ì •ë³´ê°€ ë¶€ì¡±í•œ íŠ¹ìˆ˜ ì§ˆí™˜ì— ëŒ€í•´ ì•Œì•„ë³´ê¸°

```
ì…ë ¥: "ë°˜ë ¤ë™ë¬¼ì˜ ë“œë¬¸ ìœ ì „ì§ˆí™˜ ì¹˜ë£Œë²•ì€?"

ì‹œìŠ¤í…œ ì²˜ë¦¬:
1. ì§ˆë¬¸ ë¶„ë¥˜ â†’ Type A (ì˜ë£Œ)
2. ë‚´ë¶€ ê²€ìƒ‰ â†’ ê²°ê³¼ ë¶€ì¡±
3. ê·¼ê±° í‰ê°€ â†’ ì ìˆ˜: 0.45 (ë¶€ì¡±)
4. ì›¹ ê²€ìƒ‰ ìë™ ìˆ˜í–‰
5. í†µí•© RAG ë‹µë³€ ìƒì„±

ì¶œë ¥:
- ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨
- ê·¼ê±° ì ìˆ˜ í‘œì‹œ (0.45 â†’ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰í•¨)
- í˜¼í•©ëœ ì¶œì²˜ í‘œì‹œ
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë³‘ì› ê²€ìƒ‰

**ëª©í‘œ**: íŠ¹ì • ì§€ì—­ì˜ ë™ë¬¼ë³‘ì› ì°¾ê¸°

```
ì…ë ¥: "ê°•ë‚¨êµ¬ ë™ë¬¼ë³‘ì›ì„ ì°¾ì•„ì£¼ì„¸ìš”."

ì‹œìŠ¤í…œ ì²˜ë¦¬:
1. ì§ˆë¬¸ ë¶„ë¥˜ â†’ Type B (ë³‘ì›)
2. ì •ê·œì‹ìœ¼ë¡œ "ê°•ë‚¨êµ¬" ì¶”ì¶œ
3. CSVì—ì„œ í•„í„°ë§
4. ë³‘ì› ì •ë³´ ì •ë ¬ ë° ì œê³µ

ì¶œë ¥:
êµ¬ë³„ ë³‘ì› ì •ë³´:
- ê°•ë‚¨êµ¬: 387ê°œ ë³‘ì› (ìƒìœ„ 10ê°œ í‘œì‹œ)
- ì „í™”, ì£¼ì†Œ í¬í•¨
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 4: ì¼ë°˜ ì§ˆë¬¸

**ëª©í‘œ**: ë°˜ë ¤ë™ë¬¼ ì–‘ìœ¡ íŒ ì–»ê¸°

```
ì…ë ¥: "ë°˜ë ¤ë™ë¬¼ì„ ì²˜ìŒ í‚¤ìš°ëŠ”ë° ë­˜ ì¤€ë¹„í•´ì•¼ í•˜ë‚˜ìš”?"

ì‹œìŠ¤í…œ ì²˜ë¦¬:
1. ì§ˆë¬¸ ë¶„ë¥˜ â†’ Type C (ì¼ë°˜)
2. LLM ì§ì ‘ í˜¸ì¶œ
3. ë‹µë³€ ìƒì„±

ì¶œë ¥:
- ì¤€ë¹„ë¬¼ ëª©ë¡
- ì¼€ì–´ íŒ
- ë¹„ìš© ì •ë³´
```

---

## Python API ì§ì ‘ ì‚¬ìš©

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from src.advanced_rag_pipeline import AdvancedRAGPipeline
from src.embeddings import get_embedding_model, load_vectorstore

# 1. ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
embedding_model = get_embedding_model("openai")
vectorstore = load_vectorstore(
    embedding_model,
    persist_directory="./chroma_db",
    collection_name="rag_collection"
)

# 2. íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
pipeline = AdvancedRAGPipeline(vectorstore)

# 3. ì§ˆë¬¸ ì²˜ë¦¬
result = pipeline.process_question("ê°œì˜ í”¼ë¶€ì—¼ ì¦ìƒì€?")

# 4. ê²°ê³¼ ì ‘ê·¼
print(f"ì§ˆë¬¸: {result['question']}")
print(f"ë¶„ë¥˜: {result['classification_type']}")  # A, B, C
print(f"ì‹ ë¢°ë„: {result['classification_confidence']:.1%}")
print(f"\në‹µë³€:\n{result['formatted_answer']}")
```

### ë°°ì¹˜ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì§ˆë¬¸ í•œ ë²ˆì— ì²˜ë¦¬
questions = [
    "ê°œì˜ í”¼ë¶€ì—¼ ì¦ìƒì€?",
    "ê°•ë‚¨êµ¬ ë™ë¬¼ë³‘ì›",
    "ë°˜ë ¤ë™ë¬¼ ì–‘ìœ¡ë²•",
]

results = pipeline.batch_process_questions(questions)

# ê²°ê³¼ ì €ì¥
pipeline.save_results(results, "my_results.json")
```

### ê° ëª¨ë“ˆ ì§ì ‘ ì‚¬ìš©

#### ì§ˆë¬¸ ë¶„ë¥˜ë§Œ ì‚¬ìš©

```python
from src.question_classifier import QuestionClassifier

classifier = QuestionClassifier()
question_type, confidence, reason = classifier.classify("ê°œì˜ í”¼ë¶€ì—¼?")

print(f"Type: {question_type.name}")  # MEDICAL
print(f"Confidence: {confidence:.1%}")
print(f"Reason: {reason}")
```

#### ì˜ë£Œ ì§ˆë¬¸ë§Œ ì²˜ë¦¬

```python
from src.medical_qa_handler import MedicalQAHandler

handler = MedicalQAHandler(vectorstore, score_threshold=0.6)
result = handler.handle_medical_question("ê°œì˜ í”¼ë¶€ì—¼ ì¦ìƒ?")

print(f"Relevance Score: {result['relevance_score']:.1%}")
print(f"Web Search Used: {result['used_web_search']}")
print(f"Answer: {result['answer']}")
```

#### ë³‘ì› ê²€ìƒ‰ë§Œ ì‚¬ìš©

```python
from src.hospital_handler import HospitalHandler

handler = HospitalHandler()

# ì§€ì—­ë³„ ê²€ìƒ‰
hospitals = handler.search_by_location("ê°•ë‚¨êµ¬")
for h in hospitals[:5]:
    print(f"{h['name']}: {h['phone']}")

# í†µê³„
stats = handler.get_statistics()
print(f"ì´ ë³‘ì›: {stats['total_hospitals']}")
for district, count in stats['top_districts'][:5]:
    print(f"  {district}: {count}")
```

---

## ê²°ê³¼ í•´ì„

### Type A (ì˜ë£Œ ì§ˆë¬¸) ê²°ê³¼

```python
{
    'classification_type': 'MEDICAL',
    'classification_confidence': 0.92,  # 92% í™•ì‹ 
    'relevance_score': 0.78,            # 78% ê·¼ê±° ì¶©ë¶„
    'internal_search_results': 5,       # 5ê°œ ë¬¸ì„œ ê²€ìƒ‰
    'web_search_results': 0,            # ì›¹ ê²€ìƒ‰ ë¯¸ìˆ˜í–‰
    'used_web_search': False,
    'answer': '...',                    # ë‹µë³€ ë‚´ìš©
    'sources': [
        {
            'metadata': {
                'file_name': 'disease_001.json',
                'department': 'í”¼ë¶€ê³¼',
                'title': 'í”¼ë¶€ì—¼'
            },
            'relevance_score': 0.95      # 95% ê´€ë ¨ì„±
        },
        ...
    ]
}
```

**í•´ì„**:
- âœ… ë†’ì€ ì‹ ë¢°ë„ (92%)
- âœ… ì¶©ë¶„í•œ ê·¼ê±° (78% > 60% threshold)
- âœ… ë‚´ë¶€ ë°ì´í„°ë¡œë§Œ ë‹µë³€ ê°€ëŠ¥
- âœ… ì¶œì²˜ì™€ ê·¼ê±° ëª…ì‹œë¨

---

### Type B (ë³‘ì› ì§ˆë¬¸) ê²°ê³¼

```python
{
    'classification_type': 'HOSPITAL',
    'classification_confidence': 0.88,
    'hospitals': [
        {
            'name': 'ê°•ë‚¨ë™ë¬¼ë³‘ì›',
            'address': 'ì„œìš¸ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123',
            'phone': '02-1234-5678',
            'district': 'ê°•ë‚¨êµ¬',
            'status': 'ì •ìƒ',
            'business_type': 'ê°œì¸ë™ë¬¼ì˜ë£Œ'
        },
        ...
    ],
    'statistics': {
        'total_hospitals': 5287,
        'top_districts': [
            ('ê°•ë‚¨êµ¬', 387),
            ('ì„œì´ˆêµ¬', 342),
            ...
        ]
    },
    'response': '...'  # í¬ë§·ëœ í…ìŠ¤íŠ¸
}
```

**í•´ì„**:
- âœ… 87ê°œ ë³‘ì› ê²€ìƒ‰
- âœ… ìƒì„¸ ì •ë³´ í¬í•¨
- âœ… í†µê³„ ì •ë³´ ì œê³µ

---

### Type C (ì¼ë°˜ ì§ˆë¬¸) ê²°ê³¼

```python
{
    'classification_type': 'GENERAL',
    'classification_confidence': 0.88,
    'answer': '...',  # LLM ë‹µë³€
    'sources': [],     # ì™¸ë¶€ ê²€ì¦ ì—†ìŒ
    'used_external_search': False
}
```

**í•´ì„**:
- â„¹ï¸ ì™¸ë¶€ ë°ì´í„° ê²€ì¦ ì—†ìŒ
- â„¹ï¸ LLM ëª¨ë¸ì˜ í›ˆë ¨ ë°ì´í„° ê¸°ë°˜

---

## ë””ë²„ê¹… ë° ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: "OPENAI_API_KEY not found"

**ì›ì¸**: API í‚¤ ë¯¸ì„¤ì •

**í•´ê²°**:
```bash
# .env íŒŒì¼ í™•ì¸
cat .env

# ë˜ëŠ” ì§ì ‘ ì„¤ì •
export OPENAI_API_KEY=sk-...
# Windows PowerShell
$env:OPENAI_API_KEY="sk-..."
```

---

### ë¬¸ì œ 2: "Chroma database not found"

**ì›ì¸**: ë²¡í„°ìŠ¤í† ì–´ ë¯¸ìƒì„±

**í•´ê²°**:
```bash
# ì˜ˆì‹œ ì¿¼ë¦¬ ì‹¤í–‰ (ë²¡í„°ìŠ¤í† ì–´ ìë™ ìƒì„±)
python advanced_main.py  # ë©”ë‰´: 1ë²ˆ
```

---

### ë¬¸ì œ 3: ëŠë¦° ì‘ë‹µ ì†ë„

**ì›ì¸**: 
- ì²« ì‹¤í–‰ (ì„ë² ë”© ìƒì„± ì¤‘)
- í° ë°ì´í„°ì…‹
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°

**í•´ê²°**:
- ì²« ì‹¤í–‰ í›„ì—ëŠ” ë¹ ë¦„
- ë°°ì¹˜ ì²˜ë¦¬ ì‚¬ìš©
- ìºì‹± í™œìš©

---

### ë¬¸ì œ 4: ì •í™•í•˜ì§€ ì•Šì€ ë‹µë³€

**ì˜ë£Œ ì§ˆë¬¸**:
- ë‚´ë¶€ ë°ì´í„° ë¶€ì¡± â†’ ì›¹ ê²€ìƒ‰ í™œìš©
- ê´€ë ¨ì„± ì ìˆ˜ ë‚®ìŒ â†’ ì„ê³„ê°’ ì¡°ì •

```python
# ì„ê³„ê°’ ì¡°ì • (ê¸°ë³¸ê°’: 0.6)
handler = MedicalQAHandler(
    vectorstore,
    score_threshold=0.5  # ë” ë‚®ì€ ê¸°ì¤€
)
```

**ë³‘ì› ì§ˆë¬¸**:
- ì •í™•í•œ ì§€ì—­ëª… ì‚¬ìš© (ì˜ˆ: "ê°•ë‚¨êµ¬" not "ê°•ë‚¨")

**ì¼ë°˜ ì§ˆë¬¸**:
- ëª…í™•í•œ ì§ˆë¬¸ ì‘ì„±
- ì»¨í…ìŠ¤íŠ¸ ì œê³µ

---

## ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ì»¤ìŠ¤í…€ í•„í„° ì ìš©

```python
# Type B: ë³‘ì› ë°ì´í„° ì»¤ìŠ¤í…€ í•„í„°
from src.hospital_handler import HospitalHandler

handler = HospitalHandler()

# íŠ¹ì • ìƒíƒœì˜ ë³‘ì›ë§Œ ê²€ìƒ‰
all_hospitals = handler.search_by_location("ê°•ë‚¨êµ¬")
active_hospitals = [h for h in all_hospitals 
                    if h['status'] == 'ì •ìƒ']

print(f"í™œì„± ë³‘ì›: {len(active_hospitals)}ê°œ")
```

### 2. ì ìˆ˜ ê¸°ë°˜ ê²°ê³¼ ì •ë ¬

```python
# Type A: ê´€ë ¨ì„± ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
result = pipeline.process_question("ê°œ í”¼ë¶€ì—¼?")

sorted_sources = sorted(
    result['sources'],
    key=lambda x: x['relevance_score'],
    reverse=True
)

print("ê´€ë ¨ì„± ìˆœì„œ:")
for i, source in enumerate(sorted_sources, 1):
    score = source['relevance_score']
    print(f"{i}. ({score:.0%}) {source['metadata']['title']}")
```

### 3. ì‹ ë¢°ë„ ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬

```python
result = pipeline.process_question("ê°œ í”¼ë¶€ì—¼?")

if result['classification_confidence'] >= 0.9:
    print("âœ… ë†’ì€ ì‹ ë¢°ë„ ë¶„ë¥˜")
    process_with_high_priority(result)
elif result['classification_confidence'] >= 0.7:
    print("âš ï¸ ì¤‘ê°„ ì‹ ë¢°ë„ ë¶„ë¥˜")
    process_with_normal_priority(result)
else:
    print("â“ ë‚®ì€ ì‹ ë¢°ë„ ë¶„ë¥˜ - ì¬í™•ì¸ í•„ìš”")
    process_with_verification(result)
```

### 4. ë©€í‹°í„´ ì²˜ë¦¬

```python
# ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€ (ìˆ˜ë™ êµ¬í˜„)
conversation = []

while True:
    user_input = input("ì§ˆë¬¸: ")
    
    # ì´ì „ ë§¥ë½ í¬í•¨
    context = "\n".join([f"Q: {c['q']}\nA: {c['a']}" 
                         for c in conversation])
    
    full_query = f"{context}\n\nQ: {user_input}"
    
    result = pipeline.process_question(full_query)
    
    # íˆìŠ¤í† ë¦¬ ì €ì¥
    conversation.append({
        'q': user_input,
        'a': result['answer']
    })
    
    print(f"A: {result['answer']}\n")
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹± í™œìš©

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_search(query):
    return pipeline.process_question(query)

# ë™ì¼ ì§ˆë¬¸ ì¬ì¡°íšŒì‹œ ìºì‹œ ì‚¬ìš©
result1 = cached_search("ê°œ í”¼ë¶€ì—¼?")
result2 = cached_search("ê°œ í”¼ë¶€ì—¼?")  # ìºì‹œì—ì„œ ë°˜í™˜
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ í™œìš©

```python
# ì—¬ëŸ¬ ì§ˆë¬¸ í•œ ë²ˆì— ì²˜ë¦¬
questions = load_questions_from_file("questions.txt")

# ìˆœì°¨ ì²˜ë¦¬ (ëŠë¦¼)
# results = [pipeline.process_question(q) for q in questions]

# ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)
results = pipeline.batch_process_questions(questions)
```

### 3. íƒ€ì…ë³„ í•¸ë“¤ëŸ¬ë§Œ ì‚¬ìš©

```python
# ì˜ë£Œ ì§ˆë¬¸ë§Œ ì²˜ë¦¬í•˜ëŠ” ê²½ìš°
handler = MedicalQAHandler(vectorstore)

# ë¶„ë¥˜ ì˜¤ë²„í—¤ë“œ ì œê±°
result = handler.handle_medical_question(query)
```

---

## ì¶œë ¥ í˜•ì‹ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### JSON í˜•ì‹

```python
import json

result = pipeline.process_question("ê°œ í”¼ë¶€ì—¼?")
json_output = json.dumps(result, ensure_ascii=False, indent=2)
print(json_output)
```

### CSV í˜•ì‹

```python
import csv

results = pipeline.batch_process_questions(questions)

with open("results.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["Question", "Type", "Confidence", "Answer"])
    
    for r in results:
        writer.writerow([
            r['question'],
            r['classification_type'],
            f"{r['classification_confidence']:.1%}",
            r['answer'][:100]  # ì²˜ìŒ 100ì
        ])
```

### HTML ë¦¬í¬íŠ¸

```python
html_template = """
<html>
<body>
<h1>ë°˜ë ¤ë™ë¬¼ QA ê²°ê³¼</h1>
{results_html}
</body>
</html>
"""

results_html = ""
for result in results:
    results_html += f"""
    <div>
        <h3>{result['question']}</h3>
        <p><strong>ë¶„ë¥˜:</strong> {result['classification_type']}</p>
        <p><strong>ì‹ ë¢°ë„:</strong> {result['classification_confidence']:.1%}</p>
        <p><strong>ë‹µë³€:</strong> {result['answer']}</p>
    </div>
    """

with open("results.html", "w") as f:
    f.write(html_template.format(results_html=results_html))
```

---

## FAQ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸)

**Q: ì›¹ ê²€ìƒ‰ì€ í•­ìƒ ìˆ˜í–‰ë˜ë‚˜ìš”?**
A: ì•„ë‹ˆìš”. Type A ì˜ë£Œ ì§ˆë¬¸ì—ì„œ ê·¼ê±° ì ìˆ˜ê°€ 0.6 ì´ìƒì´ë©´ ë‚´ë¶€ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

**Q: ë‹µë³€ì´ í‹€ë¦´ ìˆ˜ ìˆë‚˜ìš”?**
A: ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹íˆ ë‚´ë¶€ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì›¹ ê²€ìƒ‰ì„ í™œìš©í•˜ë©°, í•­ìƒ ì˜ë£Œ ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

**Q: ë³‘ì› ì •ë³´ëŠ” ì–¼ë§ˆë‚˜ ìµœì‹ ì¸ê°€ìš”?**
A: í˜„ì¬ ë°ì´í„°ëŠ” ì„œìš¸ì‹œ ê³µì‹ ì •ë³´ ê¸°ë°˜ì…ë‹ˆë‹¤. ì •ê¸°ì  ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.

**Q: ë¹„ìš©ì´ ë“¤ë‚˜ìš”?**
A: OpenAI API ì‚¬ìš©ë£Œê°€ ë°œìƒí•©ë‹ˆë‹¤. (ì•½ $0.02-0.10/ì§ˆë¬¸)

**Q: ë¡œì»¬ì—ì„œë§Œ ì‹¤í–‰ë˜ë‚˜ìš”?**
A: ë²¡í„°ìŠ¤í† ì–´ëŠ” ë¡œì»¬ì´ì§€ë§Œ LLMì€ í´ë¼ìš°ë“œ(OpenAI)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025ë…„ 12ì›” 3ì¼

