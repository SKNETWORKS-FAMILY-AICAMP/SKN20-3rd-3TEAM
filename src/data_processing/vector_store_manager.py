"""
Vector Store Manager Module
ì„ë² ë”© ìƒì„± ë° ë²¡í„° DB ê´€ë¦¬

ì—­í• :
  - ì²­í¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
  - ë²¡í„°ë¥¼ DBì— ì¸ë±ì‹± ë° ì €ì¥
  - ê²€ìƒ‰ ì‹œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
  - DB ìƒëª…ì£¼ê¸° ê´€ë¦¬ (ìƒì„±, ì—…ë°ì´íŠ¸, ì‚­ì œ)
"""

import os
import time
from typing import List, Dict, Tuple, Optional
import hashlib
import warnings
warnings.filterwarnings("ignore")

from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document

load_dotenv()

# API í‚¤ í™•ì¸
if not os.environ.get('OPENAI_API_KEY'):
    raise ValueError('.env í™•ì¸í•˜ì„¸ìš”. OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤')


class VectorStoreManager:
    """
    ë²¡í„° ì €ì¥ì†Œë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    
    ì±…ì„:
        1. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        2. ì²­í¬ í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
        3. ë²¡í„° DB ê´€ë¦¬
        4. ìœ ì‚¬ë„ ê²€ìƒ‰
    """
    
    def __init__(
        self, 
        collection_name: str = "pet_health_qa_system",
        persist_directory: str = "./chroma_db",
        embedding_model: str = "text-embedding-3-small"
    ):
        """
        VectorStoreManager ì´ˆê¸°í™”
        
        Args:
            collection_name: Chroma ì»¬ë ‰ì…˜ ì´ë¦„
            persist_directory: ë²¡í„° DB ì €ì¥ ê²½ë¡œ
            embedding_model: OpenAI ì„ë² ë”© ëª¨ë¸ëª…
        """
        self.collection_name = collection_name
        self.persist_directory = persist_directory
        self.embedding_function = OpenAIEmbeddings(model=embedding_model)
        self.vector_db = None
        
        print(f"âœ“ [VectorStoreManager] ì´ˆê¸°í™” ì™„ë£Œ: {collection_name}")
    
    
    def create_vectorstore(self, documents: List[Document], batch_size: int = 100) -> bool:
        """
        ë¬¸ì„œë“¤ë¡œë¶€í„° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        
        Args:
            documents: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"\në²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘: {len(documents)}ê°œ ë¬¸ì„œ")
            
            # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            first_batch = documents[:batch_size]
            
            self.vector_db = Chroma.from_documents(
                documents=first_batch,
                embedding=self.embedding_function,
                collection_name=self.collection_name,
                persist_directory=self.persist_directory,
            )
            
            print(f"ì²« ë²ˆì§¸ ë°°ì¹˜ ì™„ë£Œ: {len(first_batch)}ê°œ ë¬¸ì„œ")
            
            # ë‚˜ë¨¸ì§€ ë¬¸ì„œë“¤ì„ ë°°ì¹˜ë¡œ ì¶”ê°€
            remaining_docs = documents[batch_size:]
            total_batches = len(remaining_docs) // batch_size + (1 if len(remaining_docs) % batch_size > 0 else 0)
            
            for i in range(0, len(remaining_docs), batch_size):
                batch_num = i // batch_size + 2
                batch = remaining_docs[i:i + batch_size]
                
                print(f"ë°°ì¹˜ {batch_num}/{total_batches + 1} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")
                
                try:
                    self.vector_db.add_documents(batch)
                    print(f"ë°°ì¹˜ {batch_num} ì™„ë£Œ!")
                    time.sleep(1)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€
                    
                except Exception as e:
                    print(f"ë°°ì¹˜ {batch_num} ì—ëŸ¬: {e}")
                    # ë” ì‘ì€ ë°°ì¹˜ë¡œ ì¬ì‹œë„
                    smaller_batches = [batch[j:j+20] for j in range(0, len(batch), 20)]
                    for small_batch in smaller_batches:
                        try:
                            self.vector_db.add_documents(small_batch)
                            time.sleep(0.5)
                        except Exception as small_e:
                            print(f"ì†Œ ë°°ì¹˜ ì—ëŸ¬: {small_e}")
            
            print("ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
            print(f"ì €ì¥ ê²½ë¡œ: {self.persist_directory}")
            print(f"ì»¬ë ‰ì…˜ëª…: {self.collection_name}")
            return True
            
        except Exception as e:
            print(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    
    def load_vectorstore(self) -> bool:
        """
        ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.vector_db = Chroma(
                persist_directory=self.persist_directory,
                collection_name=self.collection_name,
                embedding_function=self.embedding_function
            )
            print(f"âœ“ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ: {self.collection_name}")
            return True
        except Exception as e:
            print(f"ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    
    def embed_and_index_chunks(self, chunks: List[Document]) -> bool:
        """
        ì—¬ëŸ¬ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  ë²¡í„° DBì— ì¸ë±ì‹±
        
        Args:
            chunks: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        return self.create_vectorstore(chunks)
    
    
    def get_retriever(self, search_type: str = "similarity", k: int = 5):
        """
        ë¦¬íŠ¸ë¦¬ë²„ ê°ì²´ ë°˜í™˜
        
        Args:
            search_type: ê²€ìƒ‰ íƒ€ì… (similarity, mmr ë“±)
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            Retriever ê°ì²´
        """
        if self.vector_db is None:
            if not self.load_vectorstore():
                raise ValueError("ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return self.vector_db.as_retriever(
            search_type=search_type,
            search_kwargs={"k": k}
        )
    
    
    def search_similar_chunks(
        self,
        query: str,
        top_k: int = 5,
        threshold: float = 0.5
    ) -> List[Document]:
        """
        ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ Kê°œ ê²°ê³¼
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ì‚¬ìš© ì•ˆ í•¨)
        
        Returns:
            List[Document]: ê²€ìƒ‰ëœ Document ë¦¬ìŠ¤íŠ¸
        """
        if self.vector_db is None:
            if not self.load_vectorstore():
                return []
        
        print(f"ğŸ” [search_similar_chunks] ìœ ì‚¬ë„ ê²€ìƒ‰: '{query}' (top_k={top_k})")
        
        try:
            results = self.vector_db.similarity_search(query, k=top_k)
            print(f"âœ“ {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
            return results
        except Exception as e:
            print(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    
    def delete_chunk_by_id(self, chunk_id: str) -> bool:
        """
        íŠ¹ì • IDì˜ ì²­í¬ ì‚­ì œ
        
        Args:
            chunk_id (str): ì‚­ì œí•  ì²­í¬ì˜ ê³ ìœ  ID
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        
        TODO:
            - self.vector_db.delete([chunk_id])
        """
        print(f"ğŸ—‘ï¸  [delete_chunk_by_id] ì²­í¬ ì‚­ì œ: {chunk_id}")
        return True
    
    
    def clear_collection(self) -> bool:
        """
        ì „ì²´ ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        
        Args:
            (ì—†ìŒ)
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        
        ì£¼ì˜: ì´ ì‘ì—…ì€ ëŒì´í‚¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!
        
        TODO:
            - self.vector_db.delete_collection(self.collection_name)
            - ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ ì¬ìƒì„±
        """
        print(f"âš ï¸  [clear_collection] ì»¬ë ‰ì…˜ ì´ˆê¸°í™”: {self.collection_name}")
        return True
    
    
    def get_stats(self) -> Dict[str, any]:
        """
        ë²¡í„° DB í†µê³„ ì¡°íšŒ
        
        Returns:
            Dict: DB í†µê³„ ì •ë³´
                {
                    'total_chunks': 0,
                    'embedding_model': 'model_name',
                    'embedding_dim': 768,
                    'collection_name': 'name',
                    'last_updated': '2025-12-05 10:30:00'
                }
        
        TODO:
            - self.vector_db.get_collection(self.collection_name).count()
        """
        stats = {
            'total_chunks': 0,
            'embedding_model': self.model_name,
            'embedding_dim': self.embedding_dim,
            'collection_name': self.collection_name,
            'status': 'initialized'
        }
        
        print(f"ğŸ“Š [get_stats] DB í†µê³„: {stats}")
        return stats


def embed_and_index_chunks(chunks: List[str]) -> bool:
    """
    ëª¨ë“ˆ ìˆ˜ì¤€ í•¨ìˆ˜: ì²­í¬ ì„ë² ë”© ë° ì¸ë±ì‹±
    
    Args:
        chunks (List[str]): ì¸ë±ì‹±í•  í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    
    ì—­í• :
        - VectorStoreManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        - ì²­í¬ ì„ë² ë”© ë° DB ì €ì¥
        - ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
    
    TODO:
        - ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ manager ê´€ë¦¬
        - ë˜ëŠ” ì „ì—­ manager ê°ì²´ ì‚¬ìš©
    """
    print("\n" + "="*60)
    print("ğŸ”„ [embed_and_index_chunks] ì²­í¬ ì„ë² ë”© ë° ì¸ë±ì‹±")
    print("="*60 + "\n")
    
    # VectorStoreManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    manager = VectorStoreManager()
    
    # ì²­í¬ ì„ë² ë”© ë° ì¸ë±ì‹±
    success = manager.embed_and_index_chunks(chunks)
    
    print("="*60)
    if success:
        print("âœ… ì„ë² ë”© ë° ì¸ë±ì‹± ì™„ë£Œ")
    else:
        print("âŒ ì„ë² ë”© ë° ì¸ë±ì‹± ì‹¤íŒ¨")
    print("="*60 + "\n")
    
    return success


# ==================== ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ ====================
if __name__ == "__main__":
    """
    í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìŠ¤ì¼ˆë ˆí†¤ ë°ëª¨)
    """
    
    print("\n" + "="*60)
    print("ğŸ“¦ Vector Store Manager Module - í…ŒìŠ¤íŠ¸")
    print("="*60 + "\n")
    
    # í…ŒìŠ¤íŠ¸ 1: VectorStoreManager ì´ˆê¸°í™”
    print("### í…ŒìŠ¤íŠ¸ 1: VectorStoreManager ì´ˆê¸°í™” ###\n")
    manager = VectorStoreManager()
    stats = manager.get_stats()
    print(f"âœ“ ì´ˆê¸°í™” ì™„ë£Œ: {stats}\n")
    
    # í…ŒìŠ¤íŠ¸ 2: ë‹¨ì¼ ì²­í¬ ì„ë² ë”©
    print("### í…ŒìŠ¤íŠ¸ 2: ë‹¨ì¼ ì²­í¬ ì„ë² ë”© ###\n")
    sample_chunk = "ê°•ì•„ì§€ í”¼ë¶€ì—¼ì€ ê°€ë ¤ì›€ì¦ì„ ìœ ë°œí•©ë‹ˆë‹¤"
    embedding = manager.embed_chunk(sample_chunk)
    print(f"âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ (í¬ê¸°: {len(embedding)})\n")
    
    # í…ŒìŠ¤íŠ¸ 3: ë°°ì¹˜ ì„ë² ë”© ë° ì¸ë±ì‹±
    print("### í…ŒìŠ¤íŠ¸ 3: ë°°ì¹˜ ì„ë² ë”© ë° ì¸ë±ì‹± ###\n")
    test_chunks = [
        "ê°•ì•„ì§€ í”¼ë¶€ì—¼ ì¦ìƒ",
        "ì¹˜ë£Œ ë°©ë²• ì•ˆë‚´",
        "ë³‘ì› ë°©ë¬¸ ê°€ì´ë“œ"
    ]
    success = manager.embed_and_index_chunks(test_chunks)
    print(f"âœ“ ì¸ë±ì‹± ê²°ê³¼: {success}\n")
    
    # í…ŒìŠ¤íŠ¸ 4: ìœ ì‚¬ë„ ê²€ìƒ‰
    print("### í…ŒìŠ¤íŠ¸ 4: ìœ ì‚¬ë„ ê²€ìƒ‰ ###\n")
    search_results = manager.search_similar_chunks("í”¼ë¶€ ì§ˆí™˜ ì¹˜ë£Œ", top_k=3)
    print(f"âœ“ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼\n")
    
    # í…ŒìŠ¤íŠ¸ 5: ëª¨ë“ˆ ìˆ˜ì¤€ í•¨ìˆ˜
    print("### í…ŒìŠ¤íŠ¸ 5: ëª¨ë“ˆ ìˆ˜ì¤€ í•¨ìˆ˜ ###\n")
    test_chunks_2 = ["ì²­í¬1", "ì²­í¬2", "ì²­í¬3"]
    embed_and_index_chunks(test_chunks_2)
    
    print("="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*60)

