"""
ë²¡í„°ìŠ¤í† ì–´ ê´€ë¦¬ ëª¨ë“ˆ
ê¸°ì¡´ vectorstore.pyë¥¼ í´ë˜ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë¦¬íŒ©í† ë§
"""

import os
import time
import warnings
from typing import List
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document

warnings.filterwarnings("ignore")
load_dotenv()


class VectorStoreManager:
    """ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        collection_name: str = "pet_health_qa_system",
        persist_directory: str = "./chroma_db",
        embedding_model: str = "text-embedding-3-small",
        batch_size: int = 500
    ):
        """
        Args:
            collection_name: Chroma ì»¬ë ‰ì…˜ ì´ë¦„
            persist_directory: ë²¡í„° DB ì €ì¥ ê²½ë¡œ
            embedding_model: OpenAI ì„ë² ë”© ëª¨ë¸
            batch_size: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
        """
        if not os.environ.get('OPENAI_API_KEY'):
            raise ValueError('.env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”')
            
        self.collection_name = collection_name
        self.persist_directory = persist_directory
        self.batch_size = batch_size
        self.embedding_function = OpenAIEmbeddings(model=embedding_model)
        self.vectorstore = None
        
        print(f"âœ“ VectorStoreManager ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  - ì»¬ë ‰ì…˜: {collection_name}")
        print(f"  - ì €ì¥ ê²½ë¡œ: {persist_directory}")
        print(f"  - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    
    def create_vectorstore(self, documents: List[Document]) -> bool:
        """
        ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        
        Args:
            documents: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"\n{'='*60}")
            print(f"ğŸš€ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘: {len(documents)}ê°œ ë¬¸ì„œ")
            print(f"{'='*60}\n")
            
            # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            first_batch = documents[:self.batch_size]
            
            self.vectorstore = Chroma.from_documents(
                documents=first_batch,
                embedding=self.embedding_function,
                collection_name=self.collection_name,
                persist_directory=self.persist_directory,
            )
            
            print(f"âœ“ ì²« ë²ˆì§¸ ë°°ì¹˜ ì™„ë£Œ: {len(first_batch)}ê°œ ë¬¸ì„œ")
            
            # ë‚˜ë¨¸ì§€ ë¬¸ì„œë“¤ì„ ë°°ì¹˜ë¡œ ì¶”ê°€
            remaining_docs = documents[self.batch_size:]
            total_batches = len(remaining_docs) // self.batch_size + \
                           (1 if len(remaining_docs) % self.batch_size > 0 else 0)
            
            for i in range(0, len(remaining_docs), self.batch_size):
                batch_num = i // self.batch_size + 2
                batch = remaining_docs[i:i + self.batch_size]
                
                print(f"ë°°ì¹˜ {batch_num}/{total_batches + 1} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")
                
                try:
                    self.vectorstore.add_documents(batch)
                    print(f"âœ“ ë°°ì¹˜ {batch_num} ì™„ë£Œ!")
                    time.sleep(1)  # API ì œí•œ ë°©ì§€
                    
                except Exception as e:
                    print(f"âš ï¸ ë°°ì¹˜ {batch_num} ì—ëŸ¬: {e}")
                    # ë” ì‘ì€ ë°°ì¹˜ë¡œ ì¬ì‹œë„
                    smaller_batches = [batch[j:j+20] for j in range(0, len(batch), 20)]
                    for small_batch in smaller_batches:
                        try:
                            self.vectorstore.add_documents(small_batch)
                            time.sleep(0.5)
                        except Exception as small_e:
                            print(f"âš ï¸ ì†Œ ë°°ì¹˜ ì—ëŸ¬: {small_e}")
            
            print(f"\n{'='*60}")
            print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
            print(f"  - ì €ì¥ ê²½ë¡œ: {self.persist_directory}")
            print(f"  - ì»¬ë ‰ì…˜ëª…: {self.collection_name}")
            print(f"{'='*60}\n")
            return True
            
        except Exception as e:
            print(f"\nâŒ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def load_vectorstore(self) -> bool:
        """
        ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                collection_name=self.collection_name,
                embedding_function=self.embedding_function
            )
            print(f"âœ“ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ: {self.collection_name}")
            return True
        except Exception as e:
            print(f"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def get_retriever(self, k: int = 5, search_type: str = "similarity"):
        """
        ë¦¬íŠ¸ë¦¬ë²„ ë°˜í™˜
        
        Args:
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
            search_type: ê²€ìƒ‰ íƒ€ì… ("similarity", "mmr", "similarity_score_threshold")
            
        Returns:
            Retriever ê°ì²´
        """
        if self.vectorstore is None:
            if not self.load_vectorstore():
                raise ValueError("ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return self.vectorstore.as_retriever(
            search_type=search_type,
            search_kwargs={"k": k}
        )
    
    def similarity_search(self, query: str, k: int = 5) -> List[Document]:
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            Document ë¦¬ìŠ¤íŠ¸
        """
        if self.vectorstore is None:
            if not self.load_vectorstore():
                return []
        
        try:
            results = self.vectorstore.similarity_search(query, k=k)
            return results
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    import pickle
    
    # ì „ì²˜ë¦¬ëœ ë¬¸ì„œ ë¡œë“œ
    with open("chunked_docs.pkl", "rb") as f:
        docs = pickle.load(f)
    
    # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    manager = VectorStoreManager(batch_size=500)
    manager.create_vectorstore(docs)
