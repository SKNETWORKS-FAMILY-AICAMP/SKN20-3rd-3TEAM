"""
Main Workflow Module
ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Orchestration)

ì—­í• :
  - 8ê°œ í•µì‹¬ ëª¨ë“ˆ í†µí•© ì¡°í•©
  - ì—”ë“œ-íˆ¬-ì—”ë“œ ì¿¼ë¦¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
  - ìƒ‰ì¸ êµ¬ì¶• ì›Œí¬í”Œë¡œìš° (indexing_workflow)
  - ì¿¼ë¦¬ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° (main_workflow)
  - ë°°ì¹˜ ì²˜ë¦¬ (batch_workflow)
"""

import time
from typing import Dict, List, Literal

# ==================== ëª¨ë“ˆ ì„í¬íŠ¸ ====================
# ë¬¸ì„œ ì²˜ë¦¬
from data_processing import preprocess_document, batch_preprocess_documents
from data_processing import embed_and_index_chunks

# ì…ë ¥ ë¶„ë¥˜
from classification import classify_query

# ê²€ìƒ‰ (RAG ë° ì›¹ ê²€ìƒ‰)
from retrieval import search_with_fallback, perform_rag_search, perform_web_search
from retrieval import get_map_info

# LLM ë° ì‘ë‹µ ìƒì„±
from generation import generate_response, rewrite_response, build_system_prompt

# í‰ê°€
from evaluation import (
    evaluate_response,
    determine_next_action,
    collect_evaluation_metrics
)


# ==================== ìƒ‰ì¸ êµ¬ì¶• ì›Œí¬í”Œë¡œìš° ====================
def indexing_workflow(file_paths: List[str]) -> bool:
    """
    ë¬¸ì„œ ìƒ‰ì¸ êµ¬ì¶• ì›Œí¬í”Œë¡œìš°
    
    ì˜ë£Œ ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì¸ë±ì‹±í•˜ëŠ” ë³„ë„ì˜ ì›Œí¬í”Œë¡œìš°
    
    Args:
        file_paths (List[str]): ì¸ë±ì‹±í•  ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
                               ì˜ˆ: ["data/disease/001.json", "data/disease/002.json"]
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€ (True: ì„±ê³µ, False: ì‹¤íŒ¨)
    
    ì²˜ë¦¬ ìˆœì„œ:
        1ï¸âƒ£  [ë¬¸ì„œ ìˆ˜ì§‘] íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì…ë ¥
        2ï¸âƒ£  [ì „ì²˜ë¦¬] batch_preprocess_documents()
        3ï¸âƒ£  [ì„ë² ë”©] embed_and_index_chunks()
        4ï¸âƒ£  [ê²€ì¦] ì €ì¥ ì™„ë£Œ í™•ì¸
        5ï¸âƒ£  [ì™„ë£Œ] ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸ“š ìƒ‰ì¸ êµ¬ì¶• ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print(f"{'='*60}\n")
    print(f"ğŸ“„ ì²˜ë¦¬í•  ë¬¸ì„œ: {len(file_paths)}ê°œ\n")
    
    start_time = time.time()
    
    # ==================== ìŠ¤í… 1: ë¬¸ì„œ ì „ì²˜ë¦¬ ====================
    print("1ï¸âƒ£  [ìŠ¤í… 1] ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ì²­í‚¹\n")
    
    processed_docs = batch_preprocess_documents(file_paths, chunk_size=500)
    
    # ëª¨ë“  ì²­í¬ ìˆ˜ì§‘
    all_chunks = []
    for doc_result in processed_docs:
        all_chunks.extend(doc_result['chunks'])
    
    print(f"âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ: ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±\n")
    
    # ==================== ìŠ¤í… 2: ì„ë² ë”© ë° ì¸ë±ì‹± ====================
    print("2ï¸âƒ£  [ìŠ¤í… 2] ì„ë² ë”© ë° ë²¡í„° DB ì¸ë±ì‹±\n")
    
    success = embed_and_index_chunks(all_chunks)
    
    # ==================== ìŠ¤í… 3: ì™„ë£Œ ====================
    elapsed_time = time.time() - start_time
    
    print("="*60)
    if success:
        print("âœ… ìƒ‰ì¸ êµ¬ì¶• ì™„ë£Œ!")
        print(f"   - ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"   - ì²˜ë¦¬ëœ ë¬¸ì„œ: {len(file_paths)}ê°œ")
        print(f"   - ìƒì„±ëœ ì²­í¬: {len(all_chunks)}ê°œ")
    else:
        print("âŒ ìƒ‰ì¸ êµ¬ì¶• ì‹¤íŒ¨")
    print("="*60 + "\n")
    
    return success


# ==================== ì¿¼ë¦¬ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ====================
def main_workflow(query: str, max_rewrite_attempts: int = 2) -> str:
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì…ë ¥ë°›ì•„ ì²˜ë¦¬í•˜ê³  ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•˜ëŠ” ë©”ì¸ ì›Œí¬í”Œë¡œìš°
    
    Args:
        query (str): ì‚¬ìš©ìì˜ ì…ë ¥ ì¿¼ë¦¬
        max_rewrite_attempts (int): ìµœëŒ€ ì¬ì‘ì„± ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 2)
        
    Returns:
        str: ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸
    
    ì›Œí¬í”Œë¡œìš° ìŠ¤í…:
        1ï¸âƒ£  [ì…ë ¥ ë¶„ë¥˜] classify_query()
        2ï¸âƒ£  [ì •ë³´ ê²€ìƒ‰] ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ì„ íƒ
        3ï¸âƒ£  [í”„ë¡¬í”„íŠ¸ êµ¬ì„±] build_system_prompt()
        4ï¸âƒ£  [LLM ì‘ë‹µ ìƒì„±] generate_response()
        5ï¸âƒ£  [í‰ê°€ ë£¨í”„] evaluate_response()
        6ï¸âƒ£  [ë‹¤ìŒ ì•¡ì…˜ ê²°ì •] determine_next_action()
        7ï¸âƒ£  [ë©”íŠ¸ë¦­ ìˆ˜ì§‘] collect_evaluation_metrics()
        8ï¸âƒ£  [ìµœì¢… ë°˜í™˜] ìµœì¢… ë‹µë³€ ë°˜í™˜
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print(f"{'='*60}")
    print(f"ğŸ“ ì‚¬ìš©ì ì¿¼ë¦¬: {query}")
    print(f"{'='*60}\n")
    
    start_time = time.time()
    
    # ==================== ìŠ¤í… 1: ì…ë ¥ ë¶„ë¥˜ ====================
    print("ğŸ“Š [ìŠ¤í… 1] ì…ë ¥ ì¿¼ë¦¬ ë¶„ë¥˜...")
    query_type = classify_query(query)
    print(f"   âœ“ ë¶„ë¥˜ ê²°ê³¼: {query_type}\n")
    
    # ==================== ìŠ¤í… 2: ì •ë³´ ê²€ìƒ‰ ====================
    print("ğŸ” [ìŠ¤í… 2] ì •ë³´ ê²€ìƒ‰...")
    
    if query_type == "map_search":
        context = get_map_info(query)
        search_source = "map_api"
        print(f"   âœ“ ì§€ë„ APIì—ì„œ ë³‘ì› ì •ë³´ ì¡°íšŒ ì™„ë£Œ")
    else:
        context, search_source = search_with_fallback(query)
        if search_source == "rag":
            print(f"   âœ“ RAG ê²€ìƒ‰ ì„±ê³µ")
        else:
            print(f"   âœ“ RAG ê²€ìƒ‰ ì‹¤íŒ¨ â†’ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
    
    print(f"   ğŸ“š ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)} ë¬¸ì\n")
    
    # ==================== ìŠ¤í… 3: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ====================
    print("ğŸ’¡ [ìŠ¤í… 3] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±...")
    system_prompt = build_system_prompt(query_type)
    print(f"   âœ“ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì™„ë£Œ\n")
    
    # ==================== ìŠ¤í… 4: LLM ì‘ë‹µ ìƒì„± ====================
    print("ğŸ¤– [ìŠ¤í… 4] LLM ì‘ë‹µ ìƒì„±...")
    response = generate_response(query, context)
    print(f"   âœ“ ì´ˆê¸° ì‘ë‹µ ìƒì„± ì™„ë£Œ")
    print(f"   ğŸ“„ ì‘ë‹µ ê¸¸ì´: {len(response)} ë¬¸ì\n")
    
    # ==================== ìŠ¤í… 5: í‰ê°€ ë° ì¬ì‘ì„± ë£¨í”„ ====================
    print("âš–ï¸  [ìŠ¤í… 5] ì‘ë‹µ í‰ê°€ ë° ì¬ì‘ì„± ë£¨í”„...\n")
    
    rewrite_count = 0
    while rewrite_count <= max_rewrite_attempts:
        
        # ì‘ë‹µ í‰ê°€
        evaluation = evaluate_response(response)
        avg_score = evaluation.get('average_score', 0)
        
        # ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
        next_action = determine_next_action(response, evaluation)
        
        if next_action == "accept":
            print(f"   âœ… í‰ê°€ í†µê³¼! ì‘ë‹µ ìŠ¹ì¸\n")
            break
        elif next_action == "rewrite" and rewrite_count < max_rewrite_attempts:
            print(f"   ğŸ”„ ì‘ë‹µ ì¬ì‘ì„± í•„ìš” (ì‹œë„ #{rewrite_count + 1}/{max_rewrite_attempts})")
            response = rewrite_response(response, evaluation['feedback'])
            rewrite_count += 1
        else:
            print(f"   âš ï¸  ìµœëŒ€ ì¬ì‘ì„± íšŸìˆ˜ ì´ˆê³¼ ë˜ëŠ” ì—ìŠ¤ì»¬ë ˆì´ì…˜ í•„ìš”\n")
            break
    
    # ==================== ìŠ¤í… 6: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¡œê¹… ====================
    generation_time = time.time() - start_time
    metrics = collect_evaluation_metrics(
        response,
        evaluation,
        generation_time,
        rewrite_count
    )
    
    print("\nğŸ“ˆ [ìŠ¤í… 6] ìµœì¢… ë©”íŠ¸ë¦­:")
    print(f"   - ì´ ì²˜ë¦¬ ì‹œê°„: {generation_time:.2f}ì´ˆ")
    print(f"   - ì¬ì‘ì„± íšŸìˆ˜: {rewrite_count}íšŒ")
    print(f"   - ìµœì¢… í‰ê°€ ì ìˆ˜: {metrics['average_score']:.2%}")
    print(f"   - í‰ê°€ í†µê³¼: {'âœ“' if metrics['passed_evaluation'] else 'âœ—'}\n")
    
    # ==================== ìµœì¢… ë‹µë³€ ë°˜í™˜ ====================
    print(f"{'='*60}")
    print(f"âœ¨ ìµœì¢… ë‹µë³€ ë°˜í™˜")
    print(f"{'='*60}\n")
    
    return response


def main_workflow_with_feedback(
    query: str,
    user_feedback: str,
    max_rewrite_attempts: int = 2
) -> str:
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ í¬í•¨í•œ í™•ì¥ ì›Œí¬í”Œë¡œìš°"""
    
    print(f"\nğŸ”„ í”¼ë“œë°± ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print(f"ì‚¬ìš©ì í”¼ë“œë°±: {user_feedback}\n")
    
    # ì´ˆê¸° ì‘ë‹µ ìƒì„±
    initial_response = main_workflow(query, max_rewrite_attempts=1)
    
    # í”¼ë“œë°± ë°˜ì˜ ì¬ì‘ì„±
    refined_response = rewrite_response(initial_response, user_feedback)
    
    # ìµœì¢… í‰ê°€
    final_evaluation = evaluate_response(refined_response)
    
    print(f"\ní”¼ë“œë°± ë°˜ì˜ ìµœì¢… í‰ê°€ ì ìˆ˜: {final_evaluation.get('average_score', 0):.2%}")
    
    return refined_response


def batch_workflow(queries: List[str]) -> List[Dict[str, any]]:
    """ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ë°°ì¹˜ ì²˜ë¦¬"""
    
    results = []
    
    print(f"\nğŸ” ë°°ì¹˜ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print(f"ì´ {len(queries)}ê°œ ì¿¼ë¦¬ ì²˜ë¦¬\n")
    
    for idx, query in enumerate(queries, 1):
        print(f"[{idx}/{len(queries)}] ì²˜ë¦¬ ì¤‘: {query}")
        
        start_time = time.time()
        response = main_workflow(query, max_rewrite_attempts=1)
        processing_time = time.time() - start_time
        
        # ìµœì¢… í‰ê°€ ì ìˆ˜ ìˆ˜ì§‘
        evaluation = evaluate_response(response)
        
        result = {
            'query': query,
            'response': response,
            'query_type': classify_query(query),
            'processing_time': processing_time,
            'evaluation_score': evaluation.get('average_score', 0)
        }
        
        results.append(result)
    
    # í†µê³„ ì¶œë ¥
    avg_time = sum(r['processing_time'] for r in results) / len(results) if results else 0
    avg_score = sum(r['evaluation_score'] for r in results) / len(results) if results else 0
    
    print(f"\nğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
    print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
    print(f"   - í‰ê·  í‰ê°€ ì ìˆ˜: {avg_score:.2%}")
    
    return results


# ==================== ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ ====================
if __name__ == "__main__":
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìŠ¤ì¼ˆë ˆí†¤ ë°ëª¨)"""
    
    print("\n" + "="*60)
    print("ğŸ¥ RAG ê¸°ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ - ëª¨ë“ˆí™”ëœ ìŠ¤ì¼ˆë ˆí†¤ ì½”ë“œ")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ ì¦ìƒì´ ë­ì˜ˆìš”?",
        "ì„œìš¸ ê°•ë‚¨ì—­ ê·¼ì²˜ 24ì‹œê°„ ë™ë¬¼ë³‘ì› ì°¾ì•„ì¤˜",
        "ë°˜ë ¤ë™ë¬¼ ì˜ˆë°© ì ‘ì¢…ì€ ì–¸ì œ í•´ì•¼ í•˜ë‚˜ìš”?"
    ]
    
    # 1ï¸âƒ£ ìƒ‰ì¸ êµ¬ì¶• ì›Œí¬í”Œë¡œìš°
    print("\n\n### í…ŒìŠ¤íŠ¸ 1: ìƒ‰ì¸ êµ¬ì¶• ì›Œí¬í”Œë¡œìš° ###\n")
    
    sample_files = [
        "data/disease/disease_001.json",
        "data/disease/disease_002.json"
    ]
    
    indexing_success = indexing_workflow(sample_files)
    
    # 2ï¸âƒ£ ë‹¨ì¼ ì¿¼ë¦¬ ì²˜ë¦¬
    print("\n\n### í…ŒìŠ¤íŠ¸ 2: ë‹¨ì¼ ì¿¼ë¦¬ ì²˜ë¦¬ ###\n")
    single_response = main_workflow(test_queries[0])
    print(f"\nìµœì¢… ë‹µë³€:\n{single_response}")
    
    # 3ï¸âƒ£ ë°°ì¹˜ ì²˜ë¦¬
    print("\n\n### í…ŒìŠ¤íŠ¸ 3: ë°°ì¹˜ ì²˜ë¦¬ ###\n")
    batch_results = batch_workflow(test_queries[:2])
    
    for result in batch_results:
        print(f"\nì¿¼ë¦¬: {result['query']}")
        print(f"ë¶„ë¥˜: {result['query_type']}")
        print(f"ì ìˆ˜: {result['evaluation_score']:.2%}")
    
    print("\n" + "="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*60)

