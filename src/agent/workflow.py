"""
LangGraph Agent ì›Œí¬í”Œë¡œìš° - ê¸°ë³¸ ë²„ì „
ì¦ìƒ ë¶„ì„ â†’ ì‘ê¸‰ë„ íŒë‹¨ â†’ ë³‘ì› ì¶”ì²œ ìë™í™” ì›Œí¬í”Œë¡œìš°
"""

import os
import sys
from typing import TypedDict, Literal, Dict, Any, List
from typing_extensions import TypedDict

# ìƒìœ„ ë””ë ‰í† ë¦¬ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from utils.tools import rag_search_tool, hospital_recommend_tool

# ìµœì í™” ëª¨ë“ˆ import
try:
    from utils.optimization import extract_keywords_for_query
    OPTIMIZATION_AVAILABLE = True
except ImportError:
    print("âš ï¸ ìµœì í™” ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    OPTIMIZATION_AVAILABLE = False


# ============================================================================
# ìƒíƒœ ì •ì˜ (State Schema)
# ============================================================================

class AgentState(TypedDict):
    """Agentì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” TypedDict"""
    messages: List[Any]  # ëŒ€í™” íˆìŠ¤í† ë¦¬
    user_query: str  # ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸
    symptoms_analysis: str  # ì¦ìƒ ë¶„ì„ ê²°ê³¼
    urgency_level: str  # ì‘ê¸‰ë„ ìˆ˜ì¤€ ("ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ")
    triage_reasoning: str  # ì‘ê¸‰ë„ íŒë‹¨ ìƒì„¸ ì¶”ë¡  ê³¼ì •
    recommended_department: str  # ì¶”ì²œ ì§„ë£Œê³¼
    hospital_list: str  # ì¶”ì²œ ë³‘ì› ë¦¬ìŠ¤íŠ¸ (í¬ë§·ëœ ë¬¸ìì—´)
    final_response: str  # ìµœì¢… ì‘ë‹µ
    next_action: str  # ë‹¤ìŒ ì•¡ì…˜ ì§€ì‹œ
    user_location: str  # ì‚¬ìš©ì ìœ„ì¹˜ (ì˜ˆ: "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™")
    # ì˜í•™ì  ê²€ìˆ˜ ê´€ë ¨ í•„ë“œ
    review_feedback: str  # ê²€ìˆ˜ í”¼ë“œë°±
    needs_revision: bool  # ìˆ˜ì • í•„ìš” ì—¬ë¶€
    revision_count: int  # ì¬ê²€í†  íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)


# ============================================================================
# Node í•¨ìˆ˜ ì •ì˜
# ============================================================================

def analyze_symptom_node(state: AgentState) -> AgentState:
    """
    Node 1: ì¦ìƒ ë¶„ì„ (RAG ê²€ìƒ‰ ìˆ˜í–‰) - ì§€ì¹¨ 4.2: lifeCycle ì¶”ë¡  ë° í™œìš©
    
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  RAGë¥¼ í†µí•´ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print("\n[Node 1] ì¦ìƒ ë¶„ì„ ì‹œì‘...")
    
    user_query = state["user_query"]
    
    # lifeCycle ì¶”ë¡  (ì§€ì¹¨ 4.2: ì§ˆë¬¸ ì†ì„± ë¶€ì—¬)
    life_cycle = _infer_life_cycle(user_query)
    
    # ì§„ë£Œê³¼ ì¶”ë¡  (í‚¤ì›Œë“œ ê¸°ë°˜)
    department_hint = _infer_department(user_query)
    
    # ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” (Query Re-writing)
    if OPTIMIZATION_AVAILABLE:
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)
        search_query = extract_keywords_for_query(user_query, llm)
        # lifeCycle ì •ë³´ ì¶”ê°€
        if life_cycle:
            search_query = f"{life_cycle} {search_query}"
        print(f"[ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬] {search_query}")
    else:
        # ìµœì í™” ëª¨ë“ˆ ì—†ì„ ê²½ìš° ê¸°ë³¸ ë°©ì‹
        search_query = user_query
        if life_cycle:
            search_query = f"[{life_cycle}] {user_query}"
    
    rag_result = rag_search_tool.invoke({
        "query": search_query, 
        "department": department_hint
    })
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    analysis_with_context = f"""[í™˜ì ì •ë³´: {life_cycle or 'ì—°ë ¹ ë¯¸ìƒ'}]

{rag_result}

â€» ì´ ë¶„ì„ì€ {life_cycle or 'ì—°ë ¹ëŒ€ ë¶ˆëª…'}ì¸ ë°˜ë ¤ë™ë¬¼ì„ ê³ ë ¤í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."""
    
    state["symptoms_analysis"] = analysis_with_context
    state["messages"].append(AIMessage(content=f"ì¦ìƒ ë¶„ì„ ì™„ë£Œ:\n{analysis_with_context}"))
    
    print(f"[Node 1 ì™„ë£Œ] ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨ (lifeCycle: {life_cycle})")
    
    return state


def _infer_life_cycle(query: str) -> str:
    """
    ì§ˆë¬¸ì—ì„œ lifeCycle ì¶”ë¡  (ì§€ì¹¨ 4.2)
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        ì¶”ë¡ ëœ lifeCycle (ìê²¬/ì„±ê²¬/ë…¸ë ¹ê²¬ ë“±)
    """
    query_lower = query.lower()
    
    if any(keyword in query for keyword in ['ê°•ì•„ì§€', 'ìê²¬', 'ìƒˆë¼', 'ì–´ë¦°', 'ìƒí›„']):
        return 'ìê²¬'
    elif any(keyword in query for keyword in ['ë…¸ë ¹', 'ë…¸ê²¬', 'ëŠ™ì€', 'ë‚˜ì´ë“ ', 'ì‹œë‹ˆì–´']):
        return 'ë…¸ë ¹ê²¬'
    elif any(keyword in query for keyword in ['ì„±ê²¬', 'ì„±ì¸']):
        return 'ì„±ê²¬'
    
    return ''  # ì¶”ë¡  ë¶ˆê°€


def _infer_department(query: str) -> str:
    """
    ì§ˆë¬¸ì—ì„œ ì§„ë£Œê³¼ ì¶”ë¡  (í‚¤ì›Œë“œ ê¸°ë°˜)
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        ì¶”ë¡ ëœ ì§„ë£Œê³¼
    """
    department_keywords = {
        'ì•ˆê³¼': ['ëˆˆ', 'ì‹œë ¥', 'ì¶©í˜ˆ', 'ê°ë§‰', 'ê²°ë§‰', 'ë°±ë‚´ì¥'],
        'ì¹˜ê³¼': ['ì´', 'ì¹˜ì•„', 'ì‡ëª¸', 'ì¹˜ì„', 'êµ¬ì·¨', 'ì…ëƒ„ìƒˆ'],
        'í”¼ë¶€ê³¼': ['í”¼ë¶€', 'ê°€ë ¤ì›€', 'íƒˆëª¨', 'ë¶‰ì€', 'ë°œì§„', 'ë°˜ì '],
        'ì™¸ê³¼': ['ê³¨ì ˆ', 'ìƒì²˜', 'ìˆ˜ìˆ ', 'ì™¸ìƒ', 'ì ˆë‹¨'],
        'ë‚´ê³¼': ['êµ¬í† ', 'ì„¤ì‚¬', 'ê¸°ì¹¨', 'í™©ë‹¬', 'ë°œì—´']
    }
    
    for dept, keywords in department_keywords.items():
        if any(keyword in query for keyword in keywords):
            return dept
    
    return ''  # ì§„ë£Œê³¼ ì¶”ë¡  ë¶ˆê°€


def triage_and_decide_node(state: AgentState) -> AgentState:
    """
    Node 2: ì‘ê¸‰ë„ íŒë‹¨ ë° ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (ì§€ì¹¨ 5: CoT ê¸°ë°˜ ê°œì„ )
    
    ì¦ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ê¸‰ë„ë¥¼ íŒë‹¨í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    # ì¬ê²€í†  íšŸìˆ˜ í™•ì¸
    revision_count = state.get("revision_count", 0)
    
    print(f"\n[Node 2] ì‘ê¸‰ë„ íŒë‹¨ ì¤‘... (ì¬ê²€í†  {revision_count}íšŒì°¨)")
    
    symptoms_analysis = state["symptoms_analysis"]
    user_query = state["user_query"]
    
    # LLMì„ ì‚¬ìš©í•œ ì‘ê¸‰ë„ íŒë‹¨ (CoT ë°©ì‹)
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=800
    )
    
    # ì§€ì¹¨ 5: Chain-of-Thought (CoT) í”„ë¡¬í”„íŠ¸ - ë‹¨ê³„ì  ì¶”ë¡  ìš”êµ¬
    triage_prompt = f"""ë‹¹ì‹ ì€ ìˆ˜ì˜í•™ ì‘ê¸‰ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¦ìƒì„ **ë‹¨ê³„ì ìœ¼ë¡œ ë¶„ì„**í•˜ì—¬ ì‘ê¸‰ë„ë¥¼ íŒë‹¨í•˜ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

## ì¦ìƒ ë¶„ì„ ê²°ê³¼
{symptoms_analysis}

## ì‘ê¸‰ë„ íŒë‹¨ í”„ë¡œì„¸ìŠ¤ (ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ ì‘ì„±)

### 1ë‹¨ê³„: ìœ„í—˜ ì§•í›„ í™•ì¸
ë‹¤ìŒ ê³ ìœ„í—˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:
- ë°œì‘, ê²½ë ¨, ì˜ì‹ ì €í•˜
- í˜¸í¡ê³¤ë€, ì²­ìƒ‰ì¦, ì§ˆì‹
- ì‹¬í•œ ì¶œí˜ˆ, ì‡¼í¬
- ë³µë¶€ íŒ½ë§Œ (ìœ„ ë¹„í‹€ë¦¼ ì˜ì‹¬)
- ê¸‰ì„± ì¤‘ë…, ê³ ì—´ (40ë„ ì´ìƒ)

**í™•ì¸ ê²°ê³¼**: [ìœ„í—˜ ì§•í›„ ìœ ë¬´ ë° í•´ë‹¹ í‚¤ì›Œë“œ]

### 2ë‹¨ê³„: ì¦ìƒì˜ ê¸‰ê²©ì„± í‰ê°€
- ì¦ìƒ ë°œí˜„ ì‹œê°„: [ê°‘ìê¸° / ì ì§„ì ]
- ì¦ìƒ ì§„í–‰ ì†ë„: [ê¸‰ì† ì•…í™” / ì•ˆì • / ê°œì„ ]
- ë™ë°˜ ì¦ìƒ ìˆ˜: [ë‹¨ì¼ / ë³µí•©]

**í‰ê°€ ê²°ê³¼**: [ì¦ìƒ ê¸‰ê²©ì„± ì„¤ëª…]

### 3ë‹¨ê³„: ìƒëª… ìœ„í˜‘ë„ íŒë‹¨
- í˜¸í¡/ìˆœí™˜ê³„: [ì •ìƒ / ì´ìƒ]
- ì˜ì‹ ìˆ˜ì¤€: [ëª…ë£Œ / ì €í•˜]
- í†µì¦ ê°•ë„: [ê²½ë¯¸ / ì¤‘ë“±ë„ / ì‹¬ê°]

**íŒë‹¨ ê²°ê³¼**: [ìƒëª… ìœ„í˜‘ë„]

### 4ë‹¨ê³„: ìµœì¢… ì‘ê¸‰ë„ ê²°ì •
ìœ„ 1-3ë‹¨ê³„ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ì‘ê¸‰ë„ë¥¼ ê²°ì •í•˜ì„¸ìš”:
- "ë†’ìŒ": ìƒëª… ìœ„í˜‘ ë˜ëŠ” ì¦‰ê°ì  ì¹˜ë£Œ í•„ìš”
- "ë³´í†µ": 24-48ì‹œê°„ ë‚´ ì§„ë£Œ í•„ìš”
- "ë‚®ìŒ": ë©°ì¹  ë‚´ ì§„ë£Œ ê°€ëŠ¥

**ìµœì¢… ì‘ê¸‰ë„**: [ë†’ìŒ/ë³´í†µ/ë‚®ìŒ]
**ì¶”ì²œ ì§„ë£Œê³¼**: [ë‚´ê³¼/ì™¸ê³¼/ì•ˆê³¼/ì¹˜ê³¼/í”¼ë¶€ê³¼]
**ê·¼ê±° ìš”ì•½**: [1-2ë¬¸ì¥]"""
    
    response = llm.invoke([HumanMessage(content=triage_prompt)])
    triage_result = response.content
    
    # ì‘ê¸‰ë„ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
    if "ë†’ìŒ" in triage_result:
        urgency = "ë†’ìŒ"
        next_action = "recommend_hospital"
    elif "ë³´í†µ" in triage_result:
        urgency = "ë³´í†µ"
        next_action = "recommend_hospital"
    else:
        urgency = "ë‚®ìŒ"
        next_action = "end"
    
    # ì§„ë£Œê³¼ ì¶”ì¶œ
    if "ë‚´ê³¼" in triage_result:
        department = "ë‚´ê³¼"
    elif "ì™¸ê³¼" in triage_result:
        department = "ì™¸ê³¼"
    elif "ì•ˆê³¼" in triage_result:
        department = "ì•ˆê³¼"
    elif "í”¼ë¶€ê³¼" in triage_result:
        department = "í”¼ë¶€ê³¼"
    else:
        department = "ì¼ë°˜"
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["urgency_level"] = urgency
    state["recommended_department"] = department
    state["triage_reasoning"] = triage_result  # ì¶”ë¡  ê³¼ì • ì €ì¥ (ê²€ìˆ˜ìš©)
    state["next_action"] = next_action
    state["messages"].append(AIMessage(content=f"ì‘ê¸‰ë„ íŒë‹¨:\n{triage_result}"))
    
    print(f"[Node 2 ì™„ë£Œ] ì‘ê¸‰ë„: {urgency}, ì§„ë£Œê³¼: {department}, ë‹¤ìŒ ì•¡ì…˜: {next_action}")
    
    return state


def medical_review_node(state: AgentState) -> AgentState:
    """
    Node 3: ì˜í•™ì  ê²€ìˆ˜ (Medical Review)
    
    ì‘ê¸‰ë„ íŒë‹¨ì˜ ì •í™•ì„±ì„ ì¬ê²€í† í•˜ê³ , ëˆ„ë½ëœ ìœ„í—˜ ì§•í›„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    í”¼ë“œë°± ë£¨í”„ë¥¼ í†µí•´ ì˜¤íŒì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    """
    print("\n[Node 3] ì˜í•™ì  ê²€ìˆ˜ ì‹œì‘...")
    
    user_query = state["user_query"]
    symptoms_analysis = state["symptoms_analysis"]
    urgency_level = state["urgency_level"]
    triage_reasoning = state["triage_reasoning"]
    revision_count = state.get("revision_count", 0)
    previous_feedback = state.get("review_feedback", "")
    
    # LLMì„ ì‚¬ìš©í•œ ì˜í•™ì  ê²€ìˆ˜
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.0,  # ì¼ê´€ëœ ê²€ìˆ˜ë¥¼ ìœ„í•´ temperature 0
        max_tokens=1000
    )
    
    # ê²€ìˆ˜ í”„ë¡¬í”„íŠ¸
    previous_feedback_section = f"## ì´ì „ ê²€ìˆ˜ í”¼ë“œë°±\n{previous_feedback}" if previous_feedback else ""
    
    review_prompt = f"""ë‹¹ì‹ ì€ ìˆ˜ì˜í•™ ì‘ê¸‰ ì „ë¬¸ê°€ì´ì í’ˆì§ˆ ê²€ìˆ˜ ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ë‹¤ìŒ ì¦ìƒ ë¶„ì„ê³¼ ì‘ê¸‰ë„ íŒë‹¨ì„ **ë¹„íŒì ìœ¼ë¡œ ì¬ê²€í† **í•˜ì—¬ ì˜í•™ì  ì •í™•ì„±ì„ ê²€ì¦í•˜ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

## ì¦ìƒ ë¶„ì„ ê²°ê³¼
{symptoms_analysis}

## íŒë‹¨ëœ ì‘ê¸‰ë„
{urgency_level}

## ì‘ê¸‰ë„ íŒë‹¨ ì¶”ë¡  ê³¼ì •
{triage_reasoning}

{previous_feedback_section}

## ê²€ìˆ˜ ê¸°ì¤€ (ë§¤ìš° ì—„ê²©í•˜ê²Œ ì ìš©)

### 1. ìƒëª… ìœ„í˜‘ ì§•í›„ ëˆ„ë½ í™•ì¸
ë‹¤ìŒ ì§•í›„ê°€ ì§ˆë¬¸ì— ìˆëŠ”ë° ì‘ê¸‰ë„ê°€ "ë‚®ìŒ"ì´ë©´ **ë°˜ë“œì‹œ ìˆ˜ì • í•„ìš”**:
- ë°œì‘, ê²½ë ¨, ì˜ì‹ ì €í•˜/í˜¼ìˆ˜
- í˜¸í¡ê³¤ë€, ì²­ìƒ‰ì¦, ì§ˆì‹
- ì‹¬í•œ ì¶œí˜ˆ, ì‡¼í¬ ì¦ìƒ
- ë³µë¶€ ê¸‰ê²©í•œ íŒ½ë§Œ (ìœ„ ë¹„í‹€ë¦¼ GDV ì˜ì‹¬)
- ê¸‰ì„± ì¤‘ë… ì˜ì‹¬
- 40ë„ ì´ìƒ ê³ ì—´
- ì‹¬í•œ íƒˆìˆ˜ (ì‡ëª¸ ì°½ë°±, í”¼ë¶€ í…íŠ¸ í…ŒìŠ¤íŠ¸ ì´ìƒ)

### 2. ê³¼ëŒ€í‰ê°€ í™•ì¸
ë‹¤ìŒ ê²½ìš° ì‘ê¸‰ë„ê°€ "ë†’ìŒ"ì´ë©´ **ê³¼ëŒ€í‰ê°€ ê°€ëŠ¥ì„±**:
- ë‹¨ìˆœ ê²½ë¯¸í•œ ì¦ìƒ (ê°€ë²¼ìš´ ê¸°ì¹¨, ê²½ë¯¸í•œ í”¼ë¶€ ë°œì§„ ë“±)
- ë§Œì„±ì ì´ê³  ì•ˆì •ì ì¸ ì¦ìƒ (ìˆ˜ê°œì›” ì§€ì†ëœ ë³€í™” ì—†ëŠ” ì¦ìƒ)
- í–‰ë™í•™ì  ë¬¸ì œ (ê³µê²©ì„±, ë¶„ë¦¬ë¶ˆì•ˆ ë“±)

### 3. ì¦ìƒ-ì‘ê¸‰ë„ ì¼ê´€ì„± ê²€ì¦
- ë³µí•© ì¦ìƒ(êµ¬í† +í™©ë‹¬, í˜¸í¡ê³¤ë€+ì²­ìƒ‰ì¦)ì´ ìˆëŠ”ë° ì‘ê¸‰ë„ "ë‚®ìŒ" â†’ **ë¶ˆì¼ì¹˜**
- ë‹¨ì¼ ê²½ë¯¸ ì¦ìƒ(ê°€ë²¼ìš´ ëˆˆ ì¶©í˜ˆ)ì¸ë° ì‘ê¸‰ë„ "ë†’ìŒ" â†’ **ë¶ˆì¼ì¹˜**

### 4. ì—°ë ¹ëŒ€(lifeCycle) ê³ ë ¤
- ìê²¬/ë…¸ë ¹ê²¬ì€ ë©´ì—­ë ¥ì´ ì•½í•´ ê°™ì€ ì¦ìƒë„ ë” ìœ„í—˜í•  ìˆ˜ ìˆìŒ
- ì´ë¥¼ ê³ ë ¤í–ˆëŠ”ì§€ í™•ì¸

## ê²€ìˆ˜ ê²°ê³¼ ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥)

**íŒì •**: [ìŠ¹ì¸/ìˆ˜ì •í•„ìš”]

**ê²€ìˆ˜ ê·¼ê±°**:
- [êµ¬ì²´ì ì¸ ì˜í•™ì  ê·¼ê±° 3-5ì¤„]
- [ë†“ì¹œ ìœ„í—˜ ì§•í›„ë‚˜ ê³¼ëŒ€í‰ê°€ ìš”ì†Œ]

**ìˆ˜ì • ì œì•ˆ** (ìˆ˜ì •í•„ìš” ì‹œì—ë§Œ):
- ì œì•ˆ ì‘ê¸‰ë„: [ë†’ìŒ/ë³´í†µ/ë‚®ìŒ]
- ì œì•ˆ ì´ìœ : [1-2ë¬¸ì¥]

**ì‹ ë¢°ë„**: [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ] (í˜„ì¬ íŒë‹¨ì˜ ì˜í•™ì  ì‹ ë¢°ë„)
"""
    
    response = llm.invoke([HumanMessage(content=review_prompt)])
    review_result = response.content
    
    # ê²€ìˆ˜ ê²°ê³¼ íŒŒì‹±
    needs_revision = "ìˆ˜ì •í•„ìš”" in review_result or "ìˆ˜ì • í•„ìš”" in review_result
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["review_feedback"] = review_result
    state["needs_revision"] = needs_revision
    # ìˆ˜ì • í•„ìš”í•  ê²½ìš° revision_count ì¦ê°€
    if needs_revision:
        state["revision_count"] = revision_count + 1
    else:
        state["revision_count"] = revision_count
    state["messages"].append(AIMessage(content=f"ì˜í•™ì  ê²€ìˆ˜:\n{review_result}"))
    
    if needs_revision:
        print(f"[Node 3 ì™„ë£Œ] ê²€ìˆ˜ ê²°ê³¼: ìˆ˜ì • í•„ìš” (ì¬ê²€í†  íšŸìˆ˜: {revision_count})")
    else:
        print(f"[Node 3 ì™„ë£Œ] ê²€ìˆ˜ ê²°ê³¼: ìŠ¹ì¸")
    
    return state


def recommend_hospital_node(state: AgentState) -> AgentState:
    """
    Node 4: ë³‘ì› ì¶”ì²œ
    
    ì‘ê¸‰ë„ì™€ ì§„ë£Œê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë³‘ì›ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
    """
    print("\n[Node 4] ë³‘ì› ì¶”ì²œ ì¤‘...")
    
    urgency = state["urgency_level"]
    department = state["recommended_department"]
    
    # ì‚¬ìš©ìì—ê²Œ ìœ„ì¹˜ ì…ë ¥ ìš”ì²­ (ì‹¤ì œë¡œëŠ” Streamlitì´ë‚˜ ëŒ€í™”ì—ì„œ ìˆ˜ì§‘)
    # TODO: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” stateì—ì„œ locationì„ ê°€ì ¸ì˜¤ê±°ë‚˜, 
    # ë³„ë„ì˜ conditional edgeë¡œ ìœ„ì¹˜ ì…ë ¥ì„ ìš”ì²­í•˜ëŠ” ë…¸ë“œë¥¼ ì¶”ê°€í•´ì•¼ í•¨
    location_query = state.get("user_location", "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬")
    
    print(f"[ë³‘ì› ê²€ìƒ‰] ìœ„ì¹˜: {location_query}, ì‘ê¸‰ë„: {urgency}")
    
    # ë³‘ì› ê²€ìƒ‰ (Tool í˜¸ì¶œ) - ì¹´ì¹´ì˜¤ ì§€ë„ API ì‚¬ìš©
    hospital_result = hospital_recommend_tool.invoke(location_query)
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸ (hospital_recommend_toolì€ ì´ì œ í¬ë§·ëœ ë¬¸ìì—´ ë°˜í™˜)
    state["hospital_list"] = hospital_result  # í¬ë§·ëœ ë¬¸ìì—´ë¡œ ì €ì¥
    
    state["messages"].append(AIMessage(content=f"ì¶”ì²œ ë³‘ì›:\n\n{hospital_result}"))
    state["next_action"] = "generate_final_response"
    
    print(f"[Node 4 ì™„ë£Œ] ë³‘ì› ì¶”ì²œ ì™„ë£Œ")
    
    return state


def generate_final_response_node(state: AgentState) -> AgentState:
    """
    Node 5: ìµœì¢… ì‘ë‹µ ìƒì„±
    
    ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì œê³µí•  ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("\n[Node 5] ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...")
    
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=1500
    )
    
    # ìµœì¢… ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸
    final_prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸:
{state['user_query']}

ì¦ìƒ ë¶„ì„:
{state['symptoms_analysis']}

ì‘ê¸‰ë„: {state['urgency_level']}
ì¶”ì²œ ì§„ë£Œê³¼: {state['recommended_department']}

ì¶”ì²œ ë³‘ì›:
{state.get('hospital_list', 'ë³‘ì› ì •ë³´ ì—†ìŒ')}

ë‹µë³€ êµ¬ì¡°:
1. ì¦ìƒ ìš”ì•½ ë° ê³µê°
2. ì˜ì‹¬ ì§ˆí™˜ ì„¤ëª… (ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ)
3. ì‘ê¸‰ë„ ë° ê¶Œì¥ ì¡°ì¹˜
4. ì¶”ì²œ ë³‘ì› ì •ë³´ (ìˆëŠ” ê²½ìš°)
5. ì¶”ê°€ ì£¼ì˜ì‚¬í•­

ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
    
    response = llm.invoke([HumanMessage(content=final_prompt)])
    final_response = response.content
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["final_response"] = final_response
    state["messages"].append(AIMessage(content=final_response))
    state["next_action"] = "end"
    
    print(f"[Node 5 ì™„ë£Œ] ìµœì¢… ì‘ë‹µ ìƒì„±ë¨")
    
    return state


# ============================================================================
# Conditional Edge í•¨ìˆ˜
# ============================================================================

def needs_medical_revision(state: AgentState) -> Literal["triage_and_decide", "recommend_hospital", "generate_final_response"]:
    """
    ì¡°ê±´ë¶€ ì—£ì§€: ê²€ìˆ˜ ê²°ê³¼ì— ë”°ë¼ ì¬ê²€í†  ì—¬ë¶€ ê²°ì •
    
    - needs_revision=Trueì´ê³  revision_count < 2: ì‘ê¸‰ë„ íŒë‹¨ ë…¸ë“œë¡œ ë³µê·€
    - needs_revision=False: ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰
    - revision_count >= 2: ê°•ì œ ì§„í–‰ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    """
    needs_revision = state.get("needs_revision", False)
    revision_count = state.get("revision_count", 0)
    urgency = state.get("urgency_level", "ë³´í†µ")
    
    # ë¬´í•œ ë£¨í”„ ë°©ì§€: ìµœëŒ€ 2ë²ˆê¹Œì§€ë§Œ ì¬ê²€í† 
    if needs_revision and revision_count < 2:
        print(f"[ì¡°ê±´ë¶€ ì—£ì§€ - ê²€ìˆ˜] ìˆ˜ì • í•„ìš” â†’ ì‘ê¸‰ë„ íŒë‹¨ ì¬ì‹¤í–‰ ({revision_count + 1}íšŒì°¨)")
        # revision_countëŠ” triage_and_decide_nodeì—ì„œ ì¦ê°€ë¨
        return "triage_and_decide"
    
    # ê²€ìˆ˜ í†µê³¼ ë˜ëŠ” ìµœëŒ€ ì¬ê²€í†  íšŸìˆ˜ ë„ë‹¬
    if revision_count >= 2:
        print(f"[ì¡°ê±´ë¶€ ì—£ì§€ - ê²€ìˆ˜] ìµœëŒ€ ì¬ê²€í†  íšŸìˆ˜ ë„ë‹¬ â†’ í˜„ì¬ íŒë‹¨ìœ¼ë¡œ ì§„í–‰")
    
    # ì‘ê¸‰ë„ì— ë”°ë¼ ë³‘ì› ì¶”ì²œ ì—¬ë¶€ ê²°ì •
    if urgency in ["ë†’ìŒ", "ë³´í†µ"]:
        print(f"[ì¡°ê±´ë¶€ ì—£ì§€ - ë³‘ì›] ì‘ê¸‰ë„ '{urgency}' â†’ ë³‘ì› ì¶”ì²œ ìˆ˜í–‰")
        return "recommend_hospital"
    else:
        print(f"[ì¡°ê±´ë¶€ ì—£ì§€ - ë³‘ì›] ì‘ê¸‰ë„ '{urgency}' â†’ ë³‘ì› ì¶”ì²œ ìƒëµ")
        return "generate_final_response"


def should_recommend_hospital(state: AgentState) -> Literal["recommend_hospital", "generate_final_response"]:
    """
    ì¡°ê±´ë¶€ ì—£ì§€: ì‘ê¸‰ë„ì— ë”°ë¼ ë³‘ì› ì¶”ì²œ ì—¬ë¶€ ê²°ì • (ê²€ìˆ˜ í†µê³¼ í›„)
    
    - ì‘ê¸‰ë„ 'ë†’ìŒ' ë˜ëŠ” 'ë³´í†µ': ë³‘ì› ì¶”ì²œ ìˆ˜í–‰
    - ì‘ê¸‰ë„ 'ë‚®ìŒ': ë³‘ì› ì¶”ì²œ ìƒëµí•˜ê³  ìµœì¢… ì‘ë‹µ ìƒì„±
    """
    urgency = state.get("urgency_level", "ë³´í†µ")
    
    if urgency in ["ë†’ìŒ", "ë³´í†µ"]:
        print(f"[ì¡°ê±´ë¶€ ì—£ì§€] ì‘ê¸‰ë„ '{urgency}' â†’ ë³‘ì› ì¶”ì²œ ìˆ˜í–‰")
        return "recommend_hospital"
    else:
        print(f"[ì¡°ê±´ë¶€ ì—£ì§€] ì‘ê¸‰ë„ '{urgency}' â†’ ë³‘ì› ì¶”ì²œ ìƒëµ")
        return "generate_final_response"


# ============================================================================
# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¶•
# ============================================================================

def create_pet_health_agent() -> StateGraph:
    """
    ë°˜ë ¤ë™ë¬¼ ê±´ê°• ìƒë‹´ Agent ì›Œí¬í”Œë¡œìš° ìƒì„±
    
    Returns:
        ì»´íŒŒì¼ëœ StateGraph
    """
    # StateGraph ì´ˆê¸°í™”
    workflow = StateGraph(AgentState)
    
    # Node ì¶”ê°€
    workflow.add_node("analyze_symptom", analyze_symptom_node)
    workflow.add_node("triage_and_decide", triage_and_decide_node)
    workflow.add_node("medical_review", medical_review_node)  # ì˜í•™ì  ê²€ìˆ˜ ë…¸ë“œ ì¶”ê°€
    workflow.add_node("recommend_hospital", recommend_hospital_node)
    workflow.add_node("generate_final_response", generate_final_response_node)
    
    # Edge ì •ì˜
    # ì‹œì‘ â†’ ì¦ìƒ ë¶„ì„
    workflow.set_entry_point("analyze_symptom")
    
    # ì¦ìƒ ë¶„ì„ â†’ ì‘ê¸‰ë„ íŒë‹¨
    workflow.add_edge("analyze_symptom", "triage_and_decide")
    
    # ì‘ê¸‰ë„ íŒë‹¨ â†’ ì˜í•™ì  ê²€ìˆ˜ (í”¼ë“œë°± ë£¨í”„ í¬í•¨)
    workflow.add_edge("triage_and_decide", "medical_review")
    
    # ì˜í•™ì  ê²€ìˆ˜ â†’ ì¡°ê±´ë¶€ ë¶„ê¸° (ì¬ê²€í†  or ë‹¤ìŒ ë‹¨ê³„)
    workflow.add_conditional_edges(
        "medical_review",
        needs_medical_revision,
        {
            "triage_and_decide": "triage_and_decide",  # í”¼ë“œë°± ë£¨í”„: ì¬ê²€í† 
            "recommend_hospital": "recommend_hospital",  # ê²€ìˆ˜ í†µê³¼ + ì‘ê¸‰ë„ ë†’ìŒ/ë³´í†µ
            "generate_final_response": "generate_final_response"  # ê²€ìˆ˜ í†µê³¼ + ì‘ê¸‰ë„ ë‚®ìŒ
        }
    )
    
    # ë³‘ì› ì¶”ì²œ â†’ ìµœì¢… ì‘ë‹µ
    workflow.add_edge("recommend_hospital", "generate_final_response")
    
    # ìµœì¢… ì‘ë‹µ â†’ ì¢…ë£Œ
    workflow.add_edge("generate_final_response", END)
    
    # ì»´íŒŒì¼ (ì²´í¬í¬ì¸í„° ì¶”ê°€ ê°€ëŠ¥)
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    
    print("LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¶• ì™„ë£Œ")
    
    return app


# ============================================================================
# ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def run_agent(user_query: str, user_location: str = None, config: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Agent ì‹¤í–‰
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        user_location: ì‚¬ìš©ì ìœ„ì¹˜ (ì˜ˆ: "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™")
        config: LangGraph ì„¤ì • (thread_id ë“±)
        
    Returns:
        ìµœì¢… ìƒíƒœ
    """
    # Agent ìƒì„±
    app = create_pet_health_agent()
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state = {
        "messages": [HumanMessage(content=user_query)],
        "user_query": user_query,
        "symptoms_analysis": "",
        "urgency_level": "",
        "triage_reasoning": "",
        "recommended_department": "",
        "hospital_list": "",  # ì´ì œ ë¬¸ìì—´ë¡œ ì €ì¥ë¨
        "final_response": "",
        "next_action": "",
        "review_feedback": "",
        "needs_revision": False,
        "revision_count": 0,
        "user_location": user_location or "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬"  # ì‚¬ìš©ì ìœ„ì¹˜ ì¶”ê°€
    }
    
    # ì„¤ì •
    if config is None:
        config = {"configurable": {"thread_id": "default"}}
    
    # ì‹¤í–‰
    print(f"\n{'='*60}")
    print(f"Agent ì‹¤í–‰ ì‹œì‘: {user_query}")
    print(f"{'='*60}")
    
    final_state = None
    for state in app.stream(initial_state, config):
        # ê° ë‹¨ê³„ì˜ ìƒíƒœ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        node_name = list(state.keys())[0]
        print(f"\n--- {node_name} ì™„ë£Œ ---")
        final_state = state[node_name]
    
    print(f"\n{'='*60}")
    print(f"Agent ì‹¤í–‰ ì™„ë£Œ")
    print(f"{'='*60}\n")
    
    return final_state


# ============================================================================
# ì˜ˆì œ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    from dotenv import load_dotenv
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ì €í¬ ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ ê³„ì†í•˜ê³  í™©ë‹¬ ì¦ìƒì´ ìˆì–´ìš”. í˜¸í¡ë„ ê±°ì¹ ì–´ìš”.",
        "ê³ ì–‘ì´ ëˆˆì´ ì•½ê°„ ì¶©í˜ˆë˜ì—ˆëŠ”ë° ê´œì°®ì„ê¹Œìš”?",
        "ê°•ì•„ì§€ í”¼ë¶€ì— ë°œì§„ì´ ìƒê²¼ì–´ìš”. ê°€ë ¤ì›Œí•˜ëŠ” ê²ƒ ê°™ì•„ìš”."
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\n{'#'*80}")
        print(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}")
        print(f"{'#'*80}")
        
        result = run_agent(query, config={"configurable": {"thread_id": f"test_{i}"}})
        
        # ìµœì¢… ì‘ë‹µ ì¶œë ¥
        print("\n" + "="*60)
        print("ìµœì¢… ì‘ë‹µ:")
        print("="*60)
        print(result.get("final_response", "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"))
        print("\n")
