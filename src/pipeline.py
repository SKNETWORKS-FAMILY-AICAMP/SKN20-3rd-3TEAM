"""
RAG Pipeline ëª¨ë“ˆ
LangGraph ê¸°ë°˜ CRAG (Corrective RAG) íŒ¨í„´ êµ¬í˜„
ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ í›„, ì—†ìœ¼ë©´ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
ìƒì„¸í•œ ë””ë²„ê¹… ë¡œê·¸ í¬í•¨
"""
from typing import List, Dict, Any, Literal
from typing_extensions import TypedDict
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.retrievers import TavilySearchAPIRetriever
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
import os
import warnings
warnings.filterwarnings("ignore")


# ==================== State ì •ì˜ ====================
class CRAGState(TypedDict):
    """CRAG íŒŒì´í”„ë¼ì¸ì˜ ìƒíƒœ"""
    question: str
    original_question: str  # ìµœì í™” ì „ ì›ë³¸ ì§ˆë¬¸
    documents: List[Document]
    document_scores: List[float]  # similarity scores
    filtered_documents: List[Document]
    relevance_scores: List[float]  # LLM í‰ê°€ ì ìˆ˜
    web_search_needed: str
    web_search_reason: str  # ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì´ìœ 
    context: str
    answer: str
    grade_results: List[str]
    sources: List[Dict[str, Any]]
    answer_quality: str  # "pass" ë˜ëŠ” "fail"
    answer_quality_reason: str  # í‰ê°€ ì‚¬ìœ 
    rewrite_count: int  # Rewrite ì‹œë„ íšŸìˆ˜


class GradeDocuments(BaseModel):
    """ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ê²°ê³¼"""
    binary_score: str = Field(
        description="ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆìœ¼ë©´ 'yes', ì—†ìœ¼ë©´ 'no'"
    )


class LangGraphRAGPipeline:
    """
    LangGraph ê¸°ë°˜ CRAG (Corrective RAG) íŒŒì´í”„ë¼ì¸
    
    ë¬¸ì„œ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ê³ , ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±í•˜ëŠ” ê³ ê¸‰ RAG ì‹œìŠ¤í…œ
    ë””ë²„ê¹… ë¡œê·¸ë¥¼ ìƒì„¸íˆ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        retriever: BaseRetriever,
        llm_model: str = "gpt-4o-mini",
        temperature: float = 0.0,
        debug: bool = True
    ):
        """
        Args:
            retriever: ë¬¸ì„œ ê²€ìƒ‰ê¸°
            llm_model: LLM ëª¨ë¸ ì´ë¦„
            temperature: LLM temperature
            debug: ë””ë²„ê¹… ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        """
        self.retriever = retriever
        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)
        self.grader_llm = ChatOpenAI(model=llm_model, temperature=0)
        self.debug = debug
        
        # ì›¹ ê²€ìƒ‰ ì„¤ì •
        try:
            self.web_search = TavilySearchAPIRetriever(k=3)
            self.web_search_available = True
            if self.debug:
                print("âœ… Tavily ì›¹ ê²€ìƒ‰ API ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ ê²½ê³ : ì›¹ ê²€ìƒ‰ API ì´ˆê¸°í™” ì‹¤íŒ¨ - {str(e)}")
            self.web_search_available = False
        
        # êµ¬ì¡°í™”ëœ grader ì„¤ì •
        self.document_grader = self._setup_grader()
        
        # LangGraph ì•± êµ¬ì¶•
        self.app = self._build_graph()
    
    def _setup_grader(self):
        """ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ê¸° ì„¤ì •"""
        structured_grader = self.grader_llm.with_structured_output(GradeDocuments)
        
        grade_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° ê´€ë ¨ì´ ìˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í‰ê°€ ê¸°ì¤€:
- ë¬¸ì„œê°€ ì§ˆë¬¸ì˜ í‚¤ì›Œë“œ, ê°œë…, ë˜ëŠ” ì£¼ì œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ë˜ì–´ ìˆìœ¼ë©´ 'yes'
- ë¬¸ì„œê°€ ì§ˆë¬¸ì˜ ë°°ê²½, ë§¥ë½, ë˜ëŠ” ê´€ë ¨ ê°œë…ì„ ë‹¤ë£¨ë©´ 'yes'
- ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ëª…í™•í•œ ì—°ê´€ì„±ì´ ì—†ìœ¼ë©´ 'no'

ì£¼ì˜: ì•½ê°„ì˜ ì—°ê´€ì„±ë§Œ ìˆì–´ë„ 'yes'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”."""),
            ("human", """ì§ˆë¬¸: {question}

ë¬¸ì„œ ë‚´ìš©:
{document}

ê´€ë ¨ì„± íŒì • (yes/no):""")
        ])
        
        return grade_prompt | structured_grader
    
    def _setup_query_rewriter(self):
        """ì›¹ ê²€ìƒ‰ìš© ì¿¼ë¦¬ ìµœì í™” LLM ì„¤ì •"""
        rewrite_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì›ì¹™:
1. ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
2. ê²€ìƒ‰ì— ë¶ˆí•„ìš”í•œ ì¡´ëŒ“ë§, ì¸ì‚¬ë§ ì œê±°í•˜ì„¸ìš”.
3. ê²€ìƒ‰ ì—”ì§„ì´ ì˜ ì´í•´í•  ìˆ˜ ìˆëŠ” ê°„ê²°í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ì„¸ìš”.
4. ì¤‘ìš”í•œ ì§€ì—­ëª…, ì¹´í…Œê³ ë¦¬ëª…ì„ ê°•ì¡°í•˜ì„¸ìš”.
5. í•œêµ­ì–´ ë˜ëŠ” ì˜ë¬¸ í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì˜ˆì‹œ:
- ì…ë ¥: "ì„œìš¸ì‹œ ì—¬ì˜ë„ ê³µì› ê·¼ì²˜ì— ìˆëŠ” ë™ë¬¼ë³‘ì›ì„ ì•Œë ¤ì£¼ì„¸ìš”"
- ì¶œë ¥: "ì—¬ì˜ë„ ê³µì› ë™ë¬¼ë³‘ì›"

- ì…ë ¥: "ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´ìš”"
- ì¶œë ¥: "ê°•ì•„ì§€ í”¼ë¶€ì§ˆí™˜ ì¦ìƒ ì¹˜ë£Œ"

ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´)."""),
            ("human", "{question}")
        ])
        
        return rewrite_prompt | self.llm | StrOutputParser()
    
    def _build_graph(self):
        """LangGraph ìƒíƒœ ê·¸ë˜í”„ êµ¬ì¶• (í‰ê°€ ë° Rewrite ë£¨í”„ í¬í•¨)"""
        workflow = StateGraph(CRAGState)
        
        # ë…¸ë“œë“¤ ì •ì˜
        workflow.add_node("retrieve", self._retrieve_node)
        workflow.add_node("grade_documents", self._grade_documents_node)
        workflow.add_node("query_rewrite", self._query_rewrite_node)
        workflow.add_node("web_search", self._web_search_node)
        workflow.add_node("generate", self._generate_node)
        workflow.add_node("evaluate_answer", self._evaluate_answer_node)  # í‰ê°€ ë…¸ë“œ ì¶”ê°€
        
        # ì—£ì§€ ì„¤ì •
        workflow.add_edge(START, "retrieve")
        workflow.add_edge("retrieve", "grade_documents")
        workflow.add_conditional_edges(
            "grade_documents",
            self._decide_to_generate,
            {
                "generate": "generate",
                "web_search": "query_rewrite"
            }
        )
        workflow.add_edge("query_rewrite", "web_search")
        workflow.add_edge("web_search", "generate")
        workflow.add_edge("generate", "evaluate_answer")  # ìƒì„± í›„ í‰ê°€
        
        # í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "evaluate_answer",
            self._decide_after_evaluation,
            {
                "end": END,
                "rewrite": "query_rewrite"  # Fail ì‹œ ì¿¼ë¦¬ ì¬ì‘ì„±
            }
        )
        
        return workflow.compile()
    
    def _retrieve_node(self, state: CRAGState) -> dict:
        """ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ (similarity score í¬í•¨, top_k=5)"""
        question = state['question']
        
        if self.debug:
            print("\n" + "="*80)
            print("ğŸ“ [1/5] RETRIEVE NODE - top_k=5 ë²¡í„°DB ê²€ìƒ‰")
            print("="*80)
            print(f"â“ ì§ˆë¬¸: {question}\n")
        
        # retrieverê°€ retrieve_with_scores ë©”ì„œë“œë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
        if hasattr(self.retriever, 'retrieve_with_scores'):
            doc_scores = self.retriever.retrieve_with_scores(question)
            documents = [doc for doc, _ in doc_scores]
            scores = [score for _, score in doc_scores]
        elif hasattr(self.retriever, 'vectorstore'):
            # ThresholdRetrieverì˜ vectorstoreì— ì§ì ‘ ì ‘ê·¼
            results = self.retriever.vectorstore.similarity_search_with_score(question, k=5)
            documents = []
            scores = []
            for doc, distance in results:
                # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜
                similarity_score = 1.0 - distance if distance <= 1.0 else max(0.0, 1.0 - distance)
                doc.metadata['similarity_score'] = similarity_score
                documents.append(doc)
                scores.append(similarity_score)
        else:
            # ê¸°ë³¸ retriever ì‚¬ìš©
            documents = self.retriever.invoke(question)
            scores = [0.0] * len(documents)
            if self.debug:
                print("âš ï¸ ê²½ê³ : Retrieverê°€ similarity scoreë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        if self.debug:
            print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ ë°˜í™˜ (top_k=5)")
            print(f"\nğŸ“‹ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (similarity ê¸°ë°˜ ìƒìœ„ 5ê°œ):")
            for i, (doc, score) in enumerate(zip(documents, scores), 1):
                source = doc.metadata.get('file_name', 'unknown')
                dept = doc.metadata.get('department', '')
                dept_str = f" | {dept}" if dept else ""
                content_preview = doc.page_content[:70].replace('\n', ' ')
                print(f"   [{i}] ğŸ“„ {source}{dept_str}")
                print(f"       ì ìˆ˜: {score:.4f}")
                print(f"       ë‚´ìš©: {content_preview}...\n")
        
        return {
            'documents': documents,
            'document_scores': scores,
            'question': question,
            'original_question': question  # ì›ë³¸ ì§ˆë¬¸ ì €ì¥
        }
    
    def _grade_documents_node(self, state: CRAGState) -> dict:
        """ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ (Yes/No ê¸°ì¤€)"""
        question = state['question']
        documents = state['documents']
        filtered_docs = []
        grade_results = []
        
        if self.debug:
            print("\n" + "="*80)
            print("ğŸ“ [2/5] GRADE DOCUMENTS NODE - LLM ê´€ë ¨ì„± í‰ê°€ (0.5 threshold)")
            print("="*80)
            print(f"â“ ì§ˆë¬¸: {question}")
            print(f"ğŸ“Š í‰ê°€í•  ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ\n")
        
        for idx, doc in enumerate(documents, 1):
            try:
                source = doc.metadata.get('file_name', 'unknown')
                content_preview = doc.page_content[:60].replace('\n', ' ')
                similarity_score = doc.metadata.get('similarity_score', 0.0)
                
                if self.debug:
                    print(f"   ğŸ“„ [{idx}] {source} (similarity: {similarity_score:.4f})")
                    print(f"       ë‚´ìš©: {content_preview}...")
                
                # LLMìœ¼ë¡œ ê´€ë ¨ì„± í‰ê°€ (Yes/No)
                score_result = self.document_grader.invoke({
                    'question': question,
                    'document': doc.page_content
                })
                grade = score_result.binary_score.lower().strip()
                
                # yesì¸ ë¬¸ì„œë§Œ í•„í„°ë§
                if grade == 'yes':
                    filtered_docs.append(doc)
                    grade_results.append("YES")
                    if self.debug:
                        print(f"       âœ… ê´€ë ¨ìˆìŒ (yes)")
                else:
                    grade_results.append("NO")
                    if self.debug:
                        print(f"       âŒ ê´€ë ¨ì—†ìŒ (no)")
            except Exception as e:
                print(f"       âš ï¸ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
                grade_results.append("ERROR")
        
        # ìµœì¢… ê²°ê³¼ í†µê³„
        relevant_docs_count = len(filtered_docs)
        
        if self.debug:
            print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼ ìš”ì•½:")
            print(f"   âœ… ê´€ë ¨ìˆìŒ: {sum(1 for r in grade_results if r == 'YES')}ê°œ")
            print(f"   âŒ ê´€ë ¨ì—†ìŒ: {sum(1 for r in grade_results if r == 'NO')}ê°œ")
            print(f"   ğŸ¯ ìµœì¢… ê´€ë ¨ ë¬¸ì„œ ìˆ˜: {relevant_docs_count}ê°œ")
        
        # Fallback ì´ìœ  ì„¤ì •
        web_search_reason = ""
        if relevant_docs_count == 0:
            web_search_reason = "ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ 0ê°œ"
        
        return {
            "filtered_documents": filtered_docs,
            "relevance_scores": [],  # yes/no ë°©ì‹ì´ë¯€ë¡œ ì ìˆ˜ ì—†ìŒ
            "web_search_needed": "Yes" if relevant_docs_count == 0 else "No",
            "web_search_reason": web_search_reason,
            "grade_results": grade_results
        }
    
    def _decide_to_generate(self, state: CRAGState) -> Literal["generate", "web_search"]:
        """
        ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (ìƒì„± ë˜ëŠ” ì›¹ ê²€ìƒ‰)
        
        ê°œì„ ëœ ë¡œì§ (Threshold ê¸°ë°˜):
        - avg_relevance_score >= THRESHOLD â†’ GENERATE (ë‚´ë¶€ ë¬¸ì„œ ë‹µë³€)
        - avg_relevance_score < THRESHOLD â†’ WEB_SEARCH (ì›¹ ê²€ìƒ‰)
        """
        filtered_docs = state.get("filtered_documents", [])
        document_scores = state.get("document_scores", [])
        RELEVANCE_THRESHOLD = 0.5  # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€
        MIN_DOCS_THRESHOLD = 1  # ìµœì†Œ ë¬¸ì„œ ìˆ˜
        
        if self.debug:
            print("\n" + "="*80)
            print("ğŸ“ [3/5] DECISION NODE - ë‹¤ìŒ ë£¨íŠ¸ ê²°ì • (Threshold ê¸°ë°˜)")
            print("="*80)
            print(f"ğŸ“Š ê´€ë ¨ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)}ê°œ")
            if document_scores:
                avg_score = sum(document_scores) / len(document_scores)
                print(f"ğŸ“Š Similarity Score í‰ê· : {avg_score:.4f}")
        
        relevant_docs_count = len(filtered_docs)
        
        if self.debug:
            print(f"\nğŸ“‹ íŒì • ê¸°ì¤€:")
            print(f"   - ê´€ë ¨ ë¬¸ì„œ ìµœì†Œ ê°œìˆ˜: {MIN_DOCS_THRESHOLD}ê°œ")
            print(f"   - ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€(Threshold): {RELEVANCE_THRESHOLD}")
            print(f"   - ì›¹ ê²€ìƒ‰ API ê°€ìš©: {self.web_search_available}")
        
        # ê°œì„ ëœ ì¡°ê±´ íŒì •
        # 1. ê´€ë ¨ ë¬¸ì„œê°€ ìµœì†Œ ê°œìˆ˜ ì´ìƒì´ë©´ì„œ
        # 2. í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ê°€ Threshold ì´ìƒì¸ ê²½ìš°ë§Œ ë‚´ë¶€ ë¬¸ì„œë¡œ ë‹µë³€
        if relevant_docs_count >= MIN_DOCS_THRESHOLD:
            # ì ìˆ˜ ê¸°ë°˜ í‰ê°€
            if document_scores:
                avg_score = sum(document_scores) / len(document_scores)
                
                # ë†’ì€ ì‹ ë¢°ë„ â†’ ë‚´ë¶€ ë¬¸ì„œ ì‚¬ìš©
                if avg_score >= RELEVANCE_THRESHOLD:
                    if self.debug:
                        print(f"\nâœ… ê²°ì •: GENERATE ë£¨íŠ¸")
                        print(f"   â†’ ì´ìœ : í‰ê·  ì ìˆ˜ {avg_score:.4f} >= {RELEVANCE_THRESHOLD}")
                        print(f"   â†’ ë‚´ë¶€ ë¬¸ì„œ ê¸°ë°˜ ê³ í’ˆì§ˆ ë‹µë³€ ìƒì„±")
                    return "generate"
                # ë‚®ì€ ì‹ ë¢°ë„ â†’ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„
                else:
                    if self.debug:
                        print(f"\nğŸŒ ê²°ì •: WEB_SEARCH ë£¨íŠ¸")
                        print(f"   â†’ ì´ìœ : í‰ê·  ì ìˆ˜ {avg_score:.4f} < {RELEVANCE_THRESHOLD}")
                        print(f"   â†’ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë” ë‚˜ì€ ì •ë³´ íšë“")
                    return "web_search" if self.web_search_available else "generate"
            else:
                # ì ìˆ˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¬¸ì„œ ê°œìˆ˜ë¡œ íŒì •
                if self.debug:
                    print(f"\nâœ… ê²°ì •: GENERATE ë£¨íŠ¸ (ì ìˆ˜ ì •ë³´ ì—†ìŒ)")
                return "generate"
        
        # ê´€ë ¨ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì›¹ ê²€ìƒ‰
        else:
            if self.web_search_available:
                if self.debug:
                    print(f"\nğŸŒ ê²°ì •: WEB_SEARCH ë£¨íŠ¸")
                    print(f"   â†’ ì´ìœ : ê´€ë ¨ ë¬¸ì„œ ë¶€ì¡± (0ê°œ)")
                    print(f"   â†’ ì›¹ì—ì„œ ì •ë³´ ê²€ìƒ‰")
                return "web_search"
            else:
                # ì›¹ ê²€ìƒ‰ API ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ë‚´ë¶€ ë¬¸ì„œë¡œ ì§„í–‰
                if self.debug:
                    print(f"\nâš ï¸ ê²°ì •: GENERATE ë£¨íŠ¸ (ì›¹ ê²€ìƒ‰ API ë¶ˆê°€)")
                    print(f"   â†’ ì›¹ ê²€ìƒ‰ API ë¶ˆê°€ëŠ¥ â†’ ë‚´ë¶€ ë¬¸ì„œë¡œ ì§„í–‰")
                return "generate"
    
    def _query_rewrite_node(self, state: CRAGState) -> dict:
        """
        ì›¹ ê²€ìƒ‰ìš© ì¿¼ë¦¬ ìµœì í™” ë…¸ë“œ
        Fail ìƒí™©ì—ì„œëŠ” ë” ê°œì„ ëœ ì¿¼ë¦¬ ì‘ì„±
        """
        question = state["question"]
        rewrite_count = state.get("rewrite_count", 0)
        is_rewrite = rewrite_count > 0  # ì¬ì‘ì„±ì¸ì§€ ì²˜ìŒì¸ì§€ í™•ì¸
        
        if self.debug:
            if is_rewrite:
                print("\n" + "="*80)
                print(f"ğŸ“ QUERY REWRITE NODE (ì¬ì‹œë„ {rewrite_count}) - ì¿¼ë¦¬ ê°œì„ ")
                print("="*80)
            else:
                print("\n" + "="*80)
                print("ğŸ“ [3-1/5] QUERY REWRITE NODE - ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”")
                print("="*80)
            print(f"â“ ì›ë³¸ ì§ˆë¬¸: {question}\n")
        
        try:
            # ì¬ì‘ì„±ì¸ ê²½ìš° ë” ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            if is_rewrite:
                rewrite_prompt = ChatPromptTemplate.from_messages([
                    ("system", """ì´ì „ ë‹µë³€ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
ë” ë‚˜ì€ ë‹µë³€ì„ ì–»ê¸° ìœ„í•´ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ê°œì„ í•˜ì„¸ìš”.

ê°œì„  ë°©ë²•:
1. í•µì‹¬ í‚¤ì›Œë“œ ê°•ì¡°
2. ì¶”ê°€ ë§¥ë½ í¬í•¨
3. ë™ì˜ì–´ë‚˜ ê´€ë ¨ ìš©ì–´ ì¶”ê°€
4. êµ¬ì²´ì ì¸ ì˜ˆì‹œ ë˜ëŠ” ì„¸ë¶€ì‚¬í•­ í¬í•¨"""),
                    ("human", "{question}")
                ])
            else:
                query_rewriter = self._setup_query_rewriter()
                optimized_query = query_rewriter.invoke({"question": question}).strip()
                
                if self.debug:
                    print(f"ğŸ” ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {optimized_query}")
                    print(f"   â†’ ì´ ì¿¼ë¦¬ë¡œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰í•©ë‹ˆë‹¤\n")
                
                return {
                    "question": optimized_query,
                    "rewrite_count": rewrite_count + 1
                }
            
            # ì¬ì‘ì„±ìš© LLM
            rewriter = self.llm.with_structured_output(
                type("QueryRewrite", (), {"query": str})
            )
            
            improved_question = rewrite_prompt | self.llm | StrOutputParser()
            optimized_query = improved_question.invoke({"question": question}).strip()
            
            if self.debug:
                print(f"ğŸ”„ ê°œì„ ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {optimized_query}\n")
        
        except Exception as e:
            if self.debug:
                print(f"âš ï¸ ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨: {str(e)}")
                print(f"   â†’ ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰ ì§„í–‰")
            optimized_query = question
        
        return {
            "question": optimized_query,
            "rewrite_count": rewrite_count + 1
        }
    
    def _web_search_node(self, state: CRAGState) -> dict:
        """ì›¹ ê²€ìƒ‰ ë…¸ë“œ (ìµœì í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©, ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš°ì„ ìˆœìœ„ ë†’ê²Œ ë°°ì¹˜)"""
        question = state["question"]  # ì´ë¯¸ ìµœì í™”ëœ ì¿¼ë¦¬
        original_question = state.get("original_question", question)
        filtered_docs = state.get("filtered_documents", [])
        
        if self.debug:
            print("\n" + "="*80)
            print("ğŸ“ [3-2/5] WEB SEARCH NODE - Tavily APIë¡œ ì›¹ ê²€ìƒ‰")
            print("="*80)
            print(f"â“ ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {question}")
            print(f"ğŸ“Š í˜„ì¬ ë³´ìœ  ë¬¸ì„œ: {len(filtered_docs)}ê°œ\n")
        
        web_results = []
        try:
            if self.debug:
                print("ğŸ” Tavily APIë¡œ ì›¹ ê²€ìƒ‰ ì¤‘...")
            
            # Tavily APIë¡œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (ìµœì í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©)
            web_results = self.web_search.invoke(question)
            
            if self.debug:
                print(f"âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {len(web_results)}ê°œ ê²°ê³¼")
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ Documentë¡œ ë³€í™˜í•˜ê³  ë©”íƒ€ë°ì´í„° ì„¤ì •
            web_docs = []
            for i, doc in enumerate(web_results, 1):
                if isinstance(doc, Document):
                    # ì›¹ ê²€ìƒ‰ ê²°ê³¼ì„ì„ ëª…ì‹œ
                    doc.metadata['source'] = doc.metadata.get('source', 'web')
                    doc.metadata['source_type'] = 'web'
                    doc.metadata['search_query'] = question  # ì‚¬ìš©ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ê¸°ë¡
                    web_docs.append(doc)
                    if self.debug:
                        source = doc.metadata.get('source', 'web')
                        content_preview = doc.page_content[:70].replace('\n', ' ')
                        print(f"   [{i}] ğŸŒ {source}")
                        print(f"       ë‚´ìš©: {content_preview}...")
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš°ì„ ìˆœìœ„ ë†’ê²Œ ë°°ì¹˜ (ì•ì— ë°°ì¹˜)
            final_docs = web_docs + filtered_docs
            
            if self.debug:
                print(f"\nâœ… ì›¹ ê²€ìƒ‰ ê²°ê³¼ í†µí•© ì™„ë£Œ")
                print(f"ğŸ“Š ìµœì¢… ë¬¸ì„œ ìˆ˜: {len(final_docs)}ê°œ (ì›¹: {len(web_docs)}ê°œ, ë‚´ë¶€: {len(filtered_docs)}ê°œ)")
                print(f"   â†’ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ë‚´ë¶€ ë¬¸ì„œë³´ë‹¤ ìš°ì„ ìˆœìœ„ ë†’ê²Œ ë°°ì¹˜ë¨")
        except Exception as e:
            if self.debug:
                print(f"âŒ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
                print("   â†’ ê¸°ì¡´ ë¬¸ì„œë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
            final_docs = filtered_docs
        
        return {
            "filtered_documents": final_docs
        }
    
    def _generate_node(self, state: CRAGState) -> dict:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ - ê´€ë ¨ ë¬¸ì„œ ì—¬ë¶€ì— ë”°ë¼ ì²˜ë¦¬"""
        question = state["question"]
        filtered_documents = state['filtered_documents']
        
        if self.debug:
            print("\n" + "="*80)
            print("ğŸ“ [4/5] GENERATE NODE - ìµœì¢… ë‹µë³€ ìƒì„±")
            print("="*80)
            print(f"â“ ì§ˆë¬¸: {question}")
            print(f"ğŸ“„ ì‚¬ìš©í•  ë¬¸ì„œ: {len(filtered_documents)}ê°œ\n")
            
            # ë¬¸ì„œ ì¶œì²˜ ì •ë³´ í‘œì‹œ
            if filtered_documents:
                print(f"ğŸ“‹ ì‚¬ìš© ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸:")
                for i, doc in enumerate(filtered_documents[:5], 1):
                    source = doc.metadata.get('file_name', doc.metadata.get('source', 'unknown'))
                    source_type = doc.metadata.get('source_type', 'internal')
                    type_marker = 'ğŸŒ' if source_type == 'web' else 'ğŸ“„'
                    dept = doc.metadata.get('department', '')
                    dept_str = f" | {dept}" if dept else ""
                    print(f"   [{i}] {type_marker} {source}{dept_str}")
                if len(filtered_documents) > 5:
                    print(f"   ... ì™¸ {len(filtered_documents) - 5}ê°œ")
                print()
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._format_docs(filtered_documents)
        
        if self.debug:
            print(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°: {len(context):,} ë¬¸ì")
        
        # ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨ ì—¬ë¶€ í™•ì¸
        has_web_search = any(doc.metadata.get('source_type') == 'web' for doc in filtered_documents)
        
        # ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨ ì‹œ ë” ìœ ì—°í•˜ê²Œ)
        if has_web_search:
            system_prompt = """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ê·œì¹™:
1. ì œê³µëœ ë¬¸ì„œ(ë¬¸ë§¥)ì— ìˆëŠ” ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ë¶ˆì™„ì „í•œ ì •ë³´ë¼ë„ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ê³  ì¡°í•©í•˜ì—¬ ë‹µë³€ì„ êµ¬ì„±í•˜ì„¸ìš”.
3. ì—¬ëŸ¬ ì¶œì²˜ì˜ ì •ë³´ë¥¼ í†µí•©í•  ë•ŒëŠ” ê° ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œê¸°í•˜ì„¸ìš” (ì˜ˆ: "ABC ì¶œì²˜ì— ë”°ë¥´ë©´...", "OOO ì›¹ì‚¬ì´íŠ¸ì—ì„œëŠ”...").
4. ì •ë³´ì˜ ì‹ ë¢°ì„±ì´ ë‚®ê±°ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš°, ì´ë¥¼ ëª…ì‹œí•˜ì„¸ìš” (ì˜ˆ: "í•´ë‹¹ ì •ë³´ëŠ” í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤").
5. ì™„ì „íˆ ë‹¤ë¥¸ ì£¼ì œì˜ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
6. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
7. ê°€ëŠ¥í•˜ë©´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."""
        else:
            system_prompt = """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ê·œì¹™:
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ(ë¬¸ë§¥)ì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ë‚˜ ì‚¬ì‹¤ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
3. ë¬¸ì„œì— ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´, "ì œê³µëœ ë¬¸ì„œì—ëŠ” ì´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
4. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
5. ê°€ëŠ¥í•˜ë©´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", """ë¬¸ë§¥(ì°¸ê³  ë¬¸ì„œ):
{context}

ì§ˆë¬¸: {question}

ìœ„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.""")
        ])
        
        if self.debug:
            print("ğŸ¤– LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
        
        chain = prompt | self.llm | StrOutputParser()
        answer = chain.invoke({"context": context, "question": question})
        
        if self.debug:
            answer_preview = answer[:100].replace('\n', ' ')
            print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            print(f"   ë¯¸ë¦¬ë³´ê¸°: {answer_preview}...\n")
        
        # ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘
        sources = []
        for doc in filtered_documents:
            source_type = doc.metadata.get('source_type', 'internal')
            sources.append({
                'file_name': doc.metadata.get('file_name', doc.metadata.get('source', 'unknown')),
                'source_path': doc.metadata.get('source_path', 'unknown'),
                'department': doc.metadata.get('department', 'unknown'),
                'title': doc.metadata.get('title', 'unknown'),
                'type': source_type
            })
        
        return {
            "context": context,
            "answer": answer,
            "sources": sources,
            "rewrite_count": state.get("rewrite_count", 0)  # Rewrite ì¹´ìš´íŠ¸ ìœ ì§€
        }
    
    def _evaluate_answer_node(self, state: CRAGState) -> dict:
        """
        ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆ í‰ê°€ ë…¸ë“œ
        
        í‰ê°€ ê¸°ì¤€:
        - ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í–ˆëŠ”ê°€?
        - ì •ë³´ê°€ ì¶©ë¶„í•œê°€?
        - ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
        """
        question = state["question"]
        answer = state["answer"]
        
        if self.debug:
            print("\n" + "="*80)
            print("ğŸ“ [5/5] EVALUATE ANSWER NODE - ë‹µë³€ í’ˆì§ˆ í‰ê°€")
            print("="*80)
            print(f"â“ ì§ˆë¬¸: {question}")
            print(f"ğŸ“ ë‹µë³€: {answer[:150].replace(chr(10), ' ')}...\n")
        
        # í‰ê°€ í”„ë¡¬í”„íŠ¸
        evaluation_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ AI ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            
í‰ê°€ ê¸°ì¤€:
1. ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í–ˆëŠ”ê°€? (ë‹µë³€ì´ ì§ˆë¬¸ì˜ ì£¼ìš” ë‚´ìš©ì„ ë‹¤ë£¨ê³  ìˆëŠ”ê°€?)
2. ì •ë³´ê°€ ì¶©ë¶„í•œê°€? (í•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?)
3. ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€? (ë…¼ë¦¬ì ì´ê³  êµ¬ì¡°í™”ë˜ì–´ ìˆëŠ”ê°€?)

ë‹µë³€ì„ í‰ê°€í•˜ê³  'PASS' ë˜ëŠ” 'FAIL'ë¡œ íŒì •í•˜ì„¸ìš”.
ë§Œì•½ FAILì´ë©´ ê°œì„ í•  ì ì„ ê°„ë‹¨íˆ ê¸°ìˆ í•˜ì„¸ìš”."""),
            ("human", """ì§ˆë¬¸: {question}

ë‹µë³€: {answer}

í‰ê°€ ê²°ê³¼ (PASS/FAIL)ì™€ ì´ìœ ë¥¼ ì œì‹œí•˜ì„¸ìš”.""")
        ])
        
        # êµ¬ì¡°í™”ëœ ì¶œë ¥ ì„¤ì •
        class AnswerEvaluation(BaseModel):
            quality_score: str = Field(description="PASS ë˜ëŠ” FAIL")
            reason: str = Field(description="í‰ê°€ ì‚¬ìœ ")
        
        evaluator = self.grader_llm.with_structured_output(AnswerEvaluation)
        chain = evaluation_prompt | evaluator
        
        evaluation = chain.invoke({
            "question": question,
            "answer": answer
        })
        
        quality = evaluation.quality_score.upper()
        if "PASS" in quality:
            quality = "pass"
        else:
            quality = "fail"
        
        if self.debug:
            print(f"â­ í‰ê°€ ê²°ê³¼: {quality.upper()}")
            print(f"ğŸ“Œ í‰ê°€ ì‚¬ìœ : {evaluation.reason}\n")
        
        return {
            "answer_quality": quality,
            "answer_quality_reason": evaluation.reason,
            "rewrite_count": state.get("rewrite_count", 0)
        }
    
    def _decide_after_evaluation(self, state: CRAGState) -> Literal["end", "rewrite"]:
        """
        í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ìµœì¢… ë‹µë³€ ë˜ëŠ” ì¬ì‘ì„± ê²°ì •
        """
        quality = state.get("answer_quality", "fail")
        rewrite_count = state.get("rewrite_count", 0)
        max_rewrites = 2  # ìµœëŒ€ 2íšŒ ì¬ì‘ì„±
        
        if self.debug:
            print(f"\nğŸ”€ í‰ê°€ ê²°ê³¼ ë¼ìš°íŒ… - Quality: {quality}, Rewrites: {rewrite_count}/{max_rewrites}")
        
        # PASS ë˜ëŠ” ìµœëŒ€ ì¬ì‘ì„± íšŸìˆ˜ ë„ë‹¬ ì‹œ ì¢…ë£Œ
        if quality == "pass" or rewrite_count >= max_rewrites:
            return "end"
        else:
            return "rewrite"
    
    def _format_docs(self, docs: List[Document]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ… (ì›¹ ê²€ìƒ‰ ê²°ê³¼ êµ¬ë¶„)"""
        formatted = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get('file_name', doc.metadata.get('source', 'unknown'))
            department = doc.metadata.get('department', '')
            source_type = doc.metadata.get('source_type', 'internal')
            dept_str = f" ({department})" if department else ""
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ì¸ì§€ í‘œì‹œ
            type_marker = "[ì›¹ ê²€ìƒ‰ ê²°ê³¼]" if source_type == 'web' else "[ë‚´ë¶€ ë¬¸ì„œ]"
            formatted.append(
                f"{type_marker} [ë¬¸ì„œ {i} - {source}{dept_str}]\n{doc.page_content}"
            )
        return "\n\n---\n\n".join(formatted) if formatted else "ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    def rag_pipeline(self, query: str) -> str:
        """
        RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            ë‹µë³€ ë¬¸ìì—´
        """
        try:
            if self.debug:
                print("\n" + "ğŸš€"*40)
                print("ğŸš€ RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘ ğŸš€".center(80))
                print("ğŸš€"*40)
            
            initial_state = {
                "question": query,
                "original_question": query,
                "documents": [],
                "document_scores": [],
                "filtered_documents": [],
                "relevance_scores": [],
                "web_search_needed": "No",
                "web_search_reason": "",
                "context": "",
                "answer": "",
                "grade_results": [],
                "sources": []
            }
            
            result = self.app.invoke(initial_state)
            
            if self.debug:
                print("\n" + "="*80)
                print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
                print("="*80)
                # ìµœì¢… Debug Log ì¶œë ¥
                print("\nğŸ“Š ìµœì¢… Debug Log:")
                doc_scores = result.get('document_scores', [])
                if doc_scores:
                    print(f"   - Top-K ë¬¸ì„œ Similarity Score: {[f'{s:.4f}' for s in doc_scores]}")
                print(f"   - Threshold í•„í„° ì´í›„ ë‚¨ì€ ë¬¸ì„œ ìˆ˜: {len(result.get('filtered_documents', []))}ê°œ")
                relevance_scores = result.get('relevance_scores', [])
                if relevance_scores:
                    avg_relevance = sum(relevance_scores) / len(relevance_scores)
                    print(f"   - ìµœì¢… Relevance Score í‰ê· : {avg_relevance:.4f}")
                print(f"   - Fallback ì—¬ë¶€: {'ì›¹ ê²€ìƒ‰ ì‹¤í–‰' if result.get('web_search_needed') == 'Yes' else 'ë‚´ë¶€ ë¬¸ì„œ ì‚¬ìš©'}")
                if result.get('web_search_reason'):
                    print(f"   - ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì´ìœ : {result.get('web_search_reason')}")
                print()
            
            return result.get('answer', 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        except Exception as e:
            error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            if self.debug:
                print(f"\nâŒ {error_msg}")
            return error_msg
    
    def rag_pipeline_with_sources(self, query: str) -> Dict[str, Any]:
        """
        RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì¶œì²˜ ì •ë³´ í¬í•¨)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            ë‹µë³€ê³¼ ì¶œì²˜ ì •ë³´ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if self.debug:
                print("\n" + "ğŸš€"*40)
                print("ğŸš€ RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘ ğŸš€".center(80))
                print("ğŸš€"*40)
            
            initial_state = {
                "question": query,
                "original_question": query,
                "documents": [],
                "document_scores": [],
                "filtered_documents": [],
                "relevance_scores": [],
                "web_search_needed": "No",
                "web_search_reason": "",
                "context": "",
                "answer": "",
                "grade_results": [],
                "sources": [],
                "answer_quality": "fail",  # í‰ê°€ ì´ˆê¸°ê°’
                "answer_quality_reason": "",
                "rewrite_count": 0  # Rewrite ì¹´ìš´íŠ¸
            }
            
            result = self.app.invoke(initial_state)
            
            if self.debug:
                print("\n" + "="*80)
                print("âœ… RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
                print("="*80)
                
                # ìµœì¢… ê²°ê³¼ ìš”ì•½
                print("\nğŸ“Š ìµœì¢… ì‹¤í–‰ ê²°ê³¼:")
                
                # 1. Top-K ê²€ìƒ‰ ê²°ê³¼
                doc_scores = result.get('document_scores', [])
                print(f"\n[1] Top-K=5 ê²€ìƒ‰ ê²°ê³¼:")
                if doc_scores:
                    print(f"   ë°˜í™˜ëœ ë¬¸ì„œ ìˆ˜: {len(doc_scores)}ê°œ")
                    scores_str = ", ".join([f"{s:.4f}" for s in doc_scores])
                    print(f"   Similarity Scores: [{scores_str}]")
                else:
                    print(f"   (ì ìˆ˜ ì •ë³´ ì—†ìŒ)")
                
                # 2. ê´€ë ¨ì„± íŒì • ê²°ê³¼
                grade_results = result.get('grade_results', [])
                print(f"\n[2] ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± íŒì • ê²°ê³¼:")
                if grade_results:
                    print(f"   íŒì • ê²°ê³¼: {grade_results}")
                    yes_count = sum(1 for g in grade_results if g == 'YES')
                    no_count = sum(1 for g in grade_results if g == 'NO')
                    print(f"   ê´€ë ¨ìˆìŒ(YES): {yes_count}ê°œ, ê´€ë ¨ì—†ìŒ(NO): {no_count}ê°œ")
                
                # 3. ê´€ë ¨ ë¬¸ì„œ ìˆ˜
                filtered_docs = result.get('filtered_documents', [])
                relevant_docs_count = len(filtered_docs)
                print(f"\n[3] ê´€ë ¨ ë¬¸ì„œ ìˆ˜ (relevant_docs_count):")
                print(f"   {relevant_docs_count}ê°œ")
                
                # 4. ì„ íƒëœ ê²½ë¡œ
                web_search_needed = result.get('web_search_needed', 'No')
                web_search_reason = result.get('web_search_reason', '')
                path = "WEB-SEARCH" if web_search_needed == 'Yes' else "INTERNAL"
                print(f"\n[4] ì„ íƒëœ ê²½ë¡œ:")
                print(f"   â†’ {path} ë£¨íŠ¸")
                if web_search_reason:
                    print(f"   ì´ìœ : {web_search_reason}")
                else:
                    print(f"   ì´ìœ : ê´€ë ¨ ë‚´ë¶€ ë¬¸ì„œ {relevant_docs_count}ê°œ ì‚¬ìš©")
                
                # 5. ìµœì¢… ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°
                answer = result.get('answer', '(ë‹µë³€ ì—†ìŒ)')
                answer_preview = answer[:80].replace('\n', ' ')
                print(f"\n[5] ìµœì¢… ë‹µë³€ (ë¯¸ë¦¬ë³´ê¸°):")
                print(f"   {answer_preview}...")
                print()
            
            return {
                'answer': result.get('answer', 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'),
                'sources': result.get('sources', []),
                'num_sources': len(result.get('sources', [])),
                'document_scores': result.get('document_scores', []),
                'relevance_scores': result.get('relevance_scores', []),
                'grade_results': result.get('grade_results', []),
                'web_search_needed': result.get('web_search_needed', 'No'),
                'web_search_reason': result.get('web_search_reason', '')
            }
        except Exception as e:
            error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            if self.debug:
                print(f"\nâŒ {error_msg}")
            return {
                'answer': error_msg,
                'sources': [],
                'num_sources': 0
            }


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ RAGPipeline í´ë˜ìŠ¤ ì •ì˜
class RAGPipeline:
    """
    RAG íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
    """
    def __init__(
        self,
        retriever: BaseRetriever,
        llm_model: str = "gpt-4o-mini",
        temperature: float = 0.0
    ):
        """
        Args:
            retriever: ë¬¸ì„œ ê²€ìƒ‰ê¸°
            llm_model: LLM ëª¨ë¸ ì´ë¦„
            temperature: LLM temperature
        """
        self.retriever = retriever
        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)
        self.chain = self._build_chain()
    
    def _build_chain(self):
        """
        RAG ì²´ì¸ êµ¬ì„±
        """
        # Hallucination ë°©ì§€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        prompt = ChatPromptTemplate.from_messages([
            ('system', '''ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì¤‘ìš”í•œ ê·œì¹™:
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ(ë¬¸ë§¥)ì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ë‚˜ ì‚¬ì‹¤ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
3. ë¬¸ì„œì— ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´, ì†”ì§í•˜ê²Œ "ì œê³µëœ ë¬¸ì„œì—ëŠ” ì´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤" ë˜ëŠ” "ë¬¸ì„œë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
4. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
5. ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
6. ê°€ëŠ¥í•˜ë©´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.'''),
            ('human', '''ë¬¸ë§¥(ì°¸ê³  ë¬¸ì„œ):
{context}

ì§ˆë¬¸: {question}

ìœ„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.''')
        ])
        
        # ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜
        def format_docs(docs: List[Document]) -> str:
            """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
            formatted = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata.get('file_name', 'unknown')
                department = doc.metadata.get('department', 'unknown')
                formatted.append(
                    f"[ë¬¸ì„œ {i} - ì¶œì²˜: {source}, ì§„ë£Œê³¼: {department}]\n{doc.page_content}"
                )
            return "\n\n---\n\n".join(formatted)
        
        # RAG ì²´ì¸ êµ¬ì„±
        chain = (
            {
                "context": self.retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )
        
        return chain
    
# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ RAGPipeline í´ë˜ìŠ¤ ì •ì˜
class RAGPipeline:
    """
    ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ (í•˜ìœ„ í˜¸í™˜ì„±)
    LangGraphRAGPipelineì˜ ë³„ì¹­ìœ¼ë¡œ ì‘ë™
    """
    def __init__(
        self,
        retriever: BaseRetriever,
        llm_model: str = "gpt-4o-mini",
        temperature: float = 0.0
    ):
        self._pipeline = LangGraphRAGPipeline(retriever, llm_model, temperature, debug=True)
    
    def rag_pipeline(self, query: str) -> str:
        return self._pipeline.rag_pipeline(query)
    
    def rag_pipeline_with_sources(self, query: str) -> Dict[str, Any]:
        return self._pipeline.rag_pipeline_with_sources(query)


def create_rag_pipeline(
    retriever: BaseRetriever,
    llm_model: str = "gpt-4o-mini",
    temperature: float = 0.0,
    use_langgraph: bool = True,
    debug: bool = True
) -> RAGPipeline:
    """
    RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    
    Args:
        retriever: ë¬¸ì„œ ê²€ìƒ‰ê¸°
        llm_model: LLM ëª¨ë¸ ì´ë¦„
        temperature: LLM temperature
        use_langgraph: LangGraph CRAG íŒ¨í„´ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        debug: ë””ë²„ê¹… ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        
    Returns:
        RAGPipeline ê°ì²´
    """
    return RAGPipeline(retriever, llm_model, temperature)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    from embeddings import load_vectorstore, get_embedding_model
    from retrieval import create_retriever
    from dotenv import load_dotenv
    
    load_dotenv()
    
    # ë²¡í„°ìŠ¤í† ì–´ ë° retriever ë¡œë“œ
    embedding_model = get_embedding_model("openai")
    vectorstore = load_vectorstore(
        embedding_model,
        persist_directory="./chroma_db",
        collection_name="rag_collection"
    )
    
    retriever = create_retriever(
        vectorstore,
        k=10,
        rerank_k=5,
        use_reranking=True,
        embedding_model=embedding_model
    )
    
    # LangGraph CRAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    print("LangGraph CRAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...\n")
    pipeline_crag = LangGraphRAGPipeline(retriever, debug=True)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ê°•ì•„ì§€ ëª¸ì— ë‘ë“œëŸ¬ê¸°ê°€ ë‚¬ì–´ìš”. ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œìš”?",
        "ë²¼ë£© ì•ŒëŸ¬ì§€ì„± í”¼ë¶€ì—¼ì˜ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "GPT-5ì˜ ìµœì‹  ê¸°ëŠ¥ì€?",  # ë¬¸ì„œì— ì—†ëŠ” ì¿¼ë¦¬ â†’ ì›¹ ê²€ìƒ‰ íŠ¸ë¦¬ê±°
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\n{'#'*80}")
        print(f"# í…ŒìŠ¤íŠ¸ {i}/{len(test_queries)}")
        print(f"{'#'*80}")
        
        result = pipeline_crag.rag_pipeline_with_sources(query)
        
        print(f"\nğŸ“‹ ìµœì¢… ë‹µë³€:")
        print(f"\n{result['answer']}\n")

