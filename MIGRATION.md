# ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ - ê¸°ì¡´ ì½”ë“œì—ì„œ ìƒˆ êµ¬ì¡°ë¡œ

## ğŸ“ ê°œìš”

ì´ ê°€ì´ë“œëŠ” ê¸°ì¡´ì˜ ë‹¨ì¼ íŒŒì¼ êµ¬ì¡°ì—ì„œ ì±…ì„ë¶„ë¦¬(SoC) ê¸°ë°˜ì˜ ëª¨ë“ˆ êµ¬ì¡°ë¡œ ì „í™˜í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ”„ ì£¼ìš” ë³€ê²½ ì‚¬í•­

| êµ¬ë¶„ | ì´ì „ | ì´í›„ |
|------|------|------|
| **êµ¬ì¡°** | `advanced_rag_pipeline.py` (ë‹¨ì¼ íŒŒì¼) | ëª¨ë“ˆì‹ êµ¬ì¡° |
| **ì„¤ì •** | í™˜ê²½ë³€ìˆ˜ ë¶„ì‚° | `config/settings.py` í†µí•© |
| **ê²€ìƒ‰** | ê³ ì •ëœ ê²€ìƒ‰ ë¡œì§ | `InternalSearcher`, `WebSearcher` |
| **ë¶„ë¥˜** | `question_classifier.py` | `classifiers/question_classifier.py` |
| **ì²˜ë¦¬** | `medical_qa_handler.py`, `hospital_handler.py` | `handlers/*` |
| **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜** | `AdvancedRAGPipeline` | `RAGOrchestrator` |
| **ì¬ì‚¬ìš©ì„±** | ì œí•œì  | ë†’ìŒ (ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜) |

---

## ğŸ¯ ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„ë³„ ê°€ì´ë“œ

### 1ë‹¨ê³„: ê¸°ì¡´ ì½”ë“œ ë¶„ì„ ë° ë§¤í•‘

#### ì´ì „ êµ¬ì¡°
```python
# advanced_rag_pipeline.py
class AdvancedRAGPipeline:
    def __init__(self, vectorstore, hospital_json_path, llm_model, score_threshold):
        self.vectorstore = vectorstore
        self.classifier = QuestionClassifier(llm_model)
        self.medical_handler = MedicalQAHandler(vectorstore, llm_model, score_threshold)
        self.hospital_handler = HospitalHandler(hospital_json_path)
    
    def process_question(self, query):
        # ë¶„ë¥˜ â†’ ë¼ìš°íŒ… â†’ ì²˜ë¦¬
```

#### ìƒˆë¡œìš´ êµ¬ì¡°
```python
# pipelines/orchestrator.py
class RAGOrchestrator(BasePipeline):
    def __init__(self, vectorstore, hospital_json_path, llm_model, score_threshold):
        self.classifier = QuestionClassifier(llm_model)
        self.medical_handler = MedicalHandler(vectorstore, llm_model=llm_model, ...)
        self.hospital_handler = HospitalHandler(hospital_json_path)
    
    def process(self, query, **kwargs):
        # ë¶„ë¥˜ â†’ ë¼ìš°íŒ… â†’ ì²˜ë¦¬
```

### 2ë‹¨ê³„: Import ë¬¸ ë³€ê²½

#### ì´ì „
```python
from src.advanced_rag_pipeline import AdvancedRAGPipeline
from src.question_classifier import QuestionClassifier, QuestionType
from src.medical_qa_handler import MedicalQAHandler
from src.hospital_handler import HospitalHandler
from src.embeddings import get_embedding_model, load_vectorstore
```

#### ì´í›„
```python
from src import (
    RAGOrchestrator,
    QuestionClassifier,
    QuestionType,
    MedicalHandler,
    HospitalHandler,
    get_embedding_model,
    load_vectorstore
)
```

ë˜ëŠ” ì„¸ë¶„í™”ëœ import
```python
from src.pipelines import RAGOrchestrator
from src.classifiers import QuestionClassifier, QuestionType
from src.handlers import MedicalHandler, HospitalHandler
from src.core import get_embedding_model, load_vectorstore
```

### 3ë‹¨ê³„: ê¸°ë³¸ ì‚¬ìš©ë²• ë³€ê²½

#### ì´ì „
```python
from src.embeddings import get_embedding_model, load_vectorstore
from src.advanced_rag_pipeline import AdvancedRAGPipeline

embedding_model = get_embedding_model("openai")
vectorstore = load_vectorstore(embedding_model)

# AdvancedRAGPipeline ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
pipeline = AdvancedRAGPipeline(
    vectorstore=vectorstore,
    hospital_json_path="data/raw/hospital/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›_ì¸í—ˆê°€_ì •ë³´.json",
    llm_model="gpt-4o-mini",
    score_threshold=0.6
)

# ì§ˆë¬¸ ì²˜ë¦¬
result = pipeline.process_question("ê°•ì•„ì§€ í”¼ë¶€ì—¼ ì¦ìƒì€?")
```

#### ì´í›„
```python
from src import (
    RAGOrchestrator,
    get_embedding_model,
    load_vectorstore
)

embedding_model = get_embedding_model("openai")
vectorstore = load_vectorstore(embedding_model)

# RAGOrchestrator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
orchestrator = RAGOrchestrator(
    vectorstore=vectorstore,
    hospital_json_path="data/raw/hospital/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›_ì¸í—ˆê°€_ì •ë³´.json",
    llm_model="gpt-4o-mini",
    score_threshold=0.6
)

# ì§ˆë¬¸ ì²˜ë¦¬
result = orchestrator.process("ê°•ì•„ì§€ í”¼ë¶€ì—¼ ì¦ìƒì€?")
```

### 4ë‹¨ê³„: ë©”ì„œë“œ/ì†ì„± ë§¤í•‘

| ì´ì „ ë©”ì„œë“œ | ìƒˆë¡œìš´ ë©”ì„œë“œ | ë³€ê²½ ì‚¬í•­ |
|----------|-----------|---------|
| `process_question(query)` | `process(query)` | ì—†ìŒ |
| `interactive_mode()` | `interactive_mode()` | í˜¸í™˜ì„± ìœ ì§€ |
| `batch_process_questions(questions)` | `batch_process(queries)` | ì¸ìëª… ë³€ê²½ |
| `save_results(results, path)` | `save_results(results, path)` | í˜¸í™˜ì„± ìœ ì§€ |

### 5ë‹¨ê³„: ê²°ê³¼ êµ¬ì¡° ë³€ê²½ í™•ì¸

#### ì´ì „ ê²°ê³¼ êµ¬ì¡°
```python
result = {
    'question': str,
    'question_type': str,
    'timestamp': str,
    'answer': str,
    'sources': list,
    'formatted_answer': str,
    # ... ê¸°íƒ€ í•„ë“œ
}
```

#### ìƒˆë¡œìš´ ê²°ê³¼ êµ¬ì¡° (í˜¸í™˜ì„± ìœ ì§€)
```python
result = {
    'question': str,
    'question_type': str,
    'timestamp': str,
    'answer': str,
    'sources': list,
    'formatted_answer': str,
    'classification_type': str,         # ìƒˆë¡œ ì¶”ê°€
    'classification_reason': str,       # ìƒˆë¡œ ì¶”ê°€
    'classification_confidence': float, # ìƒˆë¡œ ì¶”ê°€
    # ... ê¸°íƒ€ í•„ë“œ
}
```

### 6ë‹¨ê³„: ì„¤ì • ë§ˆì´ê·¸ë ˆì´ì…˜

#### ì´ì „
```python
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o-mini")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
# ... ì—¬ëŸ¬ í™˜ê²½ë³€ìˆ˜
```

#### ì´í›„
```python
from src.config import get_settings
from dotenv import load_dotenv

load_dotenv()

settings = get_settings()
print(settings.llm.model)           # "gpt-4o-mini"
print(settings.llm.api_key)         # ìë™ ë¡œë“œ
print(settings.external_api.tavily_api_key)
```

---

## ğŸ”Œ ì„¸ë¶€ ë§ˆì´ê·¸ë ˆì´ì…˜

### MedicalQAHandler â†’ MedicalHandler

#### ì´ì „
```python
handler = MedicalQAHandler(
    vectorstore=vectorstore,
    llm_model="gpt-4o-mini",
    score_threshold=0.6,
    top_k=5
)

result = handler.handle_medical_question("í”¼ë¶€ì—¼ ì¦ìƒ?")
```

#### ì´í›„
```python
handler = MedicalHandler(
    vectorstore=vectorstore,
    llm_model="gpt-4o-mini",
    score_threshold=0.6,
    top_k=5
)

result = handler.handle("í”¼ë¶€ì—¼ ì¦ìƒ?")

# ë˜ëŠ” ì™¸ë¶€ ê²€ìƒ‰ê¸° ì§€ì •
from src.retrievers import InternalSearcher, WebSearcher

internal_searcher = InternalSearcher(vectorstore, top_k=5)
web_searcher = WebSearcher()

handler = MedicalHandler(
    vectorstore=vectorstore,
    internal_searcher=internal_searcher,
    web_searcher=web_searcher
)
```

### QuestionClassifier

#### ì´ì „
```python
classifier = QuestionClassifier(llm_model="gpt-4o-mini")
question_type, confidence, reason = classifier.classify(query)
```

#### ì´í›„
```python
from src.classifiers import QuestionClassifier

classifier = QuestionClassifier(llm_model="gpt-4o-mini")
question_type, confidence, reason = classifier.classify(query)

# í˜¸í™˜ì„± ì™„ë²½ ìœ ì§€
print(question_type.name)  # "MEDICAL", "HOSPITAL", "GENERAL"
```

### HospitalHandler

#### ì´ì „
```python
handler = HospitalHandler(
    hospital_json_path="data/raw/hospital/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›_ì¸í—ˆê°€_ì •ë³´.json"
)

result = handler.handle_hospital_question("ê°•ë‚¨êµ¬ ë™ë¬¼ë³‘ì›?")
```

#### ì´í›„
```python
handler = HospitalHandler(
    hospital_json_path="data/raw/hospital/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›_ì¸í—ˆê°€_ì •ë³´.json"
)

result = handler.handle("ê°•ë‚¨êµ¬ ë™ë¬¼ë³‘ì›?", location="ê°•ë‚¨êµ¬")

# ë˜ëŠ” ì¢Œí‘œ ê¸°ë°˜
result = handler.handle(
    "ê·¼ì²˜ ë³‘ì›",
    latitude=37.4979,
    longitude=127.0276
)
```

---

## ğŸš€ ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### ë°©ë²• 1: í˜¸í™˜ì„± ë˜í¼ (ê¶Œì¥)

ê¸°ì¡´ ì½”ë“œì˜ ë³€ê²½ì„ ìµœì†Œí™”í•˜ë ¤ë©´ í˜¸í™˜ì„± ë˜í¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# compatibility.py
from src.pipelines import RAGOrchestrator

class AdvancedRAGPipeline:
    """ì´ì „ API í˜¸í™˜ì„± ìœ ì§€"""
    
    def __init__(self, vectorstore, hospital_json_path, llm_model, score_threshold):
        self.orchestrator = RAGOrchestrator(
            vectorstore=vectorstore,
            hospital_json_path=hospital_json_path,
            llm_model=llm_model,
            score_threshold=score_threshold
        )
    
    def process_question(self, query):
        """ì´ì „ ë©”ì„œë“œëª… í˜¸í™˜ì„±"""
        return self.orchestrator.process(query)
    
    # ... ê¸°íƒ€ ë©”ì„œë“œë“¤
```

ì‚¬ìš©:
```python
# ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥
from compatibility import AdvancedRAGPipeline

pipeline = AdvancedRAGPipeline(vectorstore, path, model, threshold)
result = pipeline.process_question(query)
```

### ë°©ë²• 2: ì§ì ‘ ë§ˆì´ê·¸ë ˆì´ì…˜

ê¸°ì¡´ ì½”ë“œë¥¼ ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ì§ì ‘ ìˆ˜ì •í•©ë‹ˆë‹¤:

```python
# 1. Import ë³€ê²½
from src import RAGOrchestrator

# 2. í´ë˜ìŠ¤ëª… ë³€ê²½
orchestrator = RAGOrchestrator(...)  # AdvancedRAGPipeline â†’ RAGOrchestrator

# 3. ë©”ì„œë“œëª… ë³€ê²½
result = orchestrator.process(query)  # process_question â†’ process
```

---

## ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ìƒˆ ëª¨ë“ˆ êµ¬ì¡° ì„¤ì¹˜
- [ ] í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env)
- [ ] Import ë¬¸ ì—…ë°ì´íŠ¸
- [ ] í´ë˜ìŠ¤ëª… ë³€ê²½
- [ ] ë©”ì„œë“œëª… ë³€ê²½
- [ ] íŒŒë¼ë¯¸í„° í™•ì¸
- [ ] ê²°ê³¼ êµ¬ì¡° í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ì„±ëŠ¥ ë¹„êµ
- [ ] ê¸°ì¡´ ì½”ë“œ ì œê±°

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 1ë‹¨ê³„: í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

```python
# test_migration.py
import json
from src import RAGOrchestrator, load_vectorstore, get_embedding_model

def test_basic_functionality():
    """ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    embedding_model = get_embedding_model("openai")
    vectorstore = load_vectorstore(embedding_model)
    orchestrator = RAGOrchestrator(vectorstore=vectorstore)
    
    # ì˜ë£Œ ì§ˆë¬¸
    result1 = orchestrator.process("ê°•ì•„ì§€ í”¼ë¶€ì—¼?")
    assert result1['question_type'] == 'A'
    assert 'answer' in result1
    
    # ë³‘ì› ì§ˆë¬¸
    result2 = orchestrator.process("ê°•ë‚¨ì—­ ë™ë¬¼ë³‘ì›?")
    assert result2['question_type'] == 'B'
    assert 'hospitals' in result2
    
    # ì¼ë°˜ ì§ˆë¬¸
    result3 = orchestrator.process("ë°˜ë ¤ê²¬ í›ˆë ¨ íŒ?")
    assert result3['question_type'] == 'C'
    assert 'answer' in result3
    
    print("âœ“ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼")

test_basic_functionality()
```

### 2ë‹¨ê³„: ì„±ëŠ¥ ë¹„êµ

```python
import time

# ì´ì „ ë°©ì‹
start = time.time()
for q in queries:
    result = pipeline.process_question(q)
old_time = time.time() - start

# ìƒˆë¡œìš´ ë°©ì‹
start = time.time()
for q in queries:
    result = orchestrator.process(q)
new_time = time.time() - start

print(f"ì´ì „: {old_time:.2f}s")
print(f"ìƒˆë¡œìš´: {new_time:.2f}s")
print(f"ì„±ëŠ¥ ë³€í™”: {((new_time - old_time) / old_time * 100):+.1f}%")
```

---

## ğŸ“š ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ì¶”ì²œ í™œë™

1. **ëª¨ë“ˆ ìµœì í™”**: ê° ëª¨ë“ˆì„ ì„¸ë¶„í™”í•˜ì—¬ ì¬ì‚¬ìš©ì„± ì¦ëŒ€
2. **í…ŒìŠ¤íŠ¸ ì‘ì„±**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì™€ í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€
3. **ë¬¸ì„œí™”**: ê° ëª¨ë“ˆì˜ ì‚¬ìš©ë²• ë¬¸ì„œí™”
4. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ë¡œê¹… ë° ë©”íŠ¸ë¦­ ì¶”ê°€
5. **ê¸°ëŠ¥ í™•ì¥**: ìƒˆë¡œìš´ ê²€ìƒ‰ê¸°ë‚˜ í•¸ë“¤ëŸ¬ ì¶”ê°€

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### Q: ì´ì „ ì½”ë“œì™€ ìƒˆ ì½”ë“œë¥¼ ë™ì‹œì— ì‚¬ìš© ê°€ëŠ¥í•œê°€?

**A**: í˜¸í™˜ì„± ë˜í¼ë¥¼ ì‚¬ìš©í•˜ë©´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨ê³„ì ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Q: ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²½ìš°?

**A**: ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
- ì„¤ì •ì—ì„œ top_k ê°’
- ë²¡í„°ìŠ¤í† ì–´ í¬ê¸°
- ì›¹ ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€
- LLM API ì‘ë‹µ ì‹œê°„

### Q: ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ì¬ì‚¬ìš© ê°€ëŠ¥í•œê°€?

**A**: ë„¤, ì™„ë²½í•˜ê²Œ í˜¸í™˜ë©ë‹ˆë‹¤. ë™ì¼í•œ ê²½ë¡œì—ì„œ ë¡œë“œí•˜ë©´ ë©ë‹ˆë‹¤.

### Q: ì»¤ìŠ¤í…€ í•¸ë“¤ëŸ¬ë¥¼ ë§Œë“¤ë ¤ë©´?

**A**: `BaseHandler`ë¥¼ ìƒì†í•˜ê³  `handle()` ë©”ì„œë“œë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

---

**ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ í›„**: [QUICKSTART.md](./QUICKSTART.md)ë¥¼ ì°¸ê³ í•˜ì—¬ ìƒˆ ê¸°ëŠ¥ì„ í™œìš©í•´ë³´ì„¸ìš”!

