import os
from datetime import datetime
import warnings
warnings.filterwarnings("ignore")

import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
import chromadb
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from src.ensemble import EnsembleRetriever

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ---------------------------
# í™˜ê²½ ì„¤ì • & ì „ì—­ ê°ì²´
# ---------------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ì„¤ì •ê°’ ì •ì˜
LLM_MODEL = "gpt-4o-mini"
LLM_TEMPERATURE = 0
RETRIEVER_K = 5
VECTORSTORE_PATH = r".\data\ChromaDB_bge_m3"  # prompt_new.pyì™€ ë™ì¼í•œ ê²½ë¡œ
COLLECTION_NAME = "pet_health_qa_system_bge_m3"

st.set_page_config(
    page_title="ë°˜ë ¤ê²¬ ì§ˆë³‘ Q&A",
    page_icon="ğŸ¶",
    layout="wide",
)

# ---------------------------
# Retriever ìƒì„±
# ---------------------------
def get_retriever(k=RETRIEVER_K):
    """ë²¡í„°ìŠ¤í† ì–´ë¡œë¶€í„° ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± (ìœ ì‚¬ë„ + BM25 ì•™ìƒë¸”)"""
    # BGE-M3 ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (prompt_new.pyì™€ ë™ì¼)
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        model_kwargs={'device': 'cpu'},  # GPU ì‚¬ìš©ì‹œ 'cuda'ë¡œ ë³€ê²½
        encode_kwargs={'normalize_embeddings': True}  # bge-m3ëŠ” ì •ê·œí™” ê¶Œì¥
    )
    
    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (prompt_new.pyì™€ ë™ì¼)
    vectorstore = Chroma(
        persist_directory=VECTORSTORE_PATH,
        collection_name=COLLECTION_NAME,
        embedding_function=embeddings
    )
    print("ë²¡í„°ìŠ¤í† ì–´ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì»¬ë ‰ì…˜ í™•ì¸
    client = chromadb.PersistentClient(path=VECTORSTORE_PATH)
    collections = client.list_collections()
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜:", [c.name for c in collections])
    
    # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„
    retriever = vectorstore.as_retriever(search_kwargs={"k": k}, search_type="similarity")
    
    # BM25 ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
    collection = vectorstore._collection
    doc_count = collection.count()
    
    if doc_count == 0:
        raise ValueError("ë²¡í„°ìŠ¤í† ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    
    # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_data = collection.get(limit=doc_count)
    
    # Document ê°ì²´ë¡œ ë³€í™˜
    bm25_docs = []
    if all_data and 'ids' in all_data and len(all_data['ids']) > 0:
        documents = all_data.get('documents', [])
        metadatas = all_data.get('metadatas', [])
        
        for i, doc_id in enumerate(all_data['ids']):
            page_content = documents[i] if i < len(documents) else ""
            metadata = metadatas[i] if i < len(metadatas) else {}
            bm25_docs.append(Document(page_content=page_content, metadata=metadata))
    
    if len(bm25_docs) == 0:
        raise ValueError("ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"BM25 ë¦¬íŠ¸ë¦¬ë²„ìš© ë¬¸ì„œ {len(bm25_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
    retriever_bm25 = BM25Retriever.from_documents(bm25_docs)
    
    # ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„
    retriever_ensemble = EnsembleRetriever(
        retrievers=[retriever, retriever_bm25],
        weights=[0.5, 0.5]  # ê°€ì¤‘ì¹˜ í•©ì€ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    )
    
    return retriever_ensemble

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "qa_history" not in st.session_state:
    st.session_state.qa_history = []

if "retriever" not in st.session_state:
    st.session_state.retriever = get_retriever(k=RETRIEVER_K)

if "llm" not in st.session_state:
    st.session_state.llm = ChatOpenAI(
        model=LLM_MODEL,
        temperature=LLM_TEMPERATURE,
        openai_api_key=OPENAI_API_KEY,
    )

# RAG í”„ë¡¬í”„íŠ¸ ì •ì˜ (prompt_new.py ê¸°ë°˜)
if "rag_prompt" not in st.session_state:
    st.session_state.rag_prompt = ChatPromptTemplate.from_messages([
        ("system", """
ë‹¹ì‹ ì€ ë°˜ë ¤ê²¬ ì§ˆë³‘Â·ì¦ìƒì— ëŒ€í•´ ìˆ˜ì˜í•™ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ë‹¹ì‹ ì˜ ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ë§¥(Context)ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.
ë¬¸ë§¥ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ë¡œ ì¶”ì¸¡í•˜ê±°ë‚˜ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.

[ì‚¬ìš© ê°€ëŠ¥í•œ ì •ë³´ ìœ í˜•]
- medical_data: ìˆ˜ì˜í•™ ì„œì  ë˜ëŠ” ë…¼ë¬¸
- qa_data: ë³´í˜¸ì-ìˆ˜ì˜ì‚¬ ìƒë‹´ ê¸°ë¡ (ìƒì• ì£¼ê¸° / ê³¼ / ì§ˆë³‘ íƒœê·¸ í¬í•¨)

[í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ ê·œì¹™]
1. ë¬¸ë§¥ì— ì—†ëŠ” ì •ë³´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
2. ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ "í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. ì—¬ëŸ¬ ë¬¸ì„œ ì œê³µì‹œ, ì‹¤ì œë¡œ ë‹µë³€ì— ì‚¬ìš©í•œ ë¬¸ì„œë§Œ ì¶œì²˜ ëª…ì‹œí•˜ì„¸ìš”.
4. **ì§ˆë¬¸ì— í•©ë‹¹í•œ ë‹µë³€ë§Œ ì œê³µí•˜ì„¸ìš”. ê±°ì§“ ì •ë³´ë‚˜ ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ì œì™¸í•˜ì„¸ìš”.**

[ì‘ë‹µ ê·œì¹™]
- ë³´í˜¸ìê°€ ì‘ì„±í•œ ë°˜ë ¤ê²¬ ìƒíƒœë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•œë‹¤.
- ë¬¸ë§¥ì—ì„œ í™•ì¸ëœ ê°€ëŠ¥í•œ ì›ì¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤. 
  (ë¬¸ë§¥ì— ì—†ë‹¤ë©´ "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì“´ë‹¤)
- ì§‘ì—ì„œ ê°€ëŠ¥í•œ ì•ˆì „í•œ ê´€ë¦¬ ë°©ë²• 2~3ê°œ ì œì•ˆí•œë‹¤. 
  (ë¬¸ë§¥ì— ì—†ë‹¤ë©´ ì œì•ˆí•˜ì§€ ì•ŠëŠ”ë‹¤)
- ì–¸ì œ ë³‘ì›ì— ê°€ì•¼ í•˜ëŠ”ì§€, ì–´ë–¤ ì¦ìƒì´ ì‘ê¸‰ì¸ì§€ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.
- ë§ˆì§€ë§‰ ì¤„ì— ë°˜ë“œì‹œ ëŒ€ë‹µ ìƒì„±ì— ì‚¬ìš©í•œ ëª¨ë“  ë¬¸ì„œì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•œë‹¤:
  â€¢ ì„œì  ì¶œì²˜: ì±… ì œëª© / ì €ì / ì¶œíŒì‚¬
  â€¢ QA ì¶œì²˜: ìƒì• ì£¼ê¸° / ê³¼ / ì§ˆë³‘

[ì „ì²´ í†¤]
- ê³µì†í•œ ì¡´ëŒ“ë§
- ë³´í˜¸ìë¥¼ ì•ˆì‹¬ì‹œí‚¤ë˜, í•„ìš”í•œ ë¶€ë¶„ì€ ëª…í™•í•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ìˆ˜ì˜ì‚¬ ìƒë‹´ í†¤

[ì¶œë ¥ í˜•ì‹]
-ìƒíƒœ ìš”ì•½:
-ê°€ëŠ¥í•œ ì›ì¸:
-ì§‘ì—ì„œ ê´€ë¦¬ ë°©ë²•:
-ë³‘ì› ë°©ë¬¸ ì‹œê¸°:

"""),
        ("human", """
ë¬¸ë§¥: {context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}
""")
    ])

# ì§ˆë¬¸ ë³€í™˜ í”„ë¡¬í”„íŠ¸ (prompt_new.py ê¸°ë°˜)
if "rewrite_prompt" not in st.session_state:
    st.session_state.rewrite_prompt = PromptTemplate.from_template(
        """ë‹¤ìŒ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ë” ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜í•´ ì£¼ì„¸ìš”.
í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë°”ê¿”ì£¼ì„¸ìš”.
ë³€í™˜ëœ ê²€ìƒ‰ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: {question}
ë³€í™˜ëœ ê²€ìƒ‰ì–´:""")

if "selected_qa_index" not in st.session_state:
    st.session_state.selected_qa_index = None

if "page" not in st.session_state:
    st.session_state.page = "home"  # "home", "qa", or "chat"

if "popular_qa" not in st.session_state:
    st.session_state.popular_qa = []

if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []


# ---------------------------
# ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜ (prompt.py ê¸°ë°˜)
# ---------------------------
def format_docs(docs):
    """ë¬¸ì„œë¥¼ ì¶œì²˜ ì •ë³´ì™€ í•¨ê»˜ í¬ë§·íŒ…"""
    formatted_docs = []
    for doc in docs:
        metadata = doc.metadata
        
        # ë°ì´í„° ìœ í˜•ì— ë”°ë¼ ì¶œì²˜ ì •ë³´ êµ¬ì„±
        if metadata.get("source_type") == "qa_data":
            source_info = f"ìƒë‹´ê¸°ë¡ - {metadata.get('lifeCycle', '')}/{metadata.get('department', '')}/{metadata.get('disease', '')}"
        else:
            source_info = f"ì„œì  - {metadata.get('title', '')}"
            if metadata.get('author'):
                source_info += f" (ì €ì: {metadata['author']})"
            if metadata.get('page'):
                source_info += f" p.{metadata['page']+1}"
        
        formatted_doc = f"""<document>
<content>{doc.page_content}</content>
<source_info>{source_info}</source_info>
<data_type>{metadata.get('source_type', 'unknown')}</data_type>
</document>"""
        
        formatted_docs.append(formatted_doc)
    
    return "\n\n".join(formatted_docs)


def filter_docs_by_response(docs, ai_response):
    """LLM ì‘ë‹µì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ëœ ë¬¸ì„œë§Œ í•„í„°ë§"""
    if not docs:
        return []
    
    used_docs = []
    
    for doc in docs:
        metadata = doc.metadata
        
        # ë¬¸ì„œ ì¶œì²˜ ì •ë³´ ìƒì„±
        if metadata.get("source_type") == "qa_data":
            # ìƒë‹´ê¸°ë¡ ì •ë³´
            lifecycle = metadata.get('lifeCycle', '').strip()
            department = metadata.get('department', '').strip()
            disease = metadata.get('disease', '').strip()
            
            # ì‘ë‹µì— í•´ë‹¹ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if lifecycle and lifecycle in ai_response:
                used_docs.append(doc)
            elif department and department in ai_response:
                used_docs.append(doc)
            elif disease and disease in ai_response:
                used_docs.append(doc)
        else:
            # ì„œì  ì •ë³´
            title = metadata.get('title', '').strip()
            author = metadata.get('author', '').strip()
            
            # ì‘ë‹µì— ì œëª©ì´ë‚˜ ì €ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if title and title in ai_response:
                used_docs.append(doc)
            elif author and author in ai_response:
                used_docs.append(doc)
        
        # ë¬¸ì„œ ë‚´ìš©ì´ ì‘ë‹µì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        content = doc.page_content[:100].strip()  # ì²˜ìŒ 100ì í™•ì¸
        if content and content in ai_response:
            if doc not in used_docs:
                used_docs.append(doc)
    
    # ì‚¬ìš©ëœ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì²« ë²ˆì§¸ ë¬¸ì„œ í¬í•¨
    if not used_docs and docs:
        used_docs.append(docs[0])
    
    return used_docs
    # ìˆ˜ì˜í•™ ì„œì ì˜ ê²½ìš°
    source_info = f"ì„œì  - {metadata.get('title', '')}"
    if metadata.get('author'):
        source_info += f" (ì €ì: {metadata['author']})"
    if metadata.get('page'):
        source_info += f" p.{metadata['page']+1}"

    formatted_doc = f"""<document>
<content>{doc.page_content}</content>
<source_info>{source_info}</source_info>
<data_type>{metadata.get('source_type', 'unknown')}</data_type>
</document>"""

    formatted_docs.append(formatted_doc)

    return "\n\n".join(formatted_docs)


# ---------------------------
# ì±„íŒ… í˜ì´ì§€
# ---------------------------
def show_chat():
    """ì±„íŒ… ìŠ¤íƒ€ì¼ì˜ Q&A ì¸í„°í˜ì´ìŠ¤"""
    st.markdown("""
    <div style="text-align: center; margin-bottom: 10px;">
        <h1 style="font-size: 60px; font-weight: 900; color: #1e40af; margin: 0; line-height: 1.2;">
            ë°˜ë ¤ê²¬ ê±´ê°• ìƒë‹´ ChatBot
        </h1>
        <p style="font-size: 14px; color: #666; margin: 8px 0 0 0;">
            ê¶ê¸ˆí•œ ë°˜ë ¤ê²¬ ê±´ê°• ì¦ìƒì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ë£Œ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦½ë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "submit_count" not in st.session_state:
        st.session_state.submit_count = 0

    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []

    if "message_docs" not in st.session_state:
        st.session_state.message_docs = {}  # ë©”ì‹œì§€ ì¸ë±ìŠ¤ë³„ ë¬¸ì„œ ì €ì¥
    
    # 2ì—´ ë ˆì´ì•„ì›ƒ: ì™¼ìª½(ë¬¸ì„œ) - ì˜¤ë¥¸ìª½(ì±„íŒ…)
    col_docs, col_chat = st.columns([1, 2], gap="large")
    
    with col_chat:
        st.markdown("### ğŸ’¬ ëŒ€í™”")
        
        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
        chat_container = st.container()
        
        with chat_container:
            for idx, message in enumerate(st.session_state.chat_messages):
                if message["role"] == "user":
                    # ì‚¬ìš©ì ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½, ë…¸ë€ìƒ‰)
                    st.markdown(
                        f"""
                        <div style="display: flex; justify-content: flex-end; margin-bottom: 16px;">
                            <div style="background-color: #FFF9E6; padding: 14px 18px; border-radius: 16px; max-width: 80%; word-wrap: break-word;">
                                <span style="color: #333; font-size: 15px; line-height: 1.5;">{message['content']}</span>
                            </div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                else:
                    # AI ë©”ì‹œì§€ (ì™¼ìª½, í°ìƒ‰)
                    st.markdown(
                        f"""
                        <div style="display: flex; justify-content: flex-start; margin-bottom: 16px;">
                            <div style="background-color: #F0F4F8; padding: 14px 18px; border-radius: 16px; max-width: 80%; word-wrap: break-word;">
                                <strong style="color: #1e40af; font-size: 13px;">ğŸ¶ ìˆ˜ì˜ì‚¬ AI</strong><br>
                                <span style="color: #333; font-size: 14px; line-height: 1.6; margin-top: 6px; display: block;">{message['content']}</span>
                            </div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
        
        # ì…ë ¥ í¼
        st.markdown("---")
        with st.form(key=f"chat_form_{st.session_state.submit_count}", border=True):
            col1, col2 = st.columns([5, 1], gap="small")
            with col1:
                user_input = st.text_input(
                    label="",
                    placeholder="ğŸ• ê°•ì•„ì§€ì˜ ì¦ìƒì´ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                    label_visibility="collapsed"
                )
            with col2:
                submitted = st.form_submit_button("â¤ ì „ì†¡", use_container_width=True)
        
        # ë©”ì‹œì§€ ì²˜ë¦¬
        if submitted and user_input.strip():
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.chat_messages.append({
                "role": "user",
                "content": user_input.strip()
            })
            
            with st.spinner("ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # 1. ì§ˆë¬¸ ë³€í™˜ (rewrite chain)
                    rewrite_chain = st.session_state.rewrite_prompt | st.session_state.llm | StrOutputParser()
                    transformed_query = rewrite_chain.invoke({"question": user_input.strip()})
                    
                    # 2. ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
                    docs = st.session_state.retriever.invoke(transformed_query)
                    
                    if not docs:
                        ai_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?"
                        docs_to_save = []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸
                    else:
                        # 3. ë¬¸ì„œ í¬ë§·íŒ…
                        context = format_docs(docs)
                        
                        # 4. RAG ì²´ì¸ ì‹¤í–‰
                        rag_chain = st.session_state.rag_prompt | st.session_state.llm | StrOutputParser()
                        ai_response = rag_chain.invoke({"context": context, "question": transformed_query})
                        
                        # 5. ì‘ë‹µì— ì‹¤ì œë¡œ ì‚¬ìš©ëœ ë¬¸ì„œë§Œ í•„í„°ë§
                        docs_to_save = filter_docs_by_response(docs, ai_response)
                    
                    # AI ì‘ë‹µ ì¶”ê°€
                    message_idx = len(st.session_state.chat_messages)
                    st.session_state.chat_messages.append({
                        "role": "assistant",
                        "content": ai_response
                    })
                    
                    # í•´ë‹¹ ë©”ì‹œì§€ì˜ ë¬¸ì„œ ì €ì¥ (ë¬¸ì„œê°€ ìˆì„ ë•Œë§Œ)
                    if docs_to_save:
                        st.session_state.message_docs[message_idx] = docs_to_save
                    
                    # submit_count ì¦ê°€í•˜ì—¬ form key ë³€ê²½ -> ì…ë ¥ì°½ ì´ˆê¸°í™”
                    st.session_state.submit_count += 1
                    st.rerun()
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.chat_messages = []
            st.session_state.message_docs = {}
            st.rerun()
    
    # ì™¼ìª½ ì—´: ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
    with col_docs:
        st.markdown("### ğŸ“š ì°¸ê³  ë¬¸ì„œ")
        
        # ìµœê·¼ AI ì‘ë‹µì˜ ë¬¸ì„œ ì°¾ê¸°
        last_ai_message_idx = None
        for i in range(len(st.session_state.chat_messages) - 1, -1, -1):
            if st.session_state.chat_messages[i]["role"] == "assistant":
                last_ai_message_idx = i
                break
        
        if last_ai_message_idx is not None and last_ai_message_idx in st.session_state.message_docs:
            docs = st.session_state.message_docs[last_ai_message_idx]
            for doc_idx, doc in enumerate(docs, 1):
                metadata = doc.metadata
                
                # ë¬¸ì„œ ìœ í˜•ì— ë”°ë¥¸ ì¶œì²˜ ì •ë³´
                if metadata.get("source_type") == "qa_data":
                    source_info = f"ğŸ“‹ ìƒë‹´ê¸°ë¡\n{metadata.get('lifeCycle', '')}/{metadata.get('department', '')}/{metadata.get('disease', '')}"
                else:
                    source_info = f"ğŸ“– ì„œì \n{metadata.get('title', '')}"
                    if metadata.get('author'):
                        source_info += f"\nì €ì: {metadata['author']}"
                    if metadata.get('page'):
                        source_info += f"\np.{metadata['page']+1}"
                
                with st.expander(f"ë¬¸ì„œ {doc_idx}", expanded=False):
                    st.markdown(f"**ì¶œì²˜ ì •ë³´**\n{source_info}")
                    st.markdown("---")
                    st.markdown(f"**ë‚´ìš©**\n{doc.page_content[:200]}...")
        else:
            st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì°¸ê³ í•œ ë¬¸ì„œê°€ í‘œì‹œë©ë‹ˆë‹¤.")


# ì±„íŒ… í˜ì´ì§€ ì‹¤í–‰
show_chat()
