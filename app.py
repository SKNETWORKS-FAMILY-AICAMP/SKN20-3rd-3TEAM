"""
Streamlit ê¸°ë°˜ RAG ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
LangGraph CRAG íŒŒì´í”„ë¼ì¸ì„ Streamlit UIì™€ í†µí•©

ì‚¬ìš©ë²•:
  streamlit run app.py
"""

import os
import sys
from pathlib import Path
from typing import Dict, Any, List
import time

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# Streamlit ì„í¬íŠ¸
import streamlit as st
from streamlit.logger import get_logger

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.insert(0, str(Path(__file__).parent))
from src.embeddings import get_embedding_model, load_vectorstore
from src.retrieval import create_retriever
from src.pipeline import LangGraphRAGPipeline

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

# ==================== í˜ì´ì§€ ì„¤ì • ====================
st.set_page_config(
    page_title="ğŸ¥ ì˜ë£Œ RAG ì±—ë´‡",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    /* ë©”ì¸ ì»¨í…Œì´ë„ˆ */
    .main {
        max-width: 1200px;
    }
    
    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .chat-user {
        background-color: #E3F2FD;
        padding: 12px 16px;
        border-radius: 12px;
        margin: 10px 0;
        border-left: 4px solid #2196F3;
    }
    
    .chat-assistant {
        background-color: #F5F5F5;
        padding: 12px 16px;
        border-radius: 12px;
        margin: 10px 0;
        border-left: 4px solid #4CAF50;
    }
    
    .chat-timestamp {
        font-size: 0.8em;
        color: #999;
        margin-top: 4px;
    }
    
    /* ì†ŒìŠ¤ ì •ë³´ */
    .source-box {
        background-color: #FFF3E0;
        padding: 12px;
        border-radius: 8px;
        margin: 8px 0;
        border-left: 4px solid #FF9800;
        font-size: 0.9em;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        width: 100%;
        height: 40px;
        font-size: 1em;
        border-radius: 8px;
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .metric-card {
        background-color: #F9F9F9;
        padding: 16px;
        border-radius: 8px;
        border: 1px solid #E0E0E0;
        margin: 10px 0;
    }
    
    /* ì—ëŸ¬ ë©”ì‹œì§€ */
    .error-message {
        background-color: #FFEBEE;
        color: #C62828;
        padding: 12px;
        border-radius: 8px;
        border-left: 4px solid #C62828;
    }
    
    /* ë¡œë”© ìƒíƒœ */
    .loading-indicator {
        text-align: center;
        color: #1976D2;
    }
</style>
""", unsafe_allow_html=True)

# ==================== ì´ˆê¸°í™” í•¨ìˆ˜ ====================

@st.cache_resource
def initialize_rag_pipeline():
    """
    RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (Streamlit ìºì‹œ ì‚¬ìš©)
    
    Returns:
        RAG íŒŒì´í”„ë¼ì¸ ê°ì²´
    """
    try:
        with st.spinner("ğŸ”„ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            embedding_model = get_embedding_model("openai")
            
            # 2. ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
            vectorstore = load_vectorstore(
                embedding_model,
                persist_directory="./chroma_db",
                collection_name="rag_collection"
            )
            
            # 3. Retriever ìƒì„±
            retriever = create_retriever(
                vectorstore,
                top_k=5
            )
            
            # 4. LangGraph CRAG íŒŒì´í”„ë¼ì¸ ìƒì„± (ë””ë²„ê·¸ ë¡œê·¸ ë¹„í™œì„±í™”)
            pipeline = LangGraphRAGPipeline(
                retriever,
                llm_model="gpt-4o-mini",
                temperature=0.0,
                debug=False  # Streamlit í™˜ê²½ì—ì„œëŠ” ë””ë²„ê·¸ ë¡œê·¸ ë¹„í™œì„±í™”
            )
            
        st.success("âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        return pipeline
    
    except Exception as e:
        st.error(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        logger.error(f"RAG initialization error: {str(e)}")
        return None


def initialize_session_state():
    """
    Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    """
    # ëŒ€í™” ê¸°ë¡
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # RAG íŒŒì´í”„ë¼ì¸
    if "pipeline" not in st.session_state:
        st.session_state.pipeline = None
    
    # UI ìƒíƒœ
    if "show_sources" not in st.session_state:
        st.session_state.show_sources = True
    
    if "show_debug_info" not in st.session_state:
        st.session_state.show_debug_info = False


# ==================== ì±„íŒ… í‘œì‹œ í•¨ìˆ˜ ====================

def display_chat_message(role: str, content: str, timestamp: str = None, sources: List[Dict] = None):
    """
    ì±„íŒ… ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
    
    Args:
        role: "user" ë˜ëŠ” "assistant"
        content: ë©”ì‹œì§€ ë‚´ìš©
        timestamp: ë©”ì‹œì§€ íƒ€ì„ìŠ¤íƒ¬í”„ (ì„ íƒì‚¬í•­)
        sources: ë‹µë³€ì˜ ì¶œì²˜ ì •ë³´ (assistantì¼ ë•Œë§Œ)
    """
    if role == "user":
        st.markdown(f"""
        <div class="chat-user">
            <strong>ğŸ‘¤ ë‹¹ì‹ :</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)
    
    elif role == "assistant":
        st.markdown(f"""
        <div class="chat-assistant">
            <strong>ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)
        
        # ì¶œì²˜ ì •ë³´ í‘œì‹œ
        if sources and len(sources) > 0:
            with st.expander(f"ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ({len(sources)}ê°œ)"):
                for i, source in enumerate(sources, 1):
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        st.markdown(f"**[{i}]**")
                    with col2:
                        source_type = source.get('type', 'internal')
                        type_icon = 'ğŸŒ' if source_type == 'web' else 'ğŸ“„'
                        st.markdown(f"""
                        {type_icon} **{source.get('file_name', 'Unknown')}**
                        - ë¶€ì„œ: {source.get('department', 'N/A')}
                        - ì œëª©: {source.get('title', 'N/A')}
                        """)


def display_chat_history():
    """
    ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    """
    if not st.session_state.chat_history:
        st.info("ğŸ’¬ ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return
    
    for message in st.session_state.chat_history:
        role = message.get("role")
        content = message.get("content")
        timestamp = message.get("timestamp")
        sources = message.get("sources", [])
        
        display_chat_message(role, content, timestamp, sources)


# ==================== ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜ ====================

def process_question(question: str, pipeline: LangGraphRAGPipeline) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ ìƒì„±
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        pipeline: RAG íŒŒì´í”„ë¼ì¸
        
    Returns:
        ë‹µë³€ ë° ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    try:
        with st.spinner("ğŸ”„ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            start_time = time.time()
            result = pipeline.rag_pipeline_with_sources(question)
            elapsed_time = time.time() - start_time
            
            result['elapsed_time'] = elapsed_time
            return result
    
    except Exception as e:
        logger.error(f"Question processing error: {str(e)}")
        return {
            'answer': f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            'sources': [],
            'elapsed_time': 0
        }


def handle_question_submission():
    """
    ì§ˆë¬¸ ì œì¶œ í•¸ë“¤ëŸ¬
    """
    question = st.session_state.user_input.strip()
    
    if not question:
        st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í™•ì¸
    if st.session_state.pipeline is None:
        st.error("âŒ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    st.session_state.chat_history.append({
        "role": "user",
        "content": question,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    })
    
    # ì§ˆë¬¸ ì²˜ë¦¬
    result = process_question(question, st.session_state.pipeline)
    
    # ëŒ€í™” ê¸°ë¡ì— AI ë‹µë³€ ì¶”ê°€
    st.session_state.chat_history.append({
        "role": "assistant",
        "content": result.get('answer', 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'),
        "sources": result.get('sources', []),
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "elapsed_time": result.get('elapsed_time', 0),
        "debug_info": {
            "document_scores": result.get('document_scores', []),
            "grade_results": result.get('grade_results', []),
            "web_search_needed": result.get('web_search_needed', 'No')
        }
    })
    
    # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
    st.session_state.user_input = ""


# ==================== ì‚¬ì´ë“œë°” ì„¤ì • ====================

def render_sidebar():
    """
    ì‚¬ì´ë“œë°” ë Œë”ë§
    """
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        if st.session_state.pipeline:
            st.success("âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ë¨")
        else:
            st.error("âŒ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...")
        
        # í‘œì‹œ ì˜µì…˜
        st.subheader("ğŸ“‹ í‘œì‹œ ì˜µì…˜")
        st.session_state.show_sources = st.checkbox(
            "ì¶œì²˜ ì •ë³´ í‘œì‹œ",
            value=st.session_state.show_sources
        )
        st.session_state.show_debug_info = st.checkbox(
            "ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ",
            value=st.session_state.show_debug_info
        )
        
        # ëŒ€í™” ê´€ë¦¬
        st.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.chat_history = []
                st.rerun()
        
        with col2:
            if st.button("ğŸ“Š í†µê³„", use_container_width=True):
                st.session_state.show_stats = True
        
        # ë„ì›€ë§
        st.subheader("â“ ë„ì›€ë§")
        st.markdown("""
        ### ì‚¬ìš© ë°©ë²•
        1. **ì§ˆë¬¸ ì…ë ¥**: ì•„ë˜ í…ìŠ¤íŠ¸ ìƒìì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”
        2. **ì œì¶œ**: 'ì§ˆë¬¸ ì œì¶œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        3. **ë‹µë³€ í™•ì¸**: AIì˜ ë‹µë³€ê³¼ ì°¸ê³  ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”
        
        ### íŒ
        - êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ì´ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤
        - ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤
        - ë‚´ë¶€ ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìë™ ë³´ì™„ë©ë‹ˆë‹¤
        """)
        
        # ì˜ˆì‹œ ì§ˆë¬¸
        st.subheader("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
        example_questions = [
            "ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ì˜ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë²¼ë£© ì•ŒëŸ¬ì§€ì„± í”¼ë¶€ì—¼ ì¹˜ë£Œë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ê°œì˜ í˜ˆì•¡í˜•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ë©´ì—­ ì²´ê³„ ì§ˆí™˜ì˜ ì¢…ë¥˜ëŠ”?",
        ]
        
        for example in example_questions:
            if st.button(f"ğŸ’¬ {example}", use_container_width=True, key=f"example_{example}"):
                st.session_state.user_input = example
                st.rerun()


# ==================== í†µê³„ í‘œì‹œ ====================

def display_statistics():
    """
    ëŒ€í™” í†µê³„ í‘œì‹œ
    """
    if not st.session_state.chat_history:
        st.info("ğŸ“Š ì•„ì§ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    col1, col2, col3 = st.columns(3)
    
    # ì§ˆë¬¸ ìˆ˜
    num_questions = sum(1 for msg in st.session_state.chat_history if msg['role'] == 'user')
    with col1:
        st.metric("â“ ì´ ì§ˆë¬¸ ìˆ˜", num_questions)
    
    # í‰ê·  ì‘ë‹µ ì‹œê°„
    response_times = [msg.get('elapsed_time', 0) for msg in st.session_state.chat_history 
                     if msg['role'] == 'assistant']
    avg_time = sum(response_times) / len(response_times) if response_times else 0
    with col2:
        st.metric("â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„", f"{avg_time:.2f}ì´ˆ")
    
    # ì›¹ ê²€ìƒ‰ ì‚¬ìš© íšŸìˆ˜
    web_search_count = sum(1 for msg in st.session_state.chat_history 
                          if msg['role'] == 'assistant' 
                          and msg.get('debug_info', {}).get('web_search_needed') == 'Yes')
    with col3:
        st.metric("ğŸŒ ì›¹ ê²€ìƒ‰ ì‚¬ìš© íšŸìˆ˜", web_search_count)


# ==================== ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ ====================

def display_debug_info(message: Dict):
    """
    ë©”ì‹œì§€ì˜ ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
    
    Args:
        message: ëŒ€í™” ë©”ì‹œì§€
    """
    if message['role'] != 'assistant':
        return
    
    debug_info = message.get('debug_info', {})
    
    with st.expander("ğŸ› ë””ë²„ê·¸ ì •ë³´"):
        col1, col2, col3 = st.columns(3)
        
        # ë¬¸ì„œ ìœ ì‚¬ë„ ì ìˆ˜
        with col1:
            doc_scores = debug_info.get('document_scores', [])
            if doc_scores:
                st.markdown("**ğŸ“Š Similarity Scores:**")
                for i, score in enumerate(doc_scores[:5], 1):
                    st.markdown(f"  {i}. {score:.4f}")
        
        # ê´€ë ¨ì„± íŒì • ê²°ê³¼
        with col2:
            grade_results = debug_info.get('grade_results', [])
            if grade_results:
                yes_count = sum(1 for g in grade_results if g == 'YES')
                no_count = sum(1 for g in grade_results if g == 'NO')
                st.markdown("**âœ“ ê´€ë ¨ì„± íŒì •:**")
                st.markdown(f"  ê´€ë ¨ìˆìŒ: {yes_count}ê°œ")
                st.markdown(f"  ê´€ë ¨ì—†ìŒ: {no_count}ê°œ")
        
        # ì›¹ ê²€ìƒ‰ ì—¬ë¶€
        with col3:
            web_search_needed = debug_info.get('web_search_needed', 'No')
            st.markdown("**ğŸŒ ì›¹ ê²€ìƒ‰:**")
            if web_search_needed == 'Yes':
                st.markdown("  âœ“ ì‹¤í–‰ë¨")
            else:
                st.markdown("  âœ— ë¯¸ì‹¤í–‰")


# ==================== ë©”ì¸ ì•± ====================

def main():
    """
    ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜
    """
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°” ë Œë”ë§
    render_sidebar()
    
    # í—¤ë”
    st.title("ğŸ¥ ì˜ë£Œ RAG ì±—ë´‡")
    st.markdown("""
    **Retrieval-Augmented Generation (RAG) ê¸°ë°˜ ì˜ë£Œ QA ì‹œìŠ¤í…œ**
    
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ë™ë¬¼ ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ë‚´ë¶€ ë¬¸ì„œì™€ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ 
    ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    """)
    
    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    if st.session_state.pipeline is None:
        st.session_state.pipeline = initialize_rag_pipeline()
    
    # ëŒ€í™” ì˜ì—­
    st.subheader("ğŸ’¬ ëŒ€í™”")
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    display_chat_history()
    
    # êµ¬ë¶„ì„ 
    st.divider()
    
    # ì…ë ¥ ì˜ì—­
    st.subheader("ğŸ“ ì§ˆë¬¸ ì…ë ¥")
    
    col1, col2 = st.columns([4, 1])
    with col1:
        user_input = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
            key="user_input",
            placeholder="ì˜ˆ: ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ì˜ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            label_visibility="collapsed"
        )
    
    with col2:
        submit_button = st.button(
            "ğŸ“¤ ì œì¶œ",
            use_container_width=True,
            on_click=handle_question_submission
        )
    
    # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ë§ˆì§€ë§‰ ë©”ì‹œì§€)
    if st.session_state.show_debug_info and st.session_state.chat_history:
        last_message = st.session_state.chat_history[-1]
        if last_message['role'] == 'assistant':
            display_debug_info(last_message)
    
    # í†µê³„ í‘œì‹œ (ì„¸ì…˜ ìƒíƒœì— í”Œë˜ê·¸ê°€ ìˆì„ ë•Œ)
    if st.session_state.get('show_stats', False):
        st.divider()
        st.subheader("ğŸ“Š ëŒ€í™” í†µê³„")
        display_statistics()
        st.session_state.show_stats = False


if __name__ == "__main__":
    main()

