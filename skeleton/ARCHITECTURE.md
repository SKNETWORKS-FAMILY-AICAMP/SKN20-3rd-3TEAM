# 🏗️ RAG 어시스턴트 스켈레톤 아키텍처

스켈레톤 코드의 전체 아키텍처, 모듈 간 관계, 데이터 흐름을 설명합니다.

---

## 📐 시스템 아키텍처 개요

```
┌─────────────────────────────────────────────────────────────────┐
│                      사용자 입력 (Query)                          │
└────────────────────────────┬──────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────┐
│           [1] INPUT CLASSIFIER 모듈                              │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 입력 쿼리를 다음 중 하나로 분류:                          │   │
│  │  • medical_consultation  (의료 상담)                    │   │
│  │  • map_search           (지도 검색)                    │   │
│  │  • general              (일반 질문)                    │   │
│  └──────────────────────────────────────────────────────────┘   │
└────────────────────────────┬──────────────────────────────────────┘
                             │
                ┌────────────┼────────────┐
                │            │            │
                ▼            ▼            ▼
     ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐
     │ MEDICAL          │  │ MAP              │  │ GENERAL          │
     │ CONSULTATION     │  │ SEARCH           │  │ QUESTION         │
     └──────────────────┘  └──────────────────┘  └──────────────────┘
                │                  │                       │
                ▼                  ▼                       ▼
    ┌────────────────────┐  ┌──────────────────┐  ┌──────────────────┐
    │ [2a] RAG 검색      │  │ [2b] MAP API     │  │ [2c] WEB 검색    │
    │                    │  │                  │  │                  │
    │ • 벡터 DB 검색     │  │ • 병원 정보      │  │ • 웹 검색        │
    │ • 유사도 평가      │  │ • 위치 추출      │  │ • 실시간 정보    │
    │ • 웹검색 폴백      │  │ • 거리 계산      │  │                  │
    └────────────────────┘  └──────────────────┘  └──────────────────┘
                │                  │                       │
                └────────────────────┼───────────────────────┘
                                     │
                    ┌────────────────┴────────────────┐
                    │                                 │
                    ▼                                 ▼
        ┌──────────────────────┐      ┌───────────────────────────┐
        │ Context 준비         │      │ [3] LLM GENERATOR 모듈    │
        │                      │      │                           │
        │ • 문서/정보 선별     │──────│ • 시스템 프롬프트 구성    │
        │ • 메타데이터 포함    │      │ • LLM API 호출            │
        │ • 길이 최적화        │      │ • 응답 생성               │
        └──────────────────────┘      │ • 응답 재작성 (피드백)    │
                                      └───────────────────────────┘
                                                     │
                                                     ▼
                                      ┌─────────────────────────────┐
                                      │ LLM이 생성한 초기 응답       │
                                      └─────────────────────────────┘
                                                     │
                                                     ▼
        ┌────────────────────────────────────────────────────────┐
        │ [4] EVALUATION CONTROLLER 모듈                          │
        │                                                         │
        │ 평가 4개 차원:                                         │
        │ ┌──────────────────────────────────────────────────┐  │
        │ │ • 정확도 (Accuracy)       0.0-1.0                │  │
        │ │ • 명확성 (Clarity)        0.0-1.0                │  │
        │ │ • 완전성 (Completeness)   0.0-1.0                │  │
        │ │ • 안전성 (Safety)         0.0-1.0                │  │
        │ └──────────────────────────────────────────────────┘  │
        │                                                         │
        │ 평가 결과 기반 의사결정:                              │
        │ ┌──────────────────────────────────────────────────┐  │
        │ │  점수 >= 0.75  → ✅ ACCEPT                       │  │
        │ │  0.50 ≤ 점수   → 🔄 REWRITE (최대 2회)          │  │
        │ │  점수 < 0.50   → ⚠️  ESCALATE                   │  │
        │ └──────────────────────────────────────────────────┘  │
        └────────────────────────────────────────────────────────┘
                    │
         ┌──────────┴──────────┐
         │                     │
      ACCEPT?              REWRITE?
         │                     │
         YES                   YES (최대 2회)
         │                     │
         │              [다시 평가로]
         │                     │
         └──────────┬──────────┘
                    │
                    ▼
        ┌──────────────────────────┐
        │ [5] MAIN 워크플로우      │
        │                          │
        │ • 통합 오케스트레이션   │
        │ • 모듈 조합 호출        │
        │ • 메트릭 수집           │
        │ • 최종 답변 반환        │
        └──────────────────────────┘
                    │
                    ▼
        ┌──────────────────────────┐
        │  📤 최종 답변 반환       │
        │     (사용자에게)         │
        └──────────────────────────┘
```

---

## 🔄 CRAG 패턴 상세 흐름 (의료 상담)

```
입력: "강아지 피부 질환 증상?"
        │
        ▼
┌──────────────────────────────┐
│ 1. 입력 분류                 │
│    → medical_consultation    │
└──────────────────────────────┘
        │
        ▼
┌──────────────────────────────────────────┐
│ 2. RAG 검색 (Retrieval)                  │
│                                          │
│    [쿼리 임베딩]                         │
│    "강아지 피부 질환 증상?"              │
│              ↓                           │
│    [벡터 DB 검색] Top-K=5 문서          │
│              ↓                           │
│    Retrieved: [doc1, doc2, ...]         │
└──────────────────────────────────────────┘
        │
        ▼
┌──────────────────────────────────────────┐
│ 3. 문서 관련성 평가 (Grading)            │
│                                          │
│    각 문서에 대해:                       │
│    "이 문서가 질문에 관련 있는가?"      │
│              ↓                           │
│    LLM 평가: Yes / No                    │
│              ↓                           │
│    Filtered: [doc1, doc3] (관련 문서)  │
└──────────────────────────────────────────┘
        │
        ▼
        ┌─────────────────┐
        │ 관련 문서       │
        │ 충분한가?       │
        └────┬────────────┘
             │
        ┌────┴─────┐
        │           │
       YES         NO
        │           │
        ▼           ▼
    [사용]    ┌─────────────────────┐
             │ 4. 웹 검색 폴백      │
             │                     │
             │ Tavily API 호출     │
             │ 웹 검색 결과 수집   │
             │                     │
             │ Web Results         │
             └─────────────────────┘
        │           │
        └────┬──────┘
             │
             ▼
    ┌──────────────────────┐
    │ 5. 컨텍스트 병합     │
    │                      │
    │ RAG 결과 + 웹 결과  │
    │ (또는 하나만 사용)  │
    │                      │
    │ Context 텍스트      │
    └──────────────────────┘
        │
        ▼
    ┌──────────────────────────────────┐
    │ 6. LLM 응답 생성                 │
    │                                  │
    │ System: "의료 전문가 역할"       │
    │ User: {쿼리}                     │
    │ Context: {검색 결과}             │
    │              ↓                   │
    │ GPT-4o-mini API 호출           │
    │              ↓                   │
    │ Generated Response               │
    └──────────────────────────────────┘
        │
        ▼
    ┌──────────────────────────────────┐
    │ 7. 응답 평가                     │
    │                                  │
    │ • 정확도: 정보가 맞나?          │
    │ • 명확성: 이해하기 쉬운가?      │
    │ • 완전성: 충분한가?              │
    │ • 안전성: 의료 조언 안전한가?  │
    │              ↓                   │
    │ Evaluation Score: 0.85           │
    └──────────────────────────────────┘
        │
        ▼
        ┌──────────────────┐
        │ 평가 통과?       │
        │ (점수 ≥ 0.75)   │
        └────┬─────────────┘
             │
        ┌────┴─────┐
        │           │
       YES         NO
        │           │
        ▼           ▼
    [확정]      ┌─────────────────┐
               │ 8. 재작성       │
               │                 │
               │ 평가 피드백:   │
               │ "의료 면책   │
               │  조항 추가"  │
               │              │
               │ Rewrite...  │
               │              │
               │ [재평가]     │
               └─────────────────┘
        │           │
        └────┬──────┘
             │
             ▼
    ┌──────────────────┐
    │ ✅ 최종 응답     │
    │    반환         │
    └──────────────────┘
```

---

## 📊 모듈 간 의존성 그래프

```
                     main.py
                    (오케스트레이션)
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   input_             rag_            map_
   classifier      handler          handler
        │                │                │
        └────────────────┼────────────────┘
                         │
                    llm_generator
                         │
                         ▼
                 evaluation_
                 controller


의존성 순서:
1. input_classifier      (독립적)
2. rag_handler           (독립적)
3. map_handler           (독립적)
4. llm_generator         (의존: 없음)
5. evaluation_controller (의존: 없음)
6. main.py              (의존: 위 모든 모듈)
```

---

## 💾 데이터 구조

### Query → Classification
```python
Input:  "강아지 피부 질환 증상?"
Output: "medical_consultation"
```

### Query → Search Context
```python
Input:  "강아지 피부 질환 증상?"
        (with classification="medical_consultation")

Output: {
    'context': "피부질환 관련 문서 텍스트...",
    'source': 'rag'  # 또는 'web'
}
```

### Query + Context → Response
```python
Input:  {
    'query': "강아지 피부 질환 증상?",
    'context': "피부질환 관련 문서...",
    'system_prompt': "의료 전문가 역할..."
}

Output: "생성된 최종 답변 텍스트..."
```

### Response → Evaluation
```python
Input:  "생성된 답변..."

Output: {
    'pass': True,
    'scores': {
        'accuracy': 0.85,
        'clarity': 0.90,
        'completeness': 0.80,
        'safety': 0.88
    },
    'average_score': 0.858,
    'feedback': "...",
    'reason': "..."
}
```

---

## 🔀 분기 로직 (Decision Points)

### 분기 1: Query Type 기반 경로 선택
```
Query
  ├─ "의료" 키워드 → medical_consultation
  │       └─ rag_handler.perform_rag_search()
  │
  ├─ "병원/위치" 키워드 → map_search
  │       └─ map_handler.get_map_info()
  │
  └─ 기타 → general
          └─ rag_handler.search_with_fallback()
```

### 분기 2: RAG/웹 검색 폴백 (CRAG 패턴)
```
RAG 검색
  ├─ 관련 문서 충분 (점수 ≥ threshold)
  │       └─ RAG 결과 사용
  │
  └─ 관련 문서 부족 (점수 < threshold)
          └─ 웹 검색으로 전환
```

### 분기 3: 평가 기반 흐름 제어
```
Evaluation Score
  ├─ ≥ 0.75: ACCEPT
  │       └─ 응답 반환
  │
  ├─ 0.50-0.75: REWRITE
  │       └─ 피드백 적용하여 재작성 (최대 2회)
  │
  └─ < 0.50: ESCALATE
          └─ 경고 및 기본 응답 반환
```

---

## ⚙️ 컴포넌트 역할 분담

| 모듈 | 책임 | 입력 | 출력 |
|------|------|------|------|
| **input_classifier** | 쿼리 분류 | 문자열 쿼리 | 분류 카테고리 |
| **rag_handler** | 정보 검색 | 쿼리 + 분류 | 컨텍스트 텍스트 |
| **map_handler** | 지도 정보 | 쿼리 | 병원/지도 정보 |
| **llm_generator** | 답변 생성 | 쿼리 + 컨텍스트 | 최종 답변 |
| **evaluation_controller** | 품질 평가 | 응답 | 평가 점수 + 액션 |
| **main.py** | 워크플로우 조율 | 쿼리 | 최종 답변 + 메트릭 |

---

## 🔗 외부 시스템 통합 포인트

```
스켈레톤 코드
    │
    ├─ OpenAI GPT API (LLM 호출)
    │  └─ llm_generator.generate_response()
    │
    ├─ 벡터 DB (Chroma)
    │  └─ rag_handler.perform_rag_search()
    │
    ├─ 웹 검색 API (Tavily)
    │  └─ rag_handler.perform_web_search()
    │
    └─ 지도 API (카카오맵)
       └─ map_handler.get_map_info()
```

---

## 📈 성능 메트릭 추적

```
main.py
  └─ collect_evaluation_metrics()
     ├─ response_length
     ├─ generation_time
     ├─ rewrite_count
     ├─ evaluation_scores
     │  ├─ accuracy
     │  ├─ clarity
     │  ├─ completeness
     │  └─ safety
     ├─ average_score
     └─ passed_evaluation
```

---

## 🚀 확장성 고려사항

### 모듈 추가 가능성
```
향후 추가 가능한 모듈:
├─ cache_manager.py      (응답 캐싱)
├─ feedback_collector.py (사용자 피드백)
├─ analytics.py          (분석 및 통계)
├─ conversation_manager.py (멀티턴 대화)
└─ error_handler.py      (에러 처리)
```

### 병렬 처리 가능성
```
main.py의 batch_workflow()
├─ 여러 쿼리 순차 처리
└─ (향후) 병렬 처리로 확장 가능
```

### 캐싱 전략
```
향후 최적화:
├─ 쿼리 → 분류 결과 캐싱
├─ 검색 결과 캐싱
├─ LLM 응답 캐싱
└─ 평가 결과 캐싱
```

---

## 🎯 스켈레톤 → 구현 체크리스트

- [ ] **Phase 1**: 각 모듈 기본 구현
  - [ ] input_classifier: 분류 모델 연결
  - [ ] rag_handler: 벡터 DB 연결
  - [ ] map_handler: 지도 API 연결
  
- [ ] **Phase 2**: LLM 및 평가 통합
  - [ ] llm_generator: OpenAI API 연결
  - [ ] evaluation_controller: 평가 로직 구현
  
- [ ] **Phase 3**: 통합 및 최적화
  - [ ] main.py: 전체 워크플로우 테스트
  - [ ] 성능 모니터링
  - [ ] 에러 핸들링

- [ ] **Phase 4**: 고급 기능
  - [ ] 피드백 기반 학습
  - [ ] 멀티턴 대화
  - [ ] 캐싱 및 최적화

---

**작성일**: 2025-12-05  
**버전**: 0.1.0

