# ğŸ¥ RAG ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸ (Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜)

ì˜ë£Œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **LangGraph CRAG (Corrective RAG) ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.  
**Streamlit ì›¹ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤**ë¡œ ì‰½ê³  í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```bash
# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 2. API í‚¤ ì„¤ì •
# .env íŒŒì¼ ìƒì„± í›„ OPENAI_API_KEY ì¶”ê°€

# 3. ì•± ì‹¤í–‰ (ê¸°ë³¸ ë²„ì „)
streamlit run app.py

# ë˜ëŠ” ê³ ê¸‰ ë²„ì „ ì‹¤í–‰
streamlit run app_advanced.py
```

ğŸ‘‰ [ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ](./QUICKSTART.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”!

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
.
â”œâ”€â”€ app.py                          # â­ Streamlit ë©”ì¸ ì›¹ ì•±
â”œâ”€â”€ app_advanced.py                 # ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ì›¹ ì•±
â”œâ”€â”€ streamlit_config.py             # âš™ï¸ ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml                 # Streamlit ì„¤ì •
â”œâ”€â”€ QUICKSTART.md                   # ğŸš€ 5ë¶„ ì‹œì‘ ê°€ì´ë“œ
â”œâ”€â”€ STREAMLIT_GUIDE.md              # ğŸ“– ìƒì„¸ ì‚¬ìš© ì„¤ëª…ì„œ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py                 # LangGraph CRAG íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ retrieval.py                # Retriever (Top-K=5)
â”‚   â”œâ”€â”€ embeddings.py               # Embedding ëª¨ë¸ ê´€ë¦¬
â”‚   â”œâ”€â”€ ingestion.py                # ë°ì´í„° ë¡œë”©
â”‚   â”œâ”€â”€ chunking.py                 # ë¬¸ì„œ ë¶„í• 
â”‚   â””â”€â”€ ...
â”œâ”€â”€ chroma_db/                      # ë²¡í„° DB (ì‚¬ì „ ìƒì„±ë¨)
â”œâ”€â”€ requirements.txt                # í•„ìˆ˜ íŒ¨í‚¤ì§€ ëª©ë¡
â””â”€â”€ README.md                       # ì´ íŒŒì¼
```

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

### ğŸ¯ í•µì‹¬ RAG ê¸°ëŠ¥
- **Retrieval**: ë²¡í„° DBì—ì„œ Top-K=5 ë¬¸ì„œ ê²€ìƒ‰ (Similarity Score)
- **Grading**: LLM ê¸°ë°˜ ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (Yes/No)
- **Web Search Fallback**: ê´€ë ¨ ë¬¸ì„œ ë¶€ì¡± ì‹œ Tavily APIë¡œ ìë™ ì›¹ ê²€ìƒ‰
- **Generation**: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ LLM ë‹µë³€ ìƒì„±

### ğŸŒ Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤
- âœ… ì±„íŒ… í˜•ì‹ì˜ ì§ê´€ì ì¸ UI
- ğŸ“š ì°¸ê³  ë¬¸ì„œ ì¶œì²˜ í‘œì‹œ (ë‚´ë¶€/ì›¹ êµ¬ë¶„)
- ğŸ› ë””ë²„ê·¸ ì •ë³´ ë³´ê¸° (Similarity Score, ê´€ë ¨ì„± íŒì •, ì›¹ ê²€ìƒ‰ ì—¬ë¶€)
- ğŸ“Š ëŒ€í™” í†µê³„ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ğŸ’¾ ì„¸ì…˜ ìƒíƒœ ìë™ ìœ ì§€

### âš™ï¸ ê³ ê¸‰ ê¸°ëŠ¥ (app_advanced.py)
- ğŸšï¸ ì„¤ì • í”„ë¦¬ì…‹ (Fast, Balanced, Accurate, Creative)
- ğŸ”§ LLM ëª¨ë¸ ì„ íƒ (gpt-4o-mini, gpt-4-turbo, gpt-4o)
- ğŸ›ï¸ Top-K, Temperature ë™ì  ì¡°ì •
- â±ï¸ ì„±ëŠ¥ ì¶”ì  ë° ê·¸ë˜í”„ ì‹œê°í™”
- ğŸ“ˆ ì‘ë‹µ ì‹œê°„ ì¶”ì´ ë¶„ì„

### ğŸ“± ì‚¬ìš©ì ê²½í—˜
- ğŸš€ í•œ ë²ˆì˜ ì„¤ì •ìœ¼ë¡œ ìë™ ìºì‹± (ë¹ ë¥¸ ì¬ë¡œë”©)
- ğŸ¨ ë°˜ì‘í˜• ë””ìì¸ ë° ì»¤ìŠ¤í…€ CSS
- ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ ë¹ ë¥¸ ì„ íƒ
- ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™” ë° ì¬ì‹œì‘

## ğŸ”§ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1ë‹¨ê³„: í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**ì£¼ìš” íŒ¨í‚¤ì§€:**
- streamlit: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬
- langchain: LLM ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- langgraph: ìƒíƒœ ê·¸ë˜í”„ (CRAG íŒ¨í„´)
- chromadb: ë²¡í„° DB
- openai: OpenAI API

### 2ë‹¨ê³„: API í‚¤ ì„¤ì •

`.env` íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±:

```bash
OPENAI_API_KEY=sk-your-key-here
TAVILY_API_KEY=tvly-your-key-here  # ì„ íƒì‚¬í•­ (ì›¹ ê²€ìƒ‰)
```

**API íšë“:**
- OpenAI: https://platform.openai.com/api-keys
- Tavily: https://tavily.com/

### 3ë‹¨ê³„: Streamlit ì•± ì‹¤í–‰

**ê¸°ë³¸ ë²„ì „ (ê¶Œì¥):**
```bash
streamlit run app.py
```

**ê³ ê¸‰ ë²„ì „ (ì„¤ì • í”„ë¦¬ì…‹ í¬í•¨):**
```bash
streamlit run app_advanced.py
```

ğŸŒ ìë™ìœ¼ë¡œ ë¸Œë¼ìš°ì €ê°€ ì—´ë¦½ë‹ˆë‹¤ â†’ `http://localhost:8501`

## ğŸ“– ê°€ì´ë“œ ë¬¸ì„œ

| ë¬¸ì„œ | ì„¤ëª… |
|------|------|
| [ğŸš€ QUICKSTART.md](./QUICKSTART.md) | 5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸° |
| [ğŸ“– STREAMLIT_GUIDE.md](./STREAMLIT_GUIDE.md) | ìƒì„¸ ì‚¬ìš© ì„¤ëª…ì„œ |
| [âš™ï¸ streamlit_config.py](./streamlit_config.py) | ì„¤ì • ë° í”„ë¦¬ì…‹ |

## ğŸ’» ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

ê¸°ì¡´ í„°ë¯¸ë„ í™˜ê²½ì—ì„œë„ RAGë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from src.embeddings import get_embedding_model, load_vectorstore
from src.retrieval import create_retriever
from src.pipeline import LangGraphRAGPipeline

# RAG íŒŒì´í”„ë¼ì¸ ì„¤ì •
embedding_model = get_embedding_model("openai")
vectorstore = load_vectorstore(embedding_model)
retriever = create_retriever(vectorstore, top_k=5)

pipeline = LangGraphRAGPipeline(retriever, debug=True)

# ì§ˆë¬¸í•˜ê¸°
result = pipeline.rag_pipeline_with_sources("ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ì˜ ì¦ìƒì€?")
print(result['answer'])
print(result['sources'])
```

## âš™ï¸ ì„¤ì • ì˜µì…˜

### Streamlit ì„¤ì • í”„ë¦¬ì…‹

**app_advanced.py ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒ:**

| í”„ë¦¬ì…‹ | ì†ë„ | í’ˆì§ˆ | ìš©ë„ |
|--------|------|------|------|
| âš¡ Fast | 1-2ì´ˆ | ë³´í†µ | ë¹ ë¥¸ ë‹µë³€ í•„ìš” |
| âš–ï¸ Balanced | 2-3ì´ˆ | ì¢‹ìŒ | ì¼ë°˜ì ì¸ ì‚¬ìš© (ê¸°ë³¸ê°’) |
| ğŸ¯ Accurate | 3-5ì´ˆ | ìµœê³  | ì •í™•í•œ ë‹µë³€ í•„ìš” |
| âœ¨ Creative | 3-5ì´ˆ | ì°½ì˜ì  | ë‹¤ì–‘í•œ ê´€ì  í•„ìš” |

### LLM ëª¨ë¸ ì„ íƒ

```python
# app.py ìˆ˜ì •
pipeline = LangGraphRAGPipeline(
    retriever,
    llm_model="gpt-4o",  # "gpt-4o-mini", "gpt-4-turbo", "gpt-4o"
    temperature=0.0,
    debug=False
)
```

### Top-K ê°’ ì¡°ì •

```python
# retriever top-k ì„¤ì •
retriever = create_retriever(vectorstore, top_k=10)
```

## ğŸ“š ì½”ì–´ ëª¨ë“ˆ ì„¤ëª…

### ğŸ”„ pipeline.py - LangGraph CRAG íŒŒì´í”„ë¼ì¸
```
[ì§ˆë¬¸] â†’ [Retrieve] â†’ [Grade] â†’ [Decision] 
              â†“          â†“          â†“
          Top-K=5    Yes/No     Generate?
                               â†“
                        [Web Search] (ì„ íƒ)
                               â†“
                          [Generate]
                               â†“
                         [ìµœì¢… ë‹µë³€]
```

**ì£¼ìš” í´ë˜ìŠ¤:**
- `LangGraphRAGPipeline`: 5ë‹¨ê³„ CRAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- `CRAGState`: ìƒíƒœ ê´€ë¦¬
- `rag_pipeline_with_sources()`: ë‹µë³€ + ì¶œì²˜ ì •ë³´ ë°˜í™˜

### ğŸ” retrieval.py - ë²¡í„° ê²€ìƒ‰
- `SimpleRetriever`: Top-K ê²€ìƒ‰ (ê¸°ë³¸ê°’: 5)
- `retrieve_with_scores()`: ìœ ì‚¬ë„ ì ìˆ˜ í•¨ê»˜ ë°˜í™˜
- Similarity Score: 1 - cosine_distance

### ğŸ§  embeddings.py - ì„ë² ë”© ëª¨ë¸
- `get_embedding_model()`: OpenAI ë˜ëŠ” HuggingFace ì„ íƒ
- `load_vectorstore()`: Chroma DB ë¡œë“œ
- ê¸°ë³¸ ëª¨ë¸: `text-embedding-3-small`

### ğŸ“„ ingestion.py - ë°ì´í„° ë¡œë”©
- JSON íŒŒì¼ ë¡œë“œ ë° Document ë³€í™˜
- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (file_name, department, title ë“±)

### âœ‚ï¸ chunking.py - ë¬¸ì„œ ë¶„í• 
- í† í° ê¸°ë°˜ ì²­í‚¹ (min: 300, max: 500)
- Overlap: 25% (ì¤‘ë³µ ì²˜ë¦¬)

## ğŸš¨ ì£¼ì˜ì‚¬í•­

1. **API í‚¤**: `.env` íŒŒì¼ì— `OPENAI_API_KEY` í•„ìˆ˜ ì„¤ì •
2. **ë²¡í„° DB**: ì‚¬ì „ ìƒì„±ëœ `chroma_db` ë””ë ‰í† ë¦¬ í•„ìš”
3. **ë©”ëª¨ë¦¬**: ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹œ 3-4GB í•„ìš”
4. **ë„¤íŠ¸ì›Œí¬**: OpenAI API í†µì‹  í•„ìˆ˜

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### "OPENAI_API_KEY not found"
```bash
# .env íŒŒì¼ ìƒì„± ë° API í‚¤ ì¶”ê°€
OPENAI_API_KEY=sk-your-key-here
```

### "Chroma DB not found"
```bash
# ê¸°ì¡´ chroma_db ë””ë ‰í† ë¦¬ í™•ì¸
# ë˜ëŠ” ë°ì´í„° ì¬ë¡œë“œ í•„ìš”
python src/ingestion.py
```

### "Port 8501 already in use"
```bash
streamlit run app.py --server.port 8502
```

### ëŠë¦° ì‘ë‹µ
```bash
# ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©: app.pyì—ì„œ llm_model ë³€ê²½
llm_model="gpt-4o-mini"  # ë¹ ë¦„

# ë˜ëŠ” ê³ ê¸‰ ë²„ì „ì—ì„œ Fast í”„ë¦¬ì…‹ ì„ íƒ
```

ë” ë§ì€ ë„ì›€ë§ì€ [STREAMLIT_GUIDE.md](./STREAMLIT_GUIDE.md) ì°¸ì¡°

## ğŸ“Š ì„±ëŠ¥ ê¸°ì¤€

| ì‘ì—… | ì‹œê°„ | 
|------|------|
| íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” | 2-3ì´ˆ |
| í‰ê·  ì‘ë‹µ ì‹œê°„ | 2-4ì´ˆ (gpt-4o-mini) |
| ì›¹ ê²€ìƒ‰ í¬í•¨ | 4-6ì´ˆ |
| ì‹œìŠ¤í…œ ì´ ë©”ëª¨ë¦¬ | 3-5GB |

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.

