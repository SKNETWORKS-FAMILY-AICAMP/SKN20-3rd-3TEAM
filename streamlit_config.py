"""
Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • íŒŒì¼
RAG íŒŒì´í”„ë¼ì¸ì˜ íŒŒë¼ë¯¸í„°ì™€ UI ì„¤ì •ì„ ê´€ë¦¬
"""

from dataclasses import dataclass
from typing import Optional

# ==================== RAG íŒŒì´í”„ë¼ì¸ ì„¤ì • ====================

@dataclass
class RAGConfig:
    """RAG íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    
    # ë²¡í„° DB ì„¤ì •
    persist_directory: str = "./chroma_db"
    collection_name: str = "rag_collection"
    
    # Retriever ì„¤ì •
    top_k: int = 5  # ì´ˆê¸° ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
    
    # LLM ì„¤ì •
    llm_model: str = "gpt-4o-mini"  # "gpt-4o-mini", "gpt-4-turbo", "gpt-4o"
    temperature: float = 0.0  # ê²°ì •ë¡ ì  ë‹µë³€ (0.0-1.0)
    
    # ìž„ë² ë”© ëª¨ë¸ ì„¤ì •
    embedding_model_type: str = "openai"  # "openai" ë˜ëŠ” "huggingface"
    embedding_model_name: Optional[str] = "text-embedding-3-small"
    
    # ì›¹ ê²€ìƒ‰ ì„¤ì •
    enable_web_search: bool = True
    web_search_k: int = 3  # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    
    # ë””ë²„ê·¸ ì„¤ì •
    debug_mode: bool = False  # Streamlit í™˜ê²½ì—ì„œëŠ” í•­ìƒ False ê¶Œìž¥
    show_logs: bool = False


# ==================== Streamlit UI ì„¤ì • ====================

@dataclass
class StreamlitUIConfig:
    """Streamlit UI ì„¤ì •"""
    
    # íŽ˜ì´ì§€ ì„¤ì •
    page_title: str = "ðŸ¥ ì˜ë£Œ RAG ì±—ë´‡"
    page_icon: str = "ðŸ¥"
    layout: str = "wide"  # "centered" ë˜ëŠ” "wide"
    
    # ìƒ‰ìƒ í…Œë§ˆ
    primary_color: str = "#2196F3"  # íŒŒëž€ìƒ‰
    background_color: str = "#FFFFFF"  # í°ìƒ‰
    secondary_bg_color: str = "#F8F9FA"  # ì—°í•œ íšŒìƒ‰
    
    # ì±„íŒ… UI ì„¤ì •
    show_sources_default: bool = True  # ê¸°ë³¸ì ìœ¼ë¡œ ì¶œì²˜ í‘œì‹œ
    show_debug_info_default: bool = False  # ê¸°ë³¸ì ìœ¼ë¡œ ë””ë²„ê·¸ ì •ë³´ ìˆ¨ê¹€
    show_thinking_process: bool = True  # ìƒê° ê³¼ì • í‘œì‹œ
    
    # íŽ˜ì´ì§€ë„¤ì´ì…˜
    messages_per_page: int = 10
    enable_pagination: bool = True
    
    # ìž…ë ¥ ì„¤ì •
    placeholder_text: str = "ì˜ˆ: ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ì˜ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
    max_input_length: int = 1000
    input_text_area_height: int = 100
    
    # ë²„íŠ¼ ë° UI ìš”ì†Œ
    show_example_questions: bool = True
    show_statistics: bool = True
    show_help: bool = True
    enable_export: bool = False  # ëŒ€í™” ë‚´ë³´ë‚´ê¸°
    
    # ì„¸ì…˜ íƒ€ìž„ì•„ì›ƒ (ì´ˆ ë‹¨ìœ„)
    session_timeout: int = 1800  # 30ë¶„


# ==================== ì˜ˆì‹œ ì§ˆë¬¸ ====================

EXAMPLE_QUESTIONS = [
    "ê°•ì•„ì§€ í”¼ë¶€ ì§ˆí™˜ì˜ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ë²¼ë£© ì•ŒëŸ¬ì§€ì„± í”¼ë¶€ì—¼ ì¹˜ë£Œë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
    "ê°œì˜ í˜ˆì•¡í˜•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "ë©´ì—­ ì²´ê³„ ì§ˆí™˜ì˜ ì¢…ë¥˜ëŠ”?",
    "ê°œì—ì„œ ê°ì—¼ë³‘ì˜ ì˜ˆë°© ë°©ë²•ì€?",
    "ì•ŒëŸ¬ì§€ ë°˜ì‘ì˜ ë‹¨ê³„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "ìžê°€ë©´ì—­ì§ˆí™˜ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
    "ë©´ì—­ê²°í•ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
]


# ==================== ë””ë²„ê·¸ ì •ë³´ ì„¤ì • ====================

@dataclass
class DebugConfig:
    """ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ ì„¤ì •"""
    
    # í‘œì‹œ í•­ëª©
    show_similarity_scores: bool = True
    show_grade_results: bool = True
    show_web_search_info: bool = True
    show_processing_time: bool = True
    show_token_usage: bool = False  # OpenAI í† í° ì‚¬ìš©ëŸ‰
    
    # ìƒì„¸ë„ ë ˆë²¨ (1: ìµœì†Œ, 3: ìµœëŒ€)
    verbosity_level: int = 2


# ==================== ê¸°ë³¸ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ====================

# ê¸°ë³¸ RAG ì„¤ì •
default_rag_config = RAGConfig()

# ê¸°ë³¸ UI ì„¤ì •
default_ui_config = StreamlitUIConfig()

# ê¸°ë³¸ ë””ë²„ê·¸ ì„¤ì •
default_debug_config = DebugConfig()


# ==================== í”„ë¦¬ì…‹ ì„¤ì • ====================

class RAGConfigPresets:
    """RAG ì„¤ì • í”„ë¦¬ì…‹"""
    
    @staticmethod
    def fast() -> RAGConfig:
        """ë¹ ë¥¸ ì‘ë‹µ ì„¤ì • (1-2ì´ˆ)"""
        return RAGConfig(
            llm_model="gpt-4o-mini",
            temperature=0.0,
            top_k=3,
            debug_mode=False
        )
    
    @staticmethod
    def balanced() -> RAGConfig:
        """ê· í˜•ìž¡ížŒ ì„¤ì • (2-3ì´ˆ, ê¸°ë³¸ê°’)"""
        return RAGConfig(
            llm_model="gpt-4o-mini",
            temperature=0.0,
            top_k=5,
            debug_mode=False
        )
    
    @staticmethod
    def accurate() -> RAGConfig:
        """ì •í™•í•œ ë‹µë³€ ì„¤ì • (3-5ì´ˆ)"""
        return RAGConfig(
            llm_model="gpt-4o",
            temperature=0.0,
            top_k=10,
            debug_mode=False
        )
    
    @staticmethod
    def creative() -> RAGConfig:
        """ì°½ì˜ì ì¸ ë‹µë³€ ì„¤ì • (temperature > 0)"""
        return RAGConfig(
            llm_model="gpt-4o",
            temperature=0.7,
            top_k=5,
            debug_mode=False
        )
    
    @staticmethod
    def development() -> RAGConfig:
        """ê°œë°œ ëª¨ë“œ ì„¤ì •"""
        return RAGConfig(
            llm_model="gpt-4o-mini",
            temperature=0.0,
            top_k=5,
            debug_mode=True,
            show_logs=True
        )


# ==================== í•¨ìˆ˜ ====================

def get_config_description(preset_name: str) -> str:
    """í”„ë¦¬ì…‹ ì„¤ëª… ë°˜í™˜"""
    descriptions = {
        "fast": "âš¡ ë¹ ë¥¸ ì‘ë‹µ (1-2ì´ˆ)\nìµœì†Œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©, ê¸°ë³¸ ì§ˆë¬¸ ì¶”ì²œ",
        "balanced": "âš–ï¸ ê· í˜•ìž¡ížŒ (2-3ì´ˆ)\nëŒ€ë¶€ë¶„ì˜ ì§ˆë¬¸ì— ìµœì , ê¸°ë³¸ ì„¤ì •",
        "accurate": "ðŸŽ¯ ì •í™•í•œ ë‹µë³€ (3-5ì´ˆ)\nìµœê³  í’ˆì§ˆ, ë³µìž¡í•œ ì§ˆë¬¸ ì¶”ì²œ",
        "creative": "âœ¨ ì°½ì˜ì  (3-5ì´ˆ)\në‹¤ì–‘í•œ ê´€ì  ì œê³µ, ë‚®ì€ ì˜¨ë„",
        "development": "ðŸ› ê°œë°œ ëª¨ë“œ\në¡œê·¸ ë° ë””ë²„ê·¸ ì •ë³´ í¬í•¨",
    }
    return descriptions.get(preset_name, "ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¦¬ì…‹")


def validate_config(config: RAGConfig) -> bool:
    """ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬"""
    # Top-K ë²”ìœ„
    if not (1 <= config.top_k <= 20):
        raise ValueError("top_këŠ” 1-20 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤")
    
    # Temperature ë²”ìœ„
    if not (0.0 <= config.temperature <= 1.0):
        raise ValueError("temperatureëŠ” 0.0-1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤")
    
    # LLM ëª¨ë¸ ìœ íš¨ì„±
    valid_models = ["gpt-4o-mini", "gpt-4-turbo", "gpt-4o", "gpt-3.5-turbo"]
    if config.llm_model not in valid_models:
        raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ LLM ëª¨ë¸: {config.llm_model}")
    
    # ìž„ë² ë”© ëª¨ë¸ íƒ€ìž… ìœ íš¨ì„±
    if config.embedding_model_type not in ["openai", "huggingface"]:
        raise ValueError("embedding_model_typeì€ 'openai' ë˜ëŠ” 'huggingface'ì—¬ì•¼ í•©ë‹ˆë‹¤")
    
    return True


# ==================== ì˜ˆì‹œ ì‚¬ìš© ====================

if __name__ == "__main__":
    # ê¸°ë³¸ ì„¤ì • ì¶œë ¥
    print("ê¸°ë³¸ RAG ì„¤ì •:")
    print(f"  LLM ëª¨ë¸: {default_rag_config.llm_model}")
    print(f"  Top-K: {default_rag_config.top_k}")
    print(f"  Temperature: {default_rag_config.temperature}")
    print()
    
    # í”„ë¦¬ì…‹ ì„¤ì • ì¶œë ¥
    print("ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¦¬ì…‹:")
    presets = ["fast", "balanced", "accurate", "creative", "development"]
    for preset in presets:
        print(f"  {preset}: {get_config_description(preset)}")
    print()
    
    # í”„ë¦¬ì…‹ ì ìš© ì˜ˆì‹œ
    print("í”„ë¦¬ì…‹ ì ìš© ì˜ˆì‹œ:")
    fast_config = RAGConfigPresets.fast()
    print(f"  Fast í”„ë¦¬ì…‹ - LLM: {fast_config.llm_model}, Top-K: {fast_config.top_k}")
    
    accurate_config = RAGConfigPresets.accurate()
    print(f"  Accurate í”„ë¦¬ì…‹ - LLM: {accurate_config.llm_model}, Top-K: {accurate_config.top_k}")

