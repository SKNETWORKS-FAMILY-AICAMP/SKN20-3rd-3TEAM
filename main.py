"""
í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ìµœì í™” ë²„ì „)
- ìºì‹± ì‹œìŠ¤í…œ (Vector DB + pkl)
- í‚¤ì›Œë“œ ì¶”ì¶œ (Query Re-writing)
- ë¶ˆìš©ì–´ ì œê±°
- ì²­í¬ ì‚¬ì´ì¦ˆ ìµœì í™” (512 í† í°)
- ìƒëŒ€ ê²½ë¡œ ê´€ë¦¬
"""

import os
import sys
from dotenv import load_dotenv

# src ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data.preprocessing import load_and_preprocess_data, load_multiple_departments
from rag.pipeline import setup_rag_pipeline, query_rag
from agent.workflow import run_agent

# ìµœì í™” ëª¨ë“ˆ import
try:
    from utils.optimization import manage_persistence, get_project_path
    OPTIMIZATION_ENABLED = True
    print("âœ… ìµœì í™” ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ (ìºì‹±, í‚¤ì›Œë“œ ì¶”ì¶œ í™œì„±í™”)")
except ImportError:
    OPTIMIZATION_ENABLED = False
    print("âš ï¸ ìµœì í™” ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")

# instruction ì¶”ì¶œ í•¨ìˆ˜
def extract_system_instruction(labeled_documents):
    """
    ë¼ë²¨ë§ ë°ì´í„°ì—ì„œ instructionì„ ì¶”ì¶œí•˜ì—¬ System Promptì— í™œìš©
    
    Args:
        labeled_documents: ë¼ë²¨ë§ ë°ì´í„° Document ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ëŒ€í‘œ instruction ë¬¸ìì—´
    """
    instructions = []
    for doc in labeled_documents:
        if doc.metadata.get('data_type') == 'labeled':
            instruction = doc.metadata.get('instruction', '')
            if instruction and instruction not in instructions:
                instructions.append(instruction)
    
    # ê°€ì¥ í¬ê´„ì ì¸ instruction ë°˜í™˜ (ë˜ëŠ” ì²« ë²ˆì§¸)
    return instructions[0] if instructions else ""


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ìµœì í™” ë²„ì „)"""
    
    # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸
    global OPTIMIZATION_ENABLED
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    print("="*80)
    print("ğŸ¾ ë°˜ë ¤ë™ë¬¼ ê±´ê°• ìƒë‹´ ì±—ë´‡ ì‹œìŠ¤í…œ (ìµœì í™” ë²„ì „)")
    print("="*80)
    
    # ========================================================================
    # ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    # ========================================================================
    if OPTIMIZATION_ENABLED:
        # ìµœì í™” ëª¨ë“ˆì˜ ê²½ë¡œ ê´€ë¦¬ ì‚¬ìš©
        source_base_path = get_project_path(
            'data', 
            '59.ë°˜ë ¤ê²¬ ì„±ì¥ ë° ì§ˆë³‘ ê´€ë ¨ ë§ë­‰ì¹˜ ë°ì´í„°',
            '3.ê°œë°©ë°ì´í„°',
            '1.ë°ì´í„°',
            'Training',
            '01.ì›ì²œë°ì´í„°'
        )
        persist_dir = get_project_path('data', 'chroma_db')
        print(f"ğŸ“‚ ìƒëŒ€ ê²½ë¡œ ê´€ë¦¬ í™œì„±í™”")
        print(f"   - ë°ì´í„°: {source_base_path}")
        print(f"   - Vector DB: {persist_dir}")
    else:
        # ê¸°ì¡´ ë°©ì‹ (ì ˆëŒ€ ê²½ë¡œ)
        source_base_path = r"c:\LDG_CODES\SKN20\3rd_prj\data\59.ë°˜ë ¤ê²¬ ì„±ì¥ ë° ì§ˆë³‘ ê´€ë ¨ ë§ë­‰ì¹˜ ë°ì´í„°\3.ê°œë°©ë°ì´í„°\1.ë°ì´í„°\Training\01.ì›ì²œë°ì´í„°"
        persist_dir = "./chroma_db"
    
    # ========================================================================
    # 1ë‹¨ê³„: ìºì‹± ì‹œìŠ¤í…œì„ í†µí•œ RAG ì´ˆê¸°í™”
    # ========================================================================
    print("\n[1ë‹¨ê³„] RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    
    if OPTIMIZATION_ENABLED:
        print("ğŸš€ ìµœì í™” ëª¨ë“œ: ìºì‹± ì‹œìŠ¤í…œ í™œì„±í™”")
        print("   - Vector DB ì¡´ì¬ â†’ ì¦‰ì‹œ ë¡œë“œ (~5ì´ˆ)")
        print("   - pkl ì¡´ì¬ â†’ ì„ë² ë”©ë§Œ ìˆ˜í–‰ (~2ë¶„)")
        print("   - ì—†ìŒ â†’ ì „ì²´ ì¬êµ¬ì¶• (~8ë¶„)")
        
        try:
            rag_result = manage_persistence(
                data_path=source_base_path,
                persist_dir=persist_dir,
                force_rebuild=False  # Trueë¡œ ë³€ê²½í•˜ë©´ ê°•ì œ ì¬êµ¬ì¶•
            )
            
            retriever = rag_result["retriever"]
            vectorstore = rag_result["vectorstore"]
            status = rag_result["status"]
            
            print(f"\nâœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (ìƒíƒœ: {status})")
            
            # RAG ì»´í¬ë„ŒíŠ¸ êµ¬ì„± (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
            from langchain_openai import ChatOpenAI
            from langchain_core.prompts import ChatPromptTemplate
            from langchain_core.output_parsers import StrOutputParser
            from langchain_core.runnables import RunnablePassthrough
            
            llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
            
            # ê°„ë‹¨í•œ RAG ì²´ì¸ êµ¬ì„±
            from rag.pipeline import VETERINARY_EXPERT_SYSTEM_PROMPT
            prompt = ChatPromptTemplate.from_template(VETERINARY_EXPERT_SYSTEM_PROMPT)
            
            def format_docs(docs):
                formatted = []
                for i, doc in enumerate(docs, 1):
                    dept = doc.metadata.get('department', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    title = doc.metadata.get('title', 'ì œëª© ì—†ìŒ')
                    formatted.append(f"[ë¬¸ì„œ {i} - {dept}ê³¼]\n{doc.page_content}\n")
                return "\n".join(formatted)
            
            rag_chain = (
                {"context": retriever | format_docs, "input": RunnablePassthrough()}
                | prompt
                | llm
                | StrOutputParser()
            )
            
            rag_components = {
                "chain": rag_chain,
                "retriever": retriever,
                "vectorstore": vectorstore,
                "llm": llm
            }
            
        except Exception as e:
            print(f"âš ï¸ ìµœì í™” ëª¨ë“œ ì‹¤íŒ¨: {e}")
            print("   ê¸°ë³¸ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            OPTIMIZATION_ENABLED = False
    
    if not OPTIMIZATION_ENABLED:
        # ê¸°ë³¸ ëª¨ë“œ: ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ì‹¤í–‰
        print("ğŸ“Š ê¸°ë³¸ ëª¨ë“œ: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        
        labeled_base_path = source_base_path.replace("01.ì›ì²œë°ì´í„°", "02.ë¼ë²¨ë§ë°ì´í„°")
        
        # ì›ì²œ ë°ì´í„° ë¡œë“œ (ìµœì í™”ëœ ì²­í¬ ì„¤ì • ìë™ ì ìš©)
        print("\n[1-1] ì›ì²œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        source_documents = load_multiple_departments(
            base_path=source_base_path,
            departments=["ë‚´ê³¼", "ì™¸ê³¼", "ì•ˆê³¼", "ì¹˜ê³¼", "í”¼ë¶€ê³¼"],
            data_type="source",
            chunk_size=None,  # Noneì´ë©´ ìµœì í™”ëœ 512 ì‚¬ìš©
            chunk_overlap=None,  # Noneì´ë©´ ìµœì í™”ëœ 80 ì‚¬ìš©
            remove_stopwords=True  # ë¶ˆìš©ì–´ ì œê±° í™œì„±í™”
        )
        
        # ë¼ë²¨ë§ ë°ì´í„° ë¡œë“œ
        print("\n[1-2] ë¼ë²¨ë§ ë°ì´í„° ë¡œë“œ ì¤‘...")
        labeled_documents = load_multiple_departments(
            base_path=labeled_base_path,
            departments=["ë‚´ê³¼", "ì™¸ê³¼", "ì•ˆê³¼", "ì¹˜ê³¼", "í”¼ë¶€ê³¼"],
            data_type="labeled",
            chunk_size=None,
            chunk_overlap=None,
            remove_stopwords=True
        )
        
        all_documents = source_documents + labeled_documents
        
        if not all_documents:
            print("âš ï¸ ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
        
        print(f"\nâœ“ ì›ì²œ ë°ì´í„°: {len(source_documents)}ê°œ ì²­í¬")
        print(f"âœ“ ë¼ë²¨ë§ ë°ì´í„°: {len(labeled_documents)}ê°œ ì²­í¬")
        print(f"âœ“ ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        
        # RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
        print("\n[2ë‹¨ê³„] RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì¤‘...")
        rag_components = setup_rag_pipeline(
            documents=all_documents,
            embedding_model="text-embedding-3-small",
            model_name="gpt-4o-mini",
            persist_directory=persist_dir,
            use_existing_vectorstore=False,
            k=4
        )
        
        print("âœ“ RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì™„ë£Œ")
    
    # ========================================================================
    # 2ë‹¨ê³„: RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (í‚¤ì›Œë“œ ì¶”ì¶œ ì ìš©)
    # ========================================================================
    print("\n[2ë‹¨ê³„] RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸...")
    
    test_query = "ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ í•˜ê³  í™©ë‹¬ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì§ˆí™˜ì¼ê¹Œìš”?"
    print(f"\ní…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_query}")
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ ì ìš© (ìµœì í™” ëª¨ë“œ)
    if OPTIMIZATION_ENABLED:
        from utils.optimization import extract_keywords_for_query
        from langchain_openai import ChatOpenAI
        
        llm_temp = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)
        optimized_query = extract_keywords_for_query(test_query, llm_temp)
        print(f"ğŸ”‘ ìµœì í™”ëœ ì¿¼ë¦¬: {optimized_query}")
        test_query_final = optimized_query
    else:
        test_query_final = test_query
    
    answer = query_rag(rag_components["chain"], test_query_final)
    print(f"\nRAG ë‹µë³€:\n{answer}")
    
    # ========================================================================
    # 3ë‹¨ê³„: LangGraph Agent ì‹¤í–‰ (ìµœì í™” ì›Œí¬í”Œë¡œìš°)
    # ========================================================================
    print("\n\n" + "="*80)
    print("[3ë‹¨ê³„] LangGraph Agent ì›Œí¬í”Œë¡œìš° ì‹¤í–‰")
    print("="*80)
    print("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ: í™œì„±í™”" if OPTIMIZATION_ENABLED else "")
    print("ğŸ” ì˜í•™ì  ê²€ìˆ˜: í™œì„±í™” (ìµœëŒ€ 2íšŒ ì¬ê²€í† )")
    print("ğŸ“ ìµœì í™”ëœ ì²­í¬: 512 í† í°")
    print("="*80)
    
    # Agent í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (ê¸°ëŒ€ ì‘ê¸‰ë„ í¬í•¨) - 10ê°œ
    agent_test_cases = [
        # ì‘ê¸‰ë„ ë†’ìŒ - ìƒëª… ìœ„í˜‘ ì¦ìƒ
        {
            "query": "ì €í¬ ê°•ì•„ì§€ê°€ ê°‘ìê¸° êµ¬í† ë¥¼ ì—¬ëŸ¬ ë²ˆ í•˜ê³  ë°°ê°€ ë¶€í’€ì–´ ì˜¬ëì–´ìš”. ë§¤ìš° ì•„íŒŒ ë³´ì…ë‹ˆë‹¤.",
            "expected_urgency": "ë†’ìŒ",
            "reason": "ìœ„ í™•ì¥/ë¹„í‹€ë¦¼ ì˜ì‹¬, ìƒëª… ìœ„í˜‘"
        },
        {
            "query": "ê°•ì•„ì§€ê°€ í˜¸í¡ì´ ê±°ì¹ ê³  ì…ìˆ ì´ íŒŒë˜ì¡Œì–´ìš”. ê³„ì† í—ë–¡ì´ê³  ìˆìŠµë‹ˆë‹¤.",
            "expected_urgency": "ë†’ìŒ",
            "reason": "ì²­ìƒ‰ì¦, í˜¸í¡ê³¤ë€, ì¦‰ê° ì¹˜ë£Œ í•„ìš”"
        },
        {
            "query": "ê°•ì•„ì§€ê°€ ë°œì‘ì„ ì¼ìœ¼í‚¤ê³  ì˜ì‹ì„ ìƒì—ˆì–´ìš”. 30ì´ˆ ì •ë„ ì§€ì†ëìŠµë‹ˆë‹¤.",
            "expected_urgency": "ë†’ìŒ",
            "reason": "ë°œì‘, ì‹ ê²½ê³„ ì‘ê¸‰ìƒí™©"
        },
        
        # ì‘ê¸‰ë„ ë³´í†µ - ë©°ì¹  ë‚´ ì§„ë£Œ í•„ìš”
        {
            "query": "ê³ ì–‘ì´ ëˆˆì´ ì•½ê°„ ì¶©í˜ˆë˜ì—ˆëŠ”ë° í‰ì†Œì™€ ë‹¤ë¥¼ ê²Œ ì—†ì–´ìš”.",
            "expected_urgency": "ë³´í†µ",
            "reason": "ê²½ë¯¸í•œ ì•ˆê³¼ ì¦ìƒ, 1-2ì¼ ë‚´ ì§„ë£Œ"
        },
        {
            "query": "ê°•ì•„ì§€ê°€ ì–´ì œë¶€í„° ê°€ë”ì”© ê¸°ì¹¨ì„ í•©ë‹ˆë‹¤. ì»¨ë””ì…˜ì€ ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”.",
            "expected_urgency": "ë³´í†µ",
            "reason": "í˜¸í¡ê¸° ì¦ìƒ, 2-3ì¼ ë‚´ ê²€ì§„ ê¶Œì¥"
        },
        {
            "query": "ë°˜ë ¤ê²¬ì´ ì˜¤ë¥¸ìª½ ê·€ë¥¼ ìì£¼ ê¸ê³  ë¨¸ë¦¬ë¥¼ í”ë“¤ì–´ìš”. ê·“ì†ì´ ì¢€ ë¶‰ì–´ ë³´ì…ë‹ˆë‹¤.",
            "expected_urgency": "ë³´í†µ",
            "reason": "ì™¸ì´ë„ì—¼ ì˜ì‹¬, ì¼ì£¼ì¼ ë‚´ ì§„ë£Œ"
        },
        {
            "query": "ê°•ì•„ì§€ ë°° ìª½ì— ë¶‰ì€ ë°˜ì ì´ ìƒê²¼ê³  ê°€ë ¤ì›Œí•˜ëŠ” ê²ƒ ê°™ì•„ìš”.",
            "expected_urgency": "ë³´í†µ",
            "reason": "í”¼ë¶€ ì—¼ì¦/ì•Œë ˆë¥´ê¸°, ì¼ì£¼ì¼ ë‚´ ì§„ë£Œ"
        },
        
        # ì‘ê¸‰ë„ ë‚®ìŒ - ê²½ë¯¸í•œ ì¦ìƒ
        {
            "query": "ê°•ì•„ì§€ ë°œí†±ì´ ë„ˆë¬´ ê¸¸ì–´ì§„ ê²ƒ ê°™ì€ë° ì–¸ì œ ë³‘ì› ê°€ì•¼ í• ê¹Œìš”?",
            "expected_urgency": "ë‚®ìŒ",
            "reason": "ì¼ìƒ ê´€ë¦¬, ë¹„ì‘ê¸‰"
        },
        {
            "query": "ê³ ì–‘ì´ê°€ í‰ì†Œë³´ë‹¤ ë¬¼ì„ ì¡°ê¸ˆ ë” ë§ì´ ë§ˆì‹œëŠ” ê²ƒ ê°™ì•„ìš”. ë‹¤ë¥¸ ì¦ìƒì€ ì—†ìŠµë‹ˆë‹¤.",
            "expected_urgency": "ë‚®ìŒ",
            "reason": "ê²½ë¯¸í•œ ë³€í™”, ê´€ì°° í›„ íŒë‹¨"
        },
        {
            "query": "ê°•ì•„ì§€ ì…ì—ì„œ ëƒ„ìƒˆê°€ ë‚˜ëŠ”ë° ë°¥ì€ ì˜ ë¨¹ì–´ìš”. ì¹˜ì„ì´ ì¢€ ìˆëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
            "expected_urgency": "ë³´í†µ",
            "reason": "ì¹˜ì„/ì¹˜ì£¼ì§ˆí™˜, ìŠ¤ì¼€ì¼ë§ í•„ìš”"
        },
    ]
    
    for i, test_case in enumerate(agent_test_cases, 1):
        query = test_case["query"]
        expected_urgency = test_case["expected_urgency"]
        reason = test_case["reason"]
        
        print(f"\n\n{'â”€'*80}")
        print(f"Agent í…ŒìŠ¤íŠ¸ {i}: {query}")
        print(f"ê¸°ëŒ€ ì‘ê¸‰ë„: {expected_urgency} ({reason})")
        print('â”€'*80)
        
        result = run_agent(
            user_query=query,
            config={"configurable": {"thread_id": f"test_{i}"}}
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "â”Œ" + "â”€"*78 + "â”")
        print("â”‚ ìµœì¢… ì‘ë‹µ" + " "*68 + "â”‚")
        print("â””" + "â”€"*78 + "â”˜")
        print(result.get("final_response", "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"))
        
        # íŒë‹¨ ê²°ê³¼ ë° ì •í™•ë„ í‘œì‹œ
        actual_urgency = result.get('urgency_level', 'N/A')
        is_correct = actual_urgency == expected_urgency
        correctness = "âœ… ì •ë‹µ" if is_correct else "âŒ ì˜¤ë‹µ"
        
        print("\n" + "â”Œ" + "â”€"*78 + "â”")
        print(f"â”‚ íŒë‹¨ ê²°ê³¼" + " "*66 + "â”‚")
        print("â””" + "â”€"*78 + "â”˜")
        print(f"ê¸°ëŒ€ ì‘ê¸‰ë„: {expected_urgency} | ì‹¤ì œ ì‘ê¸‰ë„: {actual_urgency} | {correctness}")
        print(f"ì¶”ì²œ ì§„ë£Œê³¼: {result.get('recommended_department', 'N/A')}")
        
        if result.get("hospital_list"):
            print(f"ì¶”ì²œ ë³‘ì› ìˆ˜: {len(result['hospital_list'])}ê°œ")
    
    # ========================================================================
    # ì™„ë£Œ
    # ========================================================================
    print("\n\n" + "="*80)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("="*80)
    
    if OPTIMIZATION_ENABLED:
        print("\nğŸš€ ì ìš©ëœ ìµœì í™”:")
        print("  âœ… ìºì‹± ì‹œìŠ¤í…œ (Vector DB + pkl)")
        print("  âœ… í‚¤ì›Œë“œ ì¶”ì¶œ (Query Re-writing)")
        print("  âœ… ë¶ˆìš©ì–´ ì œê±° (KoNLPy)")
        print("  âœ… ì²­í¬ ìµœì í™” (512 í† í°)")
        print("  âœ… ì˜í•™ì  ê²€ìˆ˜ (í”¼ë“œë°± ë£¨í”„)")
        print("  âœ… ìƒëŒ€ ê²½ë¡œ ê´€ë¦¬")
        print("\nğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ ì‹œ Vector DB ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ ~5ì´ˆ ë§Œì— ì‹œì‘ë©ë‹ˆë‹¤!")
    
    print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. ì¹´ì¹´ì˜¤ë§µ API ì—°ë™í•˜ì—¬ ì‹¤ì œ ë³‘ì› ê²€ìƒ‰ êµ¬í˜„")
    print("2. ì›¹ ì¸í„°í˜ì´ìŠ¤ ë˜ëŠ” ì±—ë´‡ UI ê°œë°œ (Streamlit/Gradio)")
    print("3. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° ëª¨ë¸ ê°œì„ ")
    print("4. ë©€í‹°í„´ ëŒ€í™” ê¸°ëŠ¥ ì¶”ê°€")


if __name__ == "__main__":
    main()
