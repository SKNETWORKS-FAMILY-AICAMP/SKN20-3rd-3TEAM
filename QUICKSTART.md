# ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸš€ ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •

### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±í•˜ê³  ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:

```bash
# OpenAI API ì„¤ì •
OPENAI_API_KEY=sk-...
LOG_LEVEL=INFO

# ì›¹ ê²€ìƒ‰ (ì„ íƒì‚¬í•­)
TAVILY_API_KEY=tvly-...

# ì¹´ì¹´ì˜¤ë§µ API (ì„ íƒì‚¬í•­)
KAKAO_MAP_API_KEY=...

# ë””ë²„ê·¸ ëª¨ë“œ (ì„ íƒì‚¬í•­)
DEBUG_MODE=False
```

### 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

---

## ğŸ“– ê¸°ë³¸ ì‚¬ìš©ë²•

### ë°©ë²• 1: ê°„ë‹¨í•œ í•œ ì¤„ ì‚¬ìš©

```python
from src import RAGOrchestrator, load_vectorstore, get_embedding_model

# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
embedding_model = get_embedding_model("openai")
vectorstore = load_vectorstore(embedding_model, persist_directory="./chroma_db")

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
orchestrator = RAGOrchestrator(vectorstore=vectorstore)

# ì§ˆë¬¸ ì²˜ë¦¬
result = orchestrator.process("ê°•ì•„ì§€ í”¼ë¶€ì—¼ì˜ ì¦ìƒì€?")
print(result['formatted_answer'])
```

### ë°©ë²• 2: ëŒ€í™”í˜• ëª¨ë“œ

```python
from src import RAGOrchestrator, load_vectorstore, get_embedding_model

embedding_model = get_embedding_model("openai")
vectorstore = load_vectorstore(embedding_model)
orchestrator = RAGOrchestrator(vectorstore=vectorstore)

# ëŒ€í™”í˜• ì‹œì‘
orchestrator.interactive_mode()
```

### ë°©ë²• 3: ë°°ì¹˜ ì²˜ë¦¬

```python
questions = [
    "ê°•ì•„ì§€ ì„¤ì‚¬ ì¦ìƒì€?",
    "ê°•ë‚¨ì—­ ê·¼ì²˜ ë™ë¬¼ë³‘ì›",
    "ë°˜ë ¤ê²¬ ì˜ì–‘ ê´€ë¦¬",
]

results = orchestrator.batch_process(questions)
orchestrator.save_results(results, output_path="results.json")
```

---

## ğŸ¥ ì§ˆë¬¸ ìœ í˜•ë³„ ì˜ˆì‹œ

### 1ï¸âƒ£ ì˜ë£Œ ì§ˆë¬¸ (Type A)
ìë™ìœ¼ë¡œ ë‚´ë¶€ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•˜ê³ , í•„ìš”ì‹œ ì›¹ ê²€ìƒ‰

```python
result = orchestrator.process("ê°•ì•„ì§€ ê·€ì—¼ì¦ ì›ì¸ê³¼ ì¹˜ë£Œë²•ì€?")
# ê²°ê³¼:
# - ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰
# - ê·¼ê±° ì ìˆ˜ í‰ê°€
# - LLM ê¸°ë°˜ ë‹µë³€ ìƒì„±
# - ì¶œì²˜ í‘œì‹œ
```

### 2ï¸âƒ£ ë³‘ì›/ì§€ë„ ì§ˆë¬¸ (Type B)
ìë™ìœ¼ë¡œ ë³‘ì› DBì—ì„œ ê²€ìƒ‰í•˜ê³  ì§€ë„ í‘œì‹œ

```python
result = orchestrator.process("ê°•ë‚¨ì—­ ê·¼ì²˜ ë™ë¬¼ë³‘ì› ì–´ë”” ìˆì–´?")
# ë˜ëŠ” ì¢Œí‘œ ê¸°ë°˜:
result = orchestrator.process(
    "ê·¼ì²˜ ë³‘ì›",
    latitude=37.4979,
    longitude=127.0276
)
# ê²°ê³¼:
# - ë³‘ì› ì •ë³´ ì¡°íšŒ
# - ê±°ë¦¬ ê¸°ë°˜ ì •ë ¬
# - ì¹´ì¹´ì˜¤ë§µ HTML ìƒì„±
```

### 3ï¸âƒ£ ì¼ë°˜ ì§ˆë¬¸ (Type C)
LLMì´ ì§ì ‘ ë‹µë³€

```python
result = orchestrator.process("ë°˜ë ¤ê²¬ í›ˆë ¨ íŒì„ ì•Œë ¤ì£¼ì„¸ìš”")
# ê²°ê³¼:
# - LLM ê¸°ë°˜ ì¼ë°˜ ë‹µë³€
# - ë‚´ë¶€ ê²€ìƒ‰ ì—†ìŒ
```

---

## ğŸ“Š ê²°ê³¼ ì´í•´í•˜ê¸°

### ê²°ê³¼ êµ¬ì¡°

```python
result = {
    'question': str,                    # ì›ë³¸ ì§ˆë¬¸
    'question_type': str,              # 'A', 'B', 'C'
    'timestamp': str,                  # ISO í˜•ì‹ ì‹œê°„
    'classification_confidence': float, # ë¶„ë¥˜ ì‹ ë¢°ë„
    'classification_type': str,        # 'MEDICAL', 'HOSPITAL', 'GENERAL'
    'classification_reason': str,      # ë¶„ë¥˜ ì´ìœ 
    'answer': str,                     # ë‹µë³€ (ì˜ë£Œ/ì¼ë°˜ìš©)
    'response': str,                   # ì‘ë‹µ (ë³‘ì›ìš©)
    'sources': list,                   # ì¶œì²˜ ì •ë³´
    'formatted_answer': str,           # í¬ë§·ëœ ìµœì¢… ë‹µë³€
    
    # ì˜ë£Œ ì§ˆë¬¸ ì „ìš©
    'internal_search_results': int,    # ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    'web_search_results': int,         # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    'relevance_score': float,          # ê·¼ê±° ì¶©ë¶„ë„ ì ìˆ˜
    'used_web_search': bool,           # ì›¹ ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€
    
    # ë³‘ì› ì§ˆë¬¸ ì „ìš©
    'hospitals': list,                 # ë³‘ì› ì •ë³´ ë¦¬ìŠ¤íŠ¸
}
```

### ì˜ë£Œ ì§ˆë¬¸ ê²°ê³¼ ì˜ˆì‹œ

```python
{
    'question': 'ê°•ì•„ì§€ í”¼ë¶€ì—¼ ì¦ìƒì€?',
    'question_type': 'A',
    'answer': 'ê°•ì•„ì§€ í”¼ë¶€ì—¼ì˜ ì¼ë°˜ì ì¸ ì¦ìƒì€...',
    'relevance_score': 0.85,
    'internal_search_results': 5,
    'web_search_results': 0,
    'used_web_search': False,
    'sources': [
        {
            'content': '...',
            'metadata': {
                'file_name': 'medical_01.json',
                'department': 'í”¼ë¶€ê³¼'
            },
            'relevance_score': 0.92
        }
    ],
    'formatted_answer': '...'
}
```

---

## ğŸ”§ ì£¼ìš” ì„¤ì • ì˜µì…˜

### RAGOrchestrator ì„¤ì •

```python
orchestrator = RAGOrchestrator(
    vectorstore=vectorstore,           # Chroma ë²¡í„°ìŠ¤í† ì–´
    hospital_json_path="...",         # ë³‘ì› JSON ê²½ë¡œ
    llm_model="gpt-4o-mini",          # LLM ëª¨ë¸
    score_threshold=0.6               # ì˜ë£Œ ì§ˆë¬¸ ì‹ ë¢°ë„ ì„ê³„ê°’
)
```

### ì„ë² ë”© ëª¨ë¸ ì„ íƒ

```python
# OpenAI ëª¨ë¸ (ê¸°ë³¸)
embedding = get_embedding_model("openai", model_name="text-embedding-3-small")

# HuggingFace ëª¨ë¸ (ë¡œì»¬)
embedding = get_embedding_model("huggingface", model_name="jhgan/ko-sroberta-multitask")
```

### ì „ì—­ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ

```python
from src.config import Settings, LLMConfig, RetrieverConfig

settings = Settings(
    llm=LLMConfig(model="gpt-4", temperature=0.5),
    retriever=RetrieverConfig(top_k=10, score_threshold=0.5)
)
```

---

## ğŸ¯ ì„±ëŠ¥ íŒ

### 1. ìºì‹± í™œìš©
```python
from src.llm import get_llm_client
llm = get_llm_client()  # ì²« í˜¸ì¶œ: ìƒì„±
llm = get_llm_client()  # ë‘ ë²ˆì§¸ í˜¸ì¶œ: ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
```python
# ë§ì€ ì§ˆë¬¸ì„ í•œ ë²ˆì— ì²˜ë¦¬
results = orchestrator.batch_process(
    questions,  # ë¦¬ìŠ¤íŠ¸
    **kwargs    # ê³µí†µ íŒŒë¼ë¯¸í„°
)
```

### 3. ì»¤ìŠ¤í…€ ê²€ìƒ‰ ì˜µì…˜
```python
result = orchestrator.process(
    query,
    latitude=37.49,        # ë³‘ì› ê²€ìƒ‰ìš©
    longitude=127.02,
)
```

---

## ğŸ“ ë°ì´í„° ì¤€ë¹„

### ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì²˜ìŒ í•œ ë²ˆ)

```python
from src import ingest_data, chunk_documents_with_token_range
from src import get_embedding_model, create_vectorstore

# ë°ì´í„° ë¡œë“œ ë° ì²­í‚¹
documents = ingest_data("data/raw")
chunked_docs = chunk_documents_with_token_range(documents)

# ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
embedding_model = get_embedding_model("openai")
vectorstore = create_vectorstore(
    documents=chunked_docs,
    embedding_model=embedding_model,
    persist_directory="./chroma_db"
)
```

### ë³‘ì› ë°ì´í„° ì„¤ì •

ë³‘ì› JSON íŒŒì¼ì„ ë‹¤ìŒ ê²½ë¡œì— ë°°ì¹˜í•˜ì„¸ìš”:
```
data/raw/hospital/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›_ì¸í—ˆê°€_ì •ë³´.json
```

ë˜ëŠ” ì§ì ‘ ì§€ì •:
```python
orchestrator = RAGOrchestrator(
    vectorstore=vectorstore,
    hospital_json_path="/path/to/hospital.json"
)
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### OpenAI API ì—ëŸ¬
```
ValueError: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤
```
**í•´ê²°**: `.env` íŒŒì¼ì— `OPENAI_API_KEY` ì¶”ê°€

### ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨
```
FileNotFoundError: chroma_db not found
```
**í•´ê²°**: ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í›„ ì‚¬ìš© (ìœ„ "ë°ì´í„° ì¤€ë¹„" ì°¸ê³ )

### ë³‘ì› ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨
```
ë³‘ì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 0ê°œ ë³‘ì›
```
**í•´ê²°**: ë³‘ì› JSON íŒŒì¼ ê²½ë¡œ í™•ì¸

### ì›¹ ê²€ìƒ‰ ë¯¸ì‘ë™
```
Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤
```
**í•´ê²°**: `.env`ì— `TAVILY_API_KEY` ì¶”ê°€ (ì„ íƒì‚¬í•­)

---

## ğŸ“š ë” ì½ì„ ê±°ë¦¬

- [ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](./ARCHITECTURE.md) - ì „ì²´ ì‹œìŠ¤í…œ ì„¤ê³„
- [ëª¨ë“ˆ ë¬¸ì„œ](#) - ê° ëª¨ë“ˆ ìƒì„¸ ì„¤ëª… (ì‘ì„± ì˜ˆì •)
- [API ë ˆí¼ëŸ°ìŠ¤](#) - í•¨ìˆ˜/í´ë˜ìŠ¤ ìƒì„¸ ë¬¸ì„œ (ì‘ì„± ì˜ˆì •)

---

## ğŸ’¬ ì˜ˆì œ ì½”ë“œ

### ì˜ˆì œ 1: ì˜ë£Œ ìƒë‹´

```python
from src import RAGOrchestrator, load_vectorstore, get_embedding_model

def medical_consultation():
    # ì´ˆê¸°í™”
    embedding_model = get_embedding_model("openai")
    vectorstore = load_vectorstore(embedding_model)
    orchestrator = RAGOrchestrator(vectorstore=vectorstore)
    
    # ìƒë‹´ ì§ˆë¬¸ë“¤
    questions = [
        "ê°•ì•„ì§€ê°€ ê³„ì† ë¬¼ë¦°ë‹¤ê³  ê¸ì–´ìš”. ì–´ë–»ê²Œ ë˜ëŠ” ê±¸ê¹Œìš”?",
        "í”¼ë¶€ì—¼ ì§„ë‹¨ë°›ì€ í›„ ì–´ë–¤ ì•½ì„ ì“°ë‚˜ìš”?",
        "ì¹˜ë£Œ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?"
    ]
    
    for q in questions:
        result = orchestrator.process(q)
        print(f"\nì§ˆë¬¸: {q}")
        print(f"ë‹µë³€: {result['formatted_answer']}")
        print(f"ì‹ ë¢°ë„: {result.get('relevance_score', 'N/A')}")

medical_consultation()
```

### ì˜ˆì œ 2: ë³‘ì› ê²€ìƒ‰

```python
def find_hospitals():
    orchestrator = RAGOrchestrator(vectorstore=vectorstore)
    
    result = orchestrator.process(
        "ê°•ë‚¨êµ¬ ì—­ì‚¼ë™ ê·¼ì²˜ ë™ë¬¼ë³‘ì›",
        location="ê°•ë‚¨êµ¬"
    )
    
    print(f"ê²€ìƒ‰ ê²°ê³¼: {result['response']}")
    for hospital in result['hospitals'][:3]:
        print(f"- {hospital['name']}: {hospital['phone']}")

find_hospitals()
```

---

**ë‹¤ìŒ ë‹¨ê³„**: ì•„í‚¤í…ì²˜ ê°€ì´ë“œë¥¼ ì½ê³  ê° ëª¨ë“ˆì˜ ì—­í• ì„ ì´í•´í•´ë³´ì„¸ìš”!

