# 시스템 아키텍처 상세 설명

## 전체 시스템 플로우

```
┌─────────────────────────────────────────────────────────────────┐
│                        사용자 질문 입력                          │
└──────────────────────────┬──────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│                  1️⃣ 질문 분류 단계 (Type 판정)                 │
│                   (QuestionClassifier)                           │
│                                                                   │
│  입력 → 키워드 기반 필터링 → LLM 검증 → 유형 + 신뢰도 반환     │
└──────────────────────────┬──────────────────────────────────────┘
                           │
           ┌───────────────┼───────────────┐
           │               │               │
           ▼               ▼               ▼
    ┌──────────────┐ ┌──────────────┐ ┌──────────────┐
    │   Type A     │ │   Type B     │ │   Type C     │
    │   의료 질문  │ │  병원 질문   │ │  일반 질문   │
    └──────────────┘ └──────────────┘ └──────────────┘
           │               │               │
           └───────────────┼───────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│              2️⃣ 유형별 처리 (AdvancedRAGPipeline)              │
└─────────────────────────────────────────────────────────────────┘
```

---

## Type A: 의료 질문 처리 상세 플로우

```
의료 질문
  │
  ▼
┌─────────────────────────────────────────────────────────────────┐
│       Step 1: 내부 문서 검색 (MedicalQAHandler)                │
│                                                                   │
│  Query → Chroma Vectorstore Similarity Search (top-k=5)         │
│           ↓                                                       │
│       [Doc1: distance=0.15, score=0.85]                         │
│       [Doc2: distance=0.25, score=0.75]                         │
│       [Doc3: distance=0.35, score=0.65]                         │
│       [Doc4: distance=0.45, score=0.55]                         │
│       [Doc5: distance=0.55, score=0.45]                         │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────────┐
│     Step 2: 근거 관련성 평가 (_evaluate_relevance)             │
│                                                                   │
│  각 문서를 LLM으로 세부 평가:                                    │
│   - 질문에 대한 직접적 답변 제공도                               │
│   - 정보의 신뢰도 및 정확성                                      │
│   - 현재성 및 적용 가능성                                        │
│                                                                   │
│  평가 결과:                                                       │
│   Doc1: 0.95 (높음 - 직접 관련)                                 │
│   Doc2: 0.80 (중상 - 부분 관련)                                 │
│   Doc3: 0.65 (중 - 관련)                                        │
│   Doc4: 0.45 (낮음)                                             │
│   Doc5: 0.30 (매우 낮음)                                        │
│                                                                   │
│  평균 점수: (0.95+0.80+0.65+0.45+0.30)/5 = 0.63               │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
         ┌─────────────────────┐
         │  Score ≥ 0.60?      │
         │ (threshold)         │
         └─────────────────────┘
                   │
        ┌──────────┴──────────┐
        │                     │
       YES                    NO
        │                     │
        ▼                     ▼
    ┌─────────────┐    ┌──────────────────────┐
    │ 내부 데이터 │    │ Step 3: 웹 검색      │
    │ 충분        │    │ (_web_search)        │
    │ ✓ 사용      │    │ Tavily API 호출     │
    └────┬────────┘    │ ↓                    │
         │             │ [Web Result 1]     │
         │             │ [Web Result 2]     │
         │             │ [Web Result 3]     │
         │             └──────────┬──────────┘
         │                        │
         └────────────┬───────────┘
                      │
                      ▼
         ┌──────────────────────────┐
         │ Step 4: RAG 답변 생성    │
         │ (_generate_answer_with_rag)
         │                          │
         │ 상위 3개 문서 선택 +    │
         │ 컨텍스트 구성 +         │
         │ LLM으로 답변 생성       │
         └──────────────┬───────────┘
                        │
                        ▼
         ┌──────────────────────────┐
         │ 최종 답변 + 출처 + 점수  │
         │ 반환                     │
         └──────────────────────────┘
```

### Type A 반환 구조

```python
{
    'question': str,                    # 원본 질문
    'question_type': 'A',               # 질문 유형
    'timestamp': str,                   # ISO8601 타임스탐프
    'internal_search_results': int,     # 내부 검색 결과 수
    'web_search_results': int,          # 웹 검색 결과 수
    'relevance_score': float,           # 0.0-1.0, 평균 근거 점수
    'used_web_search': bool,            # 웹 검색 사용 여부
    'answer': str,                      # 생성된 답변
    'sources': [
        {
            'content': str,             # 문서 내용
            'metadata': {
                'file_name': str,       # 소스 파일명
                'department': str,      # 부서 (피부과, 내과 등)
                'title': str,           # 문서 제목
                ...
            },
            'relevance_score': float,   # 0.0-1.0
            'distance': float           # 벡터 거리
        },
        ...
    ]
}
```

---

## Type B: 병원 질문 처리 상세 플로우

```
병원 질문 (예: "강남구 동물병원")
  │
  ▼
┌─────────────────────────────────────────────────────────────────┐
│         Step 1: 질문 분석 (Query Understanding)               │
│                                                                   │
│  정규표현식으로 지역명/병원명 추출:                             │
│  - '강남구' 매칭                                                 │
│  - '동물병원' 키워드 인식                                        │
│  → 결정: 위치 기반 검색                                         │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────────┐
│      Step 2: CSV 데이터 필터링 (HospitalHandler)              │
│                                                                   │
│  Pandas DataFrame 에서:                                         │
│  - 주소 컬럼 필터링: like '강남구'                              │
│  - 상태 필터링: '정상'                                          │
│  - 결과: 87개 병원                                              │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────────┐
│        Step 3: 정보 추출 및 포맷팅                            │
│                                                                   │
│  각 병원에서 추출:                                              │
│  - 사업장명 (병원명)                                            │
│  - 주소                                                          │
│  - 전화번호                                                      │
│  - 허가상태                                                      │
│  - 영업형태                                                      │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────────┐
│      Step 4: 응답 생성 및 통계 (선택사항)                     │
│                                                                   │
│  - 병원 목록 표시 (상위 10개)                                   │
│  - 구별 병원 수 통계                                            │
│  - 지역 정보                                                      │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
         ┌──────────────────────────┐
         │ 최종 응답 반환           │
         │ (병원 목록 + 통계)       │
         └──────────────────────────┘
```

### Type B 반환 구조

```python
{
    'question': str,                    # 원본 질문
    'question_type': 'B',               # 질문 유형
    'timestamp': str,                   # ISO8601 타임스탐프
    'hospitals': [
        {
            'name': str,                # 병원명
            'address': str,             # 주소
            'phone': str,               # 전화번호
            'district': str,            # 구명
            'status': str,              # 허가상태
            'business_type': str,       # 영업형태
            'original_data': dict       # 원본 CSV 행
        },
        ...
    ],
    'statistics': {
        'total_hospitals': int,         # 총 병원 수
        'districts': dict,              # 구별 병원 수
        'top_districts': list           # 상위 구 정보
    },
    'response': str                     # 포맷된 응답 문자열
}
```

---

## Type C: 일반 질문 처리 플로우

```
일반 질문
  │
  ▼
┌─────────────────────────────────────────────────────────────────┐
│              LLM 직접 호출 (ChatOpenAI)                         │
│                                                                   │
│  Prompt:                                                         │
│  "당신은 반려동물 전문 QA 어시스턴트입니다.                    │
│   다음 질문에 대해 정확하고 도움이 되는 답변을 제공하세요.     │
│   ...                                                             │
│  Question: [사용자 질문]"                                       │
│                                                                   │
│  Temperature: 0.0 (일관성 있는 답변)                           │
└──────────────────┬─────────────────────────────────────────────┘
                   │
                   ▼
         ┌──────────────────────────┐
         │ LLM 응답 생성            │
         │ (외부 검증 없음)         │
         └──────────────┬───────────┘
                        │
                        ▼
         ┌──────────────────────────┐
         │ 답변 반환                │
         └──────────────────────────┘
```

### Type C 반환 구조

```python
{
    'question': str,                    # 원본 질문
    'question_type': 'C',               # 질문 유형
    'timestamp': str,                   # ISO8601 타임스탐프
    'answer': str,                      # LLM 생성 답변
    'sources': [],                      # 빈 리스트 (외부 검증 없음)
    'used_external_search': False       # 항상 False
}
```

---

## 데이터 구조 및 흐름

### 1. 입력 데이터

```
data/raw/
├── disease/
│   ├── disease_001.json     # 질병 정보 (JSON)
│   ├── disease_002.json
│   └── ... (약 215개 파일)
│
└── hospital/
    └── 서울시_동물병원_인허가_정보.csv  # 병원 정보 (CSV)
        Columns: 사업장명, 소재지, 전화번호, 허가상태, 영업형태, ...
```

### 2. 처리 과정

```
JSON 파일 로드
  ↓
텍스트 추출 (extract_text_from_json)
  ↓
LangChain Document 변환
  ↓
Token 기반 문서 분할 (chunking)
  ↓
OpenAI Embedding 생성
  ↓
Chroma 벡터스토어 저장
  ↓
검색시 유사도 계산 및 반환
```

### 3. 메타데이터 추적

```python
Document Metadata:
{
    'source_path': 'data/raw/disease/disease_001.json',
    'file_name': 'disease_001.json',
    'department': '피부과',
    'title': '알러지성 피부염',
    'author': 'veterinarian_name',
}
```

---

## 신뢰도 점수 계산 로직

### Type A: 근거 점수 계산

```
Step 1: 초기 유사도 점수 (Chroma)
  distance (0-1) → relevance_score = 1 - distance
  예) distance=0.25 → relevance_score=0.75

Step 2: LLM 재평가
  3가지 기준으로 평가:
  - 직접성 (Directness): 질문에 직접 답변 제공도
  - 신뢰도 (Credibility): 정보 신뢰도
  - 현재성 (Applicability): 현재 상황 적용도
  
  각 기준: 0.0-1.0 범위 점수
  최종 점수 = (직접성 × 0.4 + 신뢰도 × 0.4 + 현재성 × 0.2)

Step 3: 평균 계산
  final_score = avg(doc1_score, doc2_score, ..., doc_n_score)

Step 4: Threshold 비교
  if final_score >= 0.6:
    → 내부 데이터 사용
  else:
    → 웹 검색 추가 수행
```

### Type B: 검색 정확도

```
위치 검색 정확도:
- 정확 매칭: 100%
- 부분 매칭: 99%

병원명 검색 정확도:
- 정확 매칭: 100%
- 부분 매칭: 95% (유사도 기반)
```

---

## 벡터 임베딩 파이프라인

```
┌─────────────────────────────────────────────────────────────────┐
│  원본 문서 → 텍스트 정규화 → Tokenization → Embedding        │
└─────────────────────────────────────────────────────────────────┘
                                              │
                                              ▼
                                    ┌──────────────────┐
                                    │ OpenAI API       │
                                    │ text-embedding-  │
                                    │ 3-small          │
                                    │ (1536-dim vector)│
                                    └────────┬─────────┘
                                             │
                                             ▼
                                    ┌──────────────────┐
                                    │ Chroma Vector DB │
                                    │ (SQLite backend) │
                                    └────────┬─────────┘
                                             │
                                             ▼
                        ┌────────────────────────────────────┐
                        │ 검색시: Query Embedding 생성       │
                        │ → Cosine 유사도 계산              │
                        │ → Top-K 결과 반환                 │
                        └────────────────────────────────────┘
```

---

## 에러 처리 및 Fallback 메커니즘

```
Type A (의료):
  ├─ 내부 검색 실패 → 빈 리스트 반환 → 웹 검색 자동 진행
  ├─ 평가 점수 < Threshold → 웹 검색 추가
  ├─ 웹 검색 실패 → 내부 데이터만으로 답변 생성
  └─ 모든 소스 부족 → 일반 LLM 모드 폴백

Type B (병원):
  ├─ CSV 로드 실패 → 빈 결과 반환
  ├─ 검색 결과 없음 → 통계 정보 제공
  └─ 데이터 부족 → 사용자에게 알림

Type C (일반):
  ├─ LLM 호출 실패 → 에러 메시지 반환
  └─ 타임아웃 → 재시도 또는 에러 반환
```

---

## 성능 고려사항

### 시간 복잡도

```
Type A (의료):
- 벡터 검색: O(log n) ~ O(n) (HNSW 인덱스)
- 근거 평가: O(k) (k=5 문서 수)
- LLM 호출: 2-3회
- 전체: ~5-10초

Type B (병원):
- DataFrame 필터링: O(n) (n=5000+ 병원)
- 정렬: O(n log n)
- 전체: ~1-2초

Type C (일반):
- LLM 호출: 1회
- 전체: ~2-5초
```

### 메모리 사용

```
Chroma Vector DB: ~500MB
CSV 데이터 (Pandas): ~50MB
LLM 토큰 버퍼: ~10MB
총: ~600MB
```

---

## 확장성 및 업그레이드 경로

### 1. 모델 업그레이드
```python
# 현재
embedding_model = "text-embedding-3-small"
llm_model = "gpt-4o-mini"

# 업그레이드
embedding_model = "text-embedding-3-large"  # 더 나은 성능
llm_model = "gpt-4"  # 더 강력한 모델
```

### 2. 데이터 확장
```
- 질병 정보: 215 → 1000+ 추가
- 병원 정보: 5,287 → 전국 확장
- 다국어 지원: 영어, 일본어 등
```

### 3. 기능 확장
```
- 멀티턴 대화
- 개인화된 학습
- 실시간 데이터 업데이트
- 지도 시각화 (Kakao Maps)
```

---

**마지막 업데이트**: 2025년 12월 3일

