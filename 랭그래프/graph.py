"""
LangGraph ê·¸ë˜í”„ ì •ì˜ - ì „ì²´ ëŒ€í™” í”Œë¡œìš° (ì›¹ê²€ìƒ‰ + ì˜ë„ë¶„ë¥˜ + í‰ê°€ í¬í•¨)
"""
from typing import TypedDict, List, Dict, Optional
from langgraph.graph import StateGraph, END
from app.rag_chain import rag_chain
from app.maps_client import search_nearby_hospitals
from app.web_search import web_search_client
from app.config import settings


# ìƒíƒœ ì •ì˜
class ChatState(TypedDict):
    """ëŒ€í™” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” TypedDict"""
    question: str                    # ì‚¬ìš©ì ì§ˆë¬¸
    location: Optional[str]          # ìœ„ì¹˜ ì •ë³´ (ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬")
    latitude: Optional[float]        # ìœ„ë„ ì¢Œí‘œ
    longitude: Optional[float]       # ê²½ë„ ì¢Œí‘œ
    radius: Optional[int]           # ë™ë¬¼ë³‘ì› ê²€ìƒ‰ ë°˜ê²½ (ë¯¸í„°)
    intent: str                     # ì§ˆë¬¸ ì˜ë„ (medical_consultation/hospital_search/general)
    retrieved_docs: List[Dict]      # RAG ê²€ìƒ‰ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    relevance_score: float          # ì§ˆë¬¸ê³¼ ê° ë¬¸ì„œì˜ ê´€ë ¨ë„ ì ìˆ˜ (0-1)
    needs_web_search: bool          # ì›¹ê²€ìƒ‰ í•„ìš” ì—¬ë¶€
    web_search_results: List[Dict]  # Tavily ì›¹ê²€ìƒ‰ ê²°ê³¼
    rag_response: str               # LLMì´ ìƒì„±í•œ RAG ê¸°ë°˜ ì‘ë‹µ
    quality_check: str              # ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ê²°ê³¼ (pass/fail)
    feedback: str                   # í’ˆì§ˆ í‰ê°€ í”¼ë“œë°± ë©”ì‹œì§€
    hospitals: List[Dict]           # ê·¼ì²˜ ë™ë¬¼ë³‘ì› ì •ë³´ ë¦¬ìŠ¤íŠ¸ (APIìš©)
    hospital_text: str              # ë³‘ì› ì •ë³´ í…ìŠ¤íŠ¸ (ì¶œë ¥ìš©)
    final_response: str             # ìµœì¢… í†µí•© ì‘ë‹µ (RAG + ì›¹ê²€ìƒ‰ + ë³‘ì›ì •ë³´)


def preprocess_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ A: ì…ë ¥ ì „ì²˜ë¦¬"""
    print("[ë…¸ë“œ A] ì…ë ¥ ì „ì²˜ë¦¬ ì¤‘...")
    
    question = state["question"].strip()
    
    if "location" not in state:
        state["location"] = None
    if "latitude" not in state:
        state["latitude"] = None
    if "longitude" not in state:
        state["longitude"] = None
    if "radius" not in state:
        state["radius"] = 3000
    
    state["question"] = question
    state["intent"] = "medical_consultation"
    state["needs_web_search"] = False
    state["web_search_results"] = []
    state["relevance_score"] = 0.0
    state["quality_check"] = "pass"
    state["feedback"] = ""
    state["hospital_text"] = ""  # ğŸ”§ ì¶”ê°€
    
    return state


def intent_classifier_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ A2: ì˜ë„ ë¶„ë¥˜
    í˜„ì¬ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ë°©ì‹ì„
    (íŠ¹ì • í‚¤ì›Œë“œê°€ ë“¤ì–´ê°€ë©´ íŠ¹ì • ë…¸ë“œë¡œ ë¶„ë¥˜)

    ì´ê±¸ 
    1ì°¨- í‚¤ì›Œë“œë¡œ ë¹ ë¥¸ ë¶„ë¥˜, 2ì°¨-llmì´ ë¶„ë¥˜í•´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ìˆ˜ì • (-> ê³ ë„í™” ì‘ì—…ì—ì„œ ã„±ã„±)
    
    
    """
    print("[ë…¸ë“œ A2] ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ ì¤‘...")
    
    question = state["question"].lower()
    
    hospital_keywords = ["ë³‘ì›", "ë™ë¬¼ë³‘ì›", "ìˆ˜ì˜ì‚¬", "ì–´ë””", "ìœ„ì¹˜", "ì°¾ì•„", "ì¶”ì²œ"]
    medical_keywords = ["ì¦ìƒ", "ì•„íŒŒ", "ê¸°ì¹¨", "ì„¤ì‚¬", "êµ¬í† ", "ì ˆëš", "í”¼", "ì—´", "ë¬´ê¸°ë ¥", "ë‹¤ë¦¬", "ëˆˆ", "ê·€"]
    
    if any(keyword in question for keyword in hospital_keywords):
        if not any(keyword in question for keyword in medical_keywords):
            state["intent"] = "hospital_search"
            print("  â†’ ì˜ë„: ë³‘ì› ì°¾ê¸°")
            return state
    
    if any(keyword in question for keyword in medical_keywords):
        state["intent"] = "medical_consultation"
        print("  â†’ ì˜ë„: ì˜ë£Œ ìƒë‹´")
        return state
    
    state["intent"] = "general"
    print("  â†’ ì˜ë„: ì¼ë°˜ ì§ˆë¬¸")
    return state



def retrieve_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ B: RAG ê²€ìƒ‰"""
    print("[ë…¸ë“œ B] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
    
    question = state["question"]
    documents = rag_chain.retrieve(question)
    
    state["retrieved_docs"] = [
        {
            "content": doc.page_content,
            "disease": doc.metadata.get("disease", "Unknown"),
            "symptom": doc.metadata.get("symptom", "Unknown")
        }
        for doc in documents
    ]
    
    # ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œë¡œ ì´ë™
    return grade_documents_node(state)


def grade_documents_node(state: ChatState) -> ChatState:
    """
    ë¬¸ì„œê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ
    => ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„± ì—¬ë¶€ë¥¼ llm í‰ê°€ / ê´€ë ¨ì—†ìœ¼ë©´ ì›¹ ê²€ìƒ‰ í”Œë˜ê·¸ë¥¼ í™œì„±
    """
    print("[ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€] ì‹œì‘...")
    
    question = state["question"]
    retrieved_docs = state["retrieved_docs"]
    filtered_docs = []
    grade_results = []
    
    if not retrieved_docs:
        state["needs_web_search"] = True
        print("  â†’ ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ â†’ ì›¹ ê²€ìƒ‰ í•„ìš”!")
        return state
    
    # LLMì„ ì‚¬ìš©í•œ ê´€ë ¨ë„ í‰ê°€
    from langchain_openai import ChatOpenAI
    from langchain.schema import HumanMessage
    
    try:
        llm = ChatOpenAI(model=settings.OPENAI_MODEL, temperature=0)
        
        for i, doc_dict in enumerate(retrieved_docs, 1):
            doc_content = doc_dict["content"][:500]  # ê¸¸ì´ ì œí•œ
            
            relevance_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì„œë¡œ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ê²€ìƒ‰ëœ ë¬¸ì„œ:
"{doc_content}"

ì§ˆë¬¸ì´ ê°•ì•„ì§€ ì¦ìƒì— ê´€í•œ ê²ƒì´ê³ , ë¬¸ì„œê°€ í•´ë‹¹ ì¦ìƒì´ë‚˜ ì§ˆë³‘ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤ë©´ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤.

"yes" ë˜ëŠ” "no"ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
"""
            
            response = llm.invoke([HumanMessage(content=relevance_prompt)])
            result_text = response.content.strip().lower()
            
            if "yes" in result_text:
                filtered_docs.append(doc_dict)
                grade_results.append("relevant")
                print(f"  â†’ ë¬¸ì„œ {i}: ê´€ë ¨ìˆìŒ")
            elif "no" in result_text:
                grade_results.append("not_relevant")
                print(f"  â†’ ë¬¸ì„œ {i}: ê´€ë ¨ì—†ìŒ")
            else:
                # ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µì‹œ í‚¤ì›Œë“œ ë°©ì‹ìœ¼ë¡œ fallback
                doc_lower = doc_content.lower()
                question_lower = question.lower()
                keywords = ["ì¦ìƒ", "ì§ˆë³‘", "ê°•ì•„ì§€", "ê°œ", "ìˆ˜ì˜", "ë³‘ì›", "ì¹˜ë£Œ"]
                matches = sum(1 for kw in keywords if kw in doc_lower and kw in question_lower)
                
                if matches >= 2:
                    filtered_docs.append(doc_dict)
                    grade_results.append("relevant")
                    print(f"  â†’ ë¬¸ì„œ {i}: LLM ì‘ë‹µ ì‹¤íŒ¨, í‚¤ì›Œë“œë¡œ ê´€ë ¨ìˆìŒ íŒì •")
                else:
                    grade_results.append("not_relevant")
                    print(f"  â†’ ë¬¸ì„œ {i}: LLM ì‘ë‹µ ì‹¤íŒ¨, í‚¤ì›Œë“œë¡œ ê´€ë ¨ì—†ìŒ íŒì •")

                    
    except Exception as e:
        print(f"  â†’ LLM ê´€ë ¨ë„ í‰ê°€ ì‹¤íŒ¨: {e}, í‚¤ì›Œë“œ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´")
        # LLM í˜¸ì¶œ ì‹¤íŒ¨ì‹œ ê¸°ì¡´ í‚¤ì›Œë“œ ë°©ì‹ìœ¼ë¡œ fallback
        for i, doc_dict in enumerate(retrieved_docs, 1):
            doc_lower = doc_dict["content"].lower()
            question_lower = question.lower()
            keywords = ["ì¦ìƒ", "ì§ˆë³‘", "ê°•ì•„ì§€", "ê°œ", "ìˆ˜ì˜", "ë³‘ì›", "ì¹˜ë£Œ"]
            matches = sum(1 for kw in keywords if kw in doc_lower and kw in question_lower)
            
            if matches >= 2:
                filtered_docs.append(doc_dict)
                grade_results.append("relevant")
            else:
                grade_results.append("not_relevant")
    

    # ê´€ë ¨ ë¬¸ì„œê°€ 3ê°œ ë¯¸ë§Œì´ë©´ ì›¹ ê²€ìƒ‰ í•„ìš”
    if len(filtered_docs) < 3:
        state["needs_web_search"] = True
        print(f"  â†’ ê´€ë ¨ ë¬¸ì„œ {len(filtered_docs)}ê°œ (3ê°œ ë¯¸ë§Œ) â†’ ì›¹ ê²€ìƒ‰ í•„ìš”!")
    else:
        state["needs_web_search"] = False
        print(f"  â†’ {len(filtered_docs)}ê°œ ê´€ë ¨ ë¬¸ì„œ í™•ë³´! (3ê°œ ì´ìƒ)")
    
    # í•„í„°ë§ëœ ë¬¸ì„œë¡œ ì—…ë°ì´íŠ¸
    state["retrieved_docs"] = filtered_docs
    
    return state


def web_search_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ C: ì›¹ê²€ìƒ‰ (ì¡°ê±´ë¶€)"""
    if not state.get("needs_web_search", False):
        print("[ë…¸ë“œ C] ì›¹ê²€ìƒ‰ ê±´ë„ˆëœ€ (RAG ê²°ê³¼ ì¶©ë¶„)")
        return state
    
    print("[ë…¸ë“œ C] ì›¹ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
    
    question = state["question"]
    
    try:
        search_results = web_search_client.search_korean(question, max_results=3)
        state["web_search_results"] = search_results
        print(f"  â†’ {len(search_results)}ê°œ ì›¹ê²€ìƒ‰ ê²°ê³¼ ë°œê²¬")
    except Exception as e:
        print(f"  â†’ ì›¹ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” íƒ€ì„ì•„ì›ƒ: {e}")
        state["web_search_results"] = []
    
    return state


def generate_response_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ D: LLM ì‘ë‹µ ìƒì„±"""
    print("[ë…¸ë“œ D] LLM ë‹µë³€ ìƒì„± ì¤‘...")
    
    question = state["question"]
    
    from langchain.schema import Document
    documents = [
        Document(
            page_content=doc["content"],
            metadata={"disease": doc["disease"], "symptom": doc["symptom"]}
        )
        for doc in state["retrieved_docs"]
    ]
    
    if state.get("web_search_results"):
        for web_result in state["web_search_results"]:
            web_doc = Document(
                page_content=f"[ì›¹ê²€ìƒ‰ ê²°ê³¼]\nì œëª©: {web_result['title']}\në‚´ìš©: {web_result['content']}",
                metadata={"source": "web_search", "url": web_result.get('url', '')}
            )
            documents.append(web_doc)
        print("  â†’ ì›¹ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
    
    try:
        response = rag_chain.generate_response(question, documents)
        state["rag_response"] = response
        print("  â†’ ë‹µë³€ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"  â†’ LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        
        fallback_response = f"""
[ë°ì´í„°ë² ì´ìŠ¤ì— ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤]

ì§ˆë¬¸í•˜ì‹  ì¦ìƒ "{question}"ì— ëŒ€í•´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ê°•ì•„ì§€ì˜ ë¹„ì •ìƒì ì¸ í–‰ë™ì€ ë‹¤ìŒê³¼ ê°™ì€ ì›ì¸ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**1. í¥ë¶„ ë˜ëŠ” ë†€ì´ í–‰ë™**
- ê°•ì•„ì§€ê°€ ê¸°ë¶„ì´ ì¢‹ê±°ë‚˜ í¥ë¶„í–ˆì„ ë•Œ í‰ì†Œì™€ ë‹¤ë¥¸ í–‰ë™ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**2. ì£¼ì˜ë¥¼ ëŒê¸° ìœ„í•œ í–‰ë™**
- ë³´í˜¸ìì˜ ê´€ì‹¬ì„ ë°›ê³  ì‹¶ì„ ë•Œ íŠ¹ì´í•œ í–‰ë™ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**3. ì‹ ì²´ì  ë¶ˆí¸í•¨**
- íŠ¹ì • ë¶€ìœ„ì— ë¶ˆí¸í•¨ì´ë‚˜ ê°€ë²¼ìš´ í†µì¦ì´ ìˆì„ ë•Œ ì´ìƒ í–‰ë™ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

âš ï¸ **ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° ì¦‰ì‹œ ë™ë¬¼ë³‘ì›ì„ ë°©ë¬¸í•˜ì„¸ìš”:**
- í–‰ë™ì´ ê³„ì† ë°˜ë³µë˜ê±°ë‚˜ ë¹ˆë„ê°€ ì¦ê°€í•˜ëŠ” ê²½ìš°
- ë‹¤ë¥¸ ì¦ìƒ(êµ¬í† , ì„¤ì‚¬, ì‹ìš• ì €í•˜, ë¬´ê¸°ë ¥)ì´ ë™ë°˜ë˜ëŠ” ê²½ìš°
- í‰ì†Œì™€ í™•ì—°íˆ ë‹¤ë¥¸ ë¹„ì •ìƒì ì¸ í–‰ë™ì´ ì§€ì†ë˜ëŠ” ê²½ìš°

ğŸ’¡ **ê¶Œì¥ì‚¬í•­:**
ì•„ë˜ ì¶”ì²œ ë™ë¬¼ë³‘ì›ì— ë¬¸ì˜í•˜ì—¬ ìˆ˜ì˜ì‚¬ì˜ ì •í™•í•œ ì§„ë‹¨ì„ ë°›ìœ¼ì‹œê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
"""
        state["rag_response"] = fallback_response.strip()
        print(f"  â†’ ì¼ë°˜ ì¡°ì–¸ìœ¼ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
    
    return state


def quality_check_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ E: ë‹µë³€ í’ˆì§ˆ í‰ê°€"""
    print("[ë…¸ë“œ E] ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì¤‘...")
    
    rag_response = state.get("rag_response", "")
    question = state["question"]
    
    if len(rag_response) < 50:
        state["quality_check"] = "fail"
        state["feedback"] = "ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤."
        print("  â†’ í‰ê°€: FAIL (ë‹µë³€ ë„ˆë¬´ ì§§ìŒ)")
        return state
    
    question_keywords = question.lower().split()
    response_lower = rag_response.lower()
    
    keyword_match = sum(1 for kw in question_keywords if kw in response_lower)
    
    if keyword_match < 2:
        state["quality_check"] = "fail"
        state["feedback"] = "ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤."
        print("  â†’ í‰ê°€: FAIL (ê´€ë ¨ì„± ë‚®ìŒ)")
        return state
    
    if state.get("intent") == "medical_consultation":
        if "ë³‘ì›" not in response_lower:
            state["quality_check"] = "fail"
            state["feedback"] = "ë³‘ì› ë°©ë¬¸ ê¶Œê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
            print("  â†’ í‰ê°€: FAIL (ë³‘ì› ê¶Œê³  ì—†ìŒ)")
            return state
    
    state["quality_check"] = "pass"
    print("  â†’ í‰ê°€: PASS")
    return state


def rewrite_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ F: ë‹µë³€ ì¬ìƒì„±"""
    print("[ë…¸ë“œ F] í”¼ë“œë°± ê¸°ë°˜ ë‹µë³€ ì¬ìƒì„± ì¤‘...")
    
    question = state["question"]
    previous_response = state.get("rag_response", "")
    feedback = state.get("feedback", "")
    
    rewrite_prompt = f"""
ì´ì „ ë‹µë³€ì´ ë‹¤ìŒ ì´ìœ ë¡œ ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤:
{feedback}

ì§ˆë¬¸: {question}

ì´ì „ ë‹µë³€:
{previous_response}

ìœ„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë” ë‚˜ì€ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¦ìƒ ì„¤ëª…
2. ì£¼ì˜ì‚¬í•­
3. ë³‘ì› ë°©ë¬¸ ê¶Œê³ 
"""
    
    from langchain.schema import Document
    documents = [Document(page_content=rewrite_prompt, metadata={})]
    
    try:
        response = rag_chain.generate_response(question, documents)
        state["rag_response"] = response
        state["quality_check"] = "pass"
        print("  â†’ ì¬ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"  â†’ ì¬ìƒì„± ì‹¤íŒ¨: {e}")
    
    return state


def hospital_search_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ: ë³‘ì› ê²€ìƒ‰ ì „ìš© ë…¸ë“œ (ì˜ë„ê°€ hospital_searchì¼ ë•Œ)"""
    print("[ë³‘ì› ê²€ìƒ‰ ë…¸ë“œ] ì¹´ì¹´ì˜¤ë§µ APIë¡œ ë™ë¬¼ë³‘ì› ê²€ìƒ‰ ì¤‘...")
    
    question = state["question"]
    location = state.get("location", "ì„œìš¸íŠ¹ë³„ì‹œ")
    radius = state.get("radius", 3000)
    
    try:
        # ì¹´ì¹´ì˜¤ë§µ APIë¥¼ ì‚¬ìš©í•œ ë³‘ì› ê²€ìƒ‰
        hospital_text = search_nearby_hospitals(
            location=location,
            radius=radius
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì¢… ì‘ë‹µìœ¼ë¡œ ì„¤ì •
        state["final_response"] = f"""
ğŸ¥ **ë™ë¬¼ë³‘ì› ê²€ìƒ‰ ê²°ê³¼**

ì§ˆë¬¸: {question}
ê²€ìƒ‰ ì§€ì—­: {location}
ê²€ìƒ‰ ë°˜ê²½: {radius}m

{hospital_text}

ğŸ’¡ **ì´ìš© íŒ:**
- ë°©ë¬¸ ì „ ë¯¸ë¦¬ ì „í™”ë¡œ ì§„ë£Œ ì‹œê°„ì„ í™•ì¸í•˜ì„¸ìš”
- ì‘ê¸‰ ìƒí™©ì´ë¼ë©´ 24ì‹œê°„ ì‘ê¸‰ë™ë¬¼ë³‘ì›ì„ ì´ìš©í•˜ì„¸ìš”
- ë°˜ë ¤ê²¬ì˜ ì¦ìƒì„ ìì„¸íˆ ë©”ëª¨í•´ê°€ì‹œë©´ ì§„ë£Œì— ë„ì›€ë©ë‹ˆë‹¤
"""
        
        state["hospital_text"] = hospital_text
        state["hospitals"] = []
        
        print("  â†’ ë³‘ì› ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"  â†’ ë³‘ì› ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        state["final_response"] = f"""
âš ï¸ **ë³‘ì› ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤**

ì§ˆë¬¸: {question}

ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë™ë¬¼ë³‘ì› ê²€ìƒ‰ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

**ëŒ€ì•ˆ:**
1. ë„¤ì´ë²„/êµ¬ê¸€ ì§€ë„ì—ì„œ "ë™ë¬¼ë³‘ì› + ì§€ì—­ëª…"ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰
2. ë™ë¬¼ë³‘ì› ì˜ˆì•½ ì•± (í«ë‹¥í„°, 24ì‹œí«ë³‘ì› ë“±) ì´ìš©
3. ì§€ì—­ ë™ë¬¼ë³‘ì› ì „í™”ë²ˆí˜¸ë¶€ í™•ì¸

ì‘ê¸‰ìƒí™©ì´ë¼ë©´ 119ì— ë¬¸ì˜í•˜ì—¬ ê°€ê¹Œìš´ ì‘ê¸‰ë™ë¬¼ë³‘ì›ì„ ì•ˆë‚´ë°›ìœ¼ì„¸ìš”.
"""
        state["hospital_text"] = ""
        state["hospitals"] = []
    
    return state


def search_hospitals_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ G: ë™ë¬¼ë³‘ì› ê²€ìƒ‰ (ì˜ë£Œìƒë‹´ í›„ ë³‘ì› ì¶”ì²œìš©)"""
    print("[ë…¸ë“œ G] ë™ë¬¼ë³‘ì› ê²€ìƒ‰ ì¤‘...")
    
    location = state.get("location")
    radius = state.get("radius", 3000)
    
    if not location:
        print("  â†’ ìœ„ì¹˜ ì •ë³´ ì—†ìŒ, ì„œìš¸ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰")
        location = "ì„œìš¸íŠ¹ë³„ì‹œ"
    
    try:
        # ì¹´ì¹´ì˜¤ë§µ APIë¥¼ ì‚¬ìš©í•œ ë³‘ì› ê²€ìƒ‰
        hospital_text = search_nearby_hospitals(
            location=location,
            radius=radius
        )
        
        state["hospital_text"] = hospital_text
        state["hospitals"] = []
        
        print(f"  â†’ ë³‘ì› ê²€ìƒ‰ ì™„ë£Œ")
    except Exception as e:
        print(f"  â†’ ë³‘ì› ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        state["hospital_text"] = ""
        state["hospitals"] = []
    
    return state


def general_response_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ: ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ (ì˜ë„ê°€ generalì¼ ë•Œ)"""
    print("[ì¼ë°˜ ì§ˆë¬¸ ë…¸ë“œ] ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ ì¤‘...")
    
    question = state["question"]
    
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain.schema.output_parser import StrOutputParser
    
    try:
        llm = ChatOpenAI(model=settings.OPENAI_MODEL, temperature=0.3)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
ë§Œì•½ ê°•ì•„ì§€ ê´€ë ¨ ì§ˆë¬¸ì´ë¼ë©´, ê°„ë‹¨í•œ ì¼ë°˜ ì •ë³´ëŠ” ì œê³µí•˜ë˜ êµ¬ì²´ì ì¸ ì˜ë£Œ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš° "ê°•ì•„ì§€ ì¦ìƒì— ëŒ€í•´ ë” ìì„¸íˆ ë¬¸ì˜í•˜ì‹œë ¤ë©´ ì˜ë£Œ ìƒë‹´ ê¸°ëŠ¥ì„ ì´ìš©í•´ì£¼ì„¸ìš”"ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.

ë‹µë³€ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ë„ë¡ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""),
            ("human", "{question}")
        ])
        
        chain = prompt | llm | StrOutputParser()
        response = chain.invoke({"question": question})
        
        state["final_response"] = f"""
ğŸ’¬ **ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€**

{response}

---
ğŸ’¡ **ë„ì›€ë§:**
- ê°•ì•„ì§€ ì¦ìƒ ìƒë‹´: "ê°•ì•„ì§€ê°€ [ì¦ìƒ] í•´ìš”" í˜•íƒœë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”
- ë™ë¬¼ë³‘ì› ì°¾ê¸°: "[ì§€ì—­] ë™ë¬¼ë³‘ì› ì°¾ì•„ì£¼ì„¸ìš”" í˜•íƒœë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”
"""
        
        print("  â†’ ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"  â†’ ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        state["final_response"] = f"""
ğŸ’¬ **ë‹µë³€**

ì•ˆë…•í•˜ì„¸ìš”! ì§ˆë¬¸í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.

í˜„ì¬ ì¼ì‹œì ì¸ ë¬¸ì œë¡œ ìƒì„¸í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.

**ì´ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:**
- ê°•ì•„ì§€ ì¦ìƒ ìƒë‹´: "ê°•ì•„ì§€ê°€ [ì¦ìƒëª…]ì„ í•´ìš”" í˜•íƒœë¡œ ì§ˆë¬¸
- ë™ë¬¼ë³‘ì› ì°¾ê¸°: "[ì§€ì—­ëª…] ë™ë¬¼ë³‘ì› ì°¾ì•„ì£¼ì„¸ìš”" í˜•íƒœë¡œ ì§ˆë¬¸

ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    
    return state


def finalize_response_node(state: ChatState) -> ChatState:
    """ë…¸ë“œ H: ìµœì¢… ì‘ë‹µ í†µí•©"""
    print("[ë…¸ë“œ H] ìµœì¢… ì‘ë‹µ í†µí•© ì¤‘...")
    
    rag_response = state["rag_response"]
    hospital_text = state.get("hospital_text", "")  # ğŸ”§ ë³€ê²½
    web_results = state.get("web_search_results", [])
    used_web_search = state.get("needs_web_search", False) and len(web_results) > 0
    
    final_parts = []
    
    final_parts.append("=" * 50)
    if used_web_search:
        final_parts.append("ğŸ“Š **ì •ë³´ ì¶œì²˜: VectorDB + ì›¹ê²€ìƒ‰** ğŸŒ")
        final_parts.append("(VectorDBì— ì¶©ë¶„í•œ ì •ë³´ê°€ ì—†ì–´ ì›¹ì—ì„œ ì¶”ê°€ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤)")
    else:
        final_parts.append("ğŸ“Š **ì •ë³´ ì¶œì²˜: VectorDB** ğŸ“š")
        final_parts.append("(ì—…ë¡œë“œëœ ê°•ì•„ì§€ ì¦ìƒ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤)")
    final_parts.append("=" * 50 + "\n")
    
    final_parts.append(rag_response)
    
    if web_results:
        final_parts.append("\n\n" + "=" * 50)
        final_parts.append("\nğŸ” **ì›¹ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ í™•ì¸í•œ ìë£Œ**\n")
        for i, result in enumerate(web_results[:3], 1):
            if result.get('url'):
                final_parts.append(f"\n{i}. **{result['title']}**")
                final_parts.append(f"   ğŸ”— ì¶œì²˜: {result['url']}")
                content_preview = result.get('content', '')[:150]
                if content_preview:
                    final_parts.append(f"   ğŸ’¬ ìš”ì•½: {content_preview}...")
            else:
                final_parts.append(f"\n{i}. **{result['title']}** (AI ìš”ì•½)")
    
    # ğŸ”§ ë³‘ì› ì •ë³´ ì¶œë ¥ ìˆ˜ì •
    if hospital_text:
        final_parts.append("\n\n" + "=" * 50)
        final_parts.append(hospital_text)
    else:
        final_parts.append("\n\nâš ï¸ ê·¼ì²˜ ë™ë¬¼ë³‘ì› ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    state["final_response"] = "\n".join(final_parts)
    print("  â†’ ìµœì¢… ì‘ë‹µ ì™„ì„±")
    
    return state


def route_after_intent(state: ChatState) -> str:
    """ì˜ë„ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì • (3ê°ˆë˜)"""
    intent = state.get("intent", "medical_consultation")
    
    if intent == "hospital_search":
        print(f"  â†’ ë¼ìš°íŒ…: {intent} â†’ hospital_search_node")
        return "hospital_search"
    elif intent == "medical_consultation":
        print(f"  â†’ ë¼ìš°íŒ…: {intent} â†’ retrieve_node")
        return "retrieve"
    else:  # general
        print(f"  â†’ ë¼ìš°íŒ…: {intent} â†’ general_response")
        return "general_response"


def route_after_quality_check(state: ChatState) -> str:
    """í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    quality_check = state.get("quality_check", "pass")
    
    if quality_check == "fail":
        return "rewrite"
    else:
        return "search_hospitals"


def create_graph() -> StateGraph:
    """LangGraph ê·¸ë˜í”„ ìƒì„± - 3ê°ˆë˜ í”Œë¡œìš°"""
    
    workflow = StateGraph(ChatState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("preprocess", preprocess_node)
    workflow.add_node("intent_classifier", intent_classifier_node)
    
    # 3ê°ˆë˜ ë¶„ê¸°ìš© ë…¸ë“œë“¤
    workflow.add_node("retrieve", retrieve_node)  # ì˜ë£Œìƒë‹´ìš© RAG ê²€ìƒ‰
    workflow.add_node("hospital_search", hospital_search_node)  # ë³‘ì›ê²€ìƒ‰ ì „ìš©
    workflow.add_node("general_response", general_response_node)  # ì¼ë°˜ì§ˆë¬¸ ì²˜ë¦¬
    
    # ì˜ë£Œìƒë‹´ í”Œë¡œìš° ë…¸ë“œë“¤
    workflow.add_node("web_search", web_search_node)
    workflow.add_node("generate", generate_response_node) 
    workflow.add_node("quality_evaluator", quality_check_node)
    workflow.add_node("rewrite", rewrite_node)  # ì¬ìƒì„± ë…¸ë“œ
    workflow.add_node("search_hospitals", search_hospitals_node)  # ì˜ë£Œìƒë‹´ í›„ ë³‘ì›ê²€ìƒ‰
    workflow.add_node("finalize", finalize_response_node)
    
    # ì‹œì‘ì ê³¼ ì˜ë„ ë¶„ë¥˜
    workflow.set_entry_point("preprocess")
    workflow.add_edge("preprocess", "intent_classifier")
    
    # ì˜ë„ë³„ 3ê°ˆë˜ ë¶„ê¸°
    workflow.add_conditional_edges(
        "intent_classifier",
        route_after_intent,
        {
            "retrieve": "retrieve",  # ì˜ë£Œìƒë‹´ â†’ RAG ê²€ìƒ‰
            "hospital_search": "hospital_search",  # ë³‘ì›ê²€ìƒ‰ â†’ ë³‘ì›ê²€ìƒ‰ ë…¸ë“œ
            "general_response": "general_response"  # ì¼ë°˜ì§ˆë¬¸ â†’ ì¼ë°˜ì‘ë‹µ ë…¸ë“œ
        }
    )
    
    # ì˜ë£Œìƒë‹´ í”Œë¡œìš° (retrieve â†’ grade_documents â†’ web_search/generate)
    workflow.add_edge("retrieve", "web_search")  # grade_documents_nodeëŠ” retrieve_node ì•ˆì—ì„œ ì²˜ë¦¬
    
    # ì›¹ê²€ìƒ‰ í›„ ë‹µë³€ ìƒì„±
    workflow.add_edge("web_search", "generate")
    
    # ë‹µë³€ í’ˆì§ˆ í‰ê°€ í›„ ì¬ìƒì„± ì—¬ë¶€ ê²°ì •
    workflow.add_edge("generate", "quality_evaluator")
    
    workflow.add_conditional_edges(
        "quality_evaluator",
        route_after_quality_check,
        {
            "rewrite": "rewrite",  # í’ˆì§ˆ ë‚®ìŒ â†’ ì¬ìƒì„±
            "search_hospitals": "search_hospitals"  # í’ˆì§ˆ OK â†’ ë³‘ì›ê²€ìƒ‰
        }
    )
    
    # ì¬ìƒì„± í›„ ë³‘ì›ê²€ìƒ‰ìœ¼ë¡œ ì´ë™
    workflow.add_edge("rewrite", "search_hospitals")
    
    # ì˜ë£Œìƒë‹´ì˜ ë³‘ì›ê²€ìƒ‰ í›„ ìµœì¢… ì‘ë‹µ í†µí•©
    workflow.add_edge("search_hospitals", "finalize")
    
    # ì¢…ë£Œì ë“¤
    workflow.add_edge("hospital_search", END)  # ë³‘ì›ê²€ìƒ‰ì€ ë°”ë¡œ ì¢…ë£Œ
    workflow.add_edge("general_response", END)  # ì¼ë°˜ì§ˆë¬¸ë„ ë°”ë¡œ ì¢…ë£Œ
    workflow.add_edge("finalize", END)  # ì˜ë£Œìƒë‹´ì€ finalize í›„ ì¢…ë£Œ
    
    return workflow.compile()


graph = create_graph()